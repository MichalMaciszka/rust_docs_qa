{
  "data": [
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "What method must iterator implement?",
              "id": 2,
              "answers": [
                {
                  "answer_id": 2,
                  "document_id": 64,
                  "question_id": 2,
                  "text": "the\n`next` method",
                  "answer_start": 3130,
                  "answer_end": 3147,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "How can iterator be consumed?",
              "id": 3,
              "answers": [
                {
                  "answer_id": 3,
                  "document_id": 64,
                  "question_id": 3,
                  "text": "use the `collect` method",
                  "answer_start": 7054,
                  "answer_end": 7078,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "How can I filter container elements?",
              "id": 4,
              "answers": [
                {
                  "answer_id": 4,
                  "document_id": 64,
                  "question_id": 4,
                  "text": "call `filter`",
                  "answer_start": 9561,
                  "answer_end": 9574,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What is an iterator?",
              "id": 113,
              "answers": [
                {
                  "answer_id": 113,
                  "document_id": 64,
                  "question_id": 113,
                  "text": "The iterator pattern allows you to perform some task on a sequence of items in\nturn. An iterator is responsible for the logic of iterating over each item and\ndetermining when the sequence has finished.",
                  "answer_start": 48,
                  "answer_end": 249,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "When iterators are evaluated?",
              "id": 114,
              "answers": [
                {
                  "answer_id": 114,
                  "document_id": 64,
                  "question_id": 114,
                  "text": "In Rust, iterators are *lazy*, meaning they have no effect until you call\nmethods that consume the iterator to use it up.",
                  "answer_start": 326,
                  "answer_end": 447,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "How iterators work with for loops?",
              "id": 115,
              "answers": [
                {
                  "answer_id": 115,
                  "document_id": 64,
                  "question_id": 115,
                  "text": "we\niterated over an array using a `for` loop to execute some code on each of its\nitems. Under the hood this implicitly created and then consumed an iterator",
                  "answer_start": 955,
                  "answer_end": 1111,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "## Processing a Series of Items with Iterators\n\nThe iterator pattern allows you to perform some task on a sequence of items in\nturn. An iterator is responsible for the logic of iterating over each item and\ndetermining when the sequence has finished. When you use iterators, you don’t\nhave to reimplement that logic yourself.\n\nIn Rust, iterators are *lazy*, meaning they have no effect until you call\nmethods that consume the iterator to use it up. For example, the code in\nListing 13-10 creates an iterator over the items in the vector `v1` by calling\nthe `iter` method defined on `Vec<T>`. This code by itself doesn’t do anything\nuseful.\n\n```rust\n{{#rustdoc_include ../listings/ch13-functional-features/listing-13-10/src/main.rs:here}}\n```\n\n<span class=\"caption\">Listing 13-10: Creating an iterator</span>\n\nThe iterator is stored in the `v1_iter` variable. Once we’ve created an\niterator, we can use it in a variety of ways. In Listing 3-5 in Chapter 3, we\niterated over an array using a `for` loop to execute some code on each of its\nitems. Under the hood this implicitly created and then consumed an iterator,\nbut we glossed over how exactly that works until now.\n\nIn the example in Listing 13-11, we separate the creation of the iterator from\nthe use of the iterator in the `for` loop. When the `for` loop is called using\nthe iterator in `v1_iter`, each element in the iterator is used in one\niteration of the loop, which prints out each value.\n\n```rust\n{{#rustdoc_include ../listings/ch13-functional-features/listing-13-11/src/main.rs:here}}\n```\n\n<span class=\"caption\">Listing 13-11: Using an iterator in a `for` loop</span>\n\nIn languages that don’t have iterators provided by their standard libraries,\nyou would likely write this same functionality by starting a variable at index\n0, using that variable to index into the vector to get a value, and\nincrementing the variable value in a loop until it reached the total number of\nitems in the vector.\n\nIterators handle all that logic for you, cutting down on repetitive code you\ncould potentially mess up. Iterators give you more flexibility to use the same\nlogic with many different kinds of sequences, not just data structures you can\nindex into, like vectors. Let’s examine how iterators do that.\n\n### The `Iterator` Trait and the `next` Method\n\nAll iterators implement a trait named `Iterator` that is defined in the\nstandard library. The definition of the trait looks like this:\n\n```rust\npub trait Iterator {\n    type Item;\n\n    fn next(&mut self) -> Option<Self::Item>;\n\n    // methods with default implementations elided\n}\n```\n\nNotice this definition uses some new syntax: `type Item` and `Self::Item`,\nwhich are defining an *associated type* with this trait. We’ll talk about\nassociated types in depth in Chapter 19. For now, all you need to know is that\nthis code says implementing the `Iterator` trait requires that you also define\nan `Item` type, and this `Item` type is used in the return type of the `next`\nmethod. In other words, the `Item` type will be the type returned from the\niterator.\n\nThe `Iterator` trait only requires implementors to define one method: the\n`next` method, which returns one item of the iterator at a time wrapped in\n`Some` and, when iteration is over, returns `None`.\n\nWe can call the `next` method on iterators directly; Listing 13-12 demonstrates\nwhat values are returned from repeated calls to `next` on the iterator created\nfrom the vector.\n\n<span class=\"filename\">Filename: src/lib.rs</span>\n\n```rust,noplayground\n{{#rustdoc_include ../listings/ch13-functional-features/listing-13-12/src/lib.rs:here}}\n```\n\n<span class=\"caption\">Listing 13-12: Calling the `next` method on an\niterator</span>\n\nNote that we needed to make `v1_iter` mutable: calling the `next` method on an\niterator changes internal state that the iterator uses to keep track of where\nit is in the sequence. In other words, this code *consumes*, or uses up, the\niterator. Each call to `next` eats up an item from the iterator. We didn’t need\nto make `v1_iter` mutable when we used a `for` loop because the loop took\nownership of `v1_iter` and made it mutable behind the scenes.\n\nAlso note that the values we get from the calls to `next` are immutable\nreferences to the values in the vector. The `iter` method produces an iterator\nover immutable references. If we want to create an iterator that takes\nownership of `v1` and returns owned values, we can call `into_iter` instead of\n`iter`. Similarly, if we want to iterate over mutable references, we can call\n`iter_mut` instead of `iter`.\n\n### Methods that Consume the Iterator\n\nThe `Iterator` trait has a number of different methods with default\nimplementations provided by the standard library; you can find out about these\nmethods by looking in the standard library API documentation for the `Iterator`\ntrait. Some of these methods call the `next` method in their definition, which\nis why you’re required to implement the `next` method when implementing the\n`Iterator` trait.\n\nMethods that call `next` are called *consuming adaptors*, because calling them\nuses up the iterator. One example is the `sum` method, which takes ownership of\nthe iterator and iterates through the items by repeatedly calling `next`, thus\nconsuming the iterator. As it iterates through, it adds each item to a running\ntotal and returns the total when iteration is complete. Listing 13-13 has a\ntest illustrating a use of the `sum` method:\n\n<span class=\"filename\">Filename: src/lib.rs</span>\n\n```rust,noplayground\n{{#rustdoc_include ../listings/ch13-functional-features/listing-13-13/src/lib.rs:here}}\n```\n\n<span class=\"caption\">Listing 13-13: Calling the `sum` method to get the total\nof all items in the iterator</span>\n\nWe aren’t allowed to use `v1_iter` after the call to `sum` because `sum` takes\nownership of the iterator we call it on.\n\n### Methods that Produce Other Iterators\n\n*Iterator adaptors* are methods defined on the `Iterator` trait that don’t\nconsume the iterator. Instead, they produce different iterators by changing\nsome aspect of the original iterator.\n\nListing 13-14 shows an example of calling the iterator adaptor method `map`,\nwhich takes a closure to call on each item as the items are iterated through.\nThe `map` method returns a new iterator that produces the modified items. The\nclosure here creates a new iterator in which each item from the vector will be\nincremented by 1:\n\n<span class=\"filename\">Filename: src/main.rs</span>\n\n```rust,not_desired_behavior\n{{#rustdoc_include ../listings/ch13-functional-features/listing-13-14/src/main.rs:here}}\n```\n\n<span class=\"caption\">Listing 13-14: Calling the iterator adaptor `map` to\ncreate a new iterator</span>\n\nHowever, this code produces a warning:\n\n```console\n{{#include ../listings/ch13-functional-features/listing-13-14/output.txt}}\n```\n\nThe code in Listing 13-14 doesn’t do anything; the closure we’ve specified\nnever gets called. The warning reminds us why: iterator adaptors are lazy, and\nwe need to consume the iterator here.\n\nTo fix this warning and consume the iterator, we’ll use the `collect` method,\nwhich we used in Chapter 12 with `env::args` in Listing 12-1. This method\nconsumes the iterator and collects the resulting values into a collection data\ntype.\n\nIn Listing 13-15, we collect the results of iterating over the iterator that’s\nreturned from the call to `map` into a vector. This vector will end up\ncontaining each item from the original vector incremented by 1.\n\n<span class=\"filename\">Filename: src/main.rs</span>\n\n```rust\n{{#rustdoc_include ../listings/ch13-functional-features/listing-13-15/src/main.rs:here}}\n```\n\n<span class=\"caption\">Listing 13-15: Calling the `map` method to create a new\niterator and then calling the `collect` method to consume the new iterator and\ncreate a vector</span>\n\nBecause `map` takes a closure, we can specify any operation we want to perform\non each item. This is a great example of how closures let you customize some\nbehavior while reusing the iteration behavior that the `Iterator` trait\nprovides.\n\nYou can chain multiple calls to iterator adaptors to perform complex actions in\na readable way. But because all iterators are lazy, you have to call one of the\nconsuming adaptor methods to get results from calls to iterator adaptors.\n\n### Using Closures that Capture Their Environment\n\nMany iterator adapters take closures as arguments, and commonly the closures\nwe’ll specify as arguments to iterator adapters will be closures that capture\ntheir environment.\n\nFor this example, we’ll use the `filter` method that takes a closure. The\nclosure gets an item from the iterator and returns a `bool`. If the closure\nreturns `true`, the value will be included in the iteration produced by\n`filter`. If the closure returns `false`, the value won’t be included.\n\nIn Listing 13-16, we use `filter` with a closure that captures the `shoe_size`\nvariable from its environment to iterate over a collection of `Shoe` struct\ninstances. It will return only shoes that are the specified size.\n\n<span class=\"filename\">Filename: src/lib.rs</span>\n\n```rust,noplayground\n{{#rustdoc_include ../listings/ch13-functional-features/listing-13-16/src/lib.rs}}\n```\n\n<span class=\"caption\">Listing 13-16: Using the `filter` method with a closure\nthat captures `shoe_size`</span>\n\nThe `shoes_in_size` function takes ownership of a vector of shoes and a shoe\nsize as parameters. It returns a vector containing only shoes of the specified\nsize.\n\nIn the body of `shoes_in_size`, we call `into_iter` to create an iterator\nthat takes ownership of the vector. Then we call `filter` to adapt that\niterator into a new iterator that only contains elements for which the closure\nreturns `true`.\n\nThe closure captures the `shoe_size` parameter from the environment and\ncompares the value with each shoe’s size, keeping only shoes of the size\nspecified. Finally, calling `collect` gathers the values returned by the\nadapted iterator into a vector that’s returned by the function.\n\nThe test shows that when we call `shoes_in_size`, we get back only shoes\nthat have the same size as the value we specified.\n",
          "document_id": 64
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "What to do with iterator output?",
              "id": 5,
              "answers": [
                {
                  "answer_id": 5,
                  "document_id": 65,
                  "question_id": 5,
                  "text": "we use a `match` to extract the value",
                  "answer_start": 5255,
                  "answer_end": 5292,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What code style should be used for iteration?",
              "id": 6,
              "answers": [
                {
                  "answer_id": 6,
                  "document_id": 65,
                  "question_id": 6,
                  "text": "Most Rust programmers prefer to use the iterator\nstyle.",
                  "answer_start": 7347,
                  "answer_end": 7402,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "How iterator can improve the code?",
              "id": 7,
              "answers": [
                {
                  "answer_id": 7,
                  "document_id": 65,
                  "question_id": 7,
                  "text": "This will clarify what the\n`Config::build` function is doing because the iterator will access the values.",
                  "answer_start": 1692,
                  "answer_end": 1797,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "How to make parameter mutable?",
              "id": 116,
              "answers": [
                {
                  "answer_id": 116,
                  "document_id": 65,
                  "question_id": 116,
                  "text": "we can add the `mut` keyword into the specification of the\n`args` parameter to make it mutable",
                  "answer_start": 4292,
                  "answer_end": 4386,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What is the first value returned from env::args?",
              "id": 117,
              "answers": [
                {
                  "answer_id": 117,
                  "document_id": 65,
                  "question_id": 117,
                  "text": "the first value in the return value of `env::args` is the name of\nthe program",
                  "answer_start": 4947,
                  "answer_end": 5024,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "How to improve iteration code?",
              "id": 118,
              "answers": [
                {
                  "answer_id": 118,
                  "document_id": 65,
                  "question_id": 118,
                  "text": "We can write this code in a more concise way using iterator adaptor methods.",
                  "answer_start": 5913,
                  "answer_end": 5989,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "## Improving Our I/O Project\n\nWith this new knowledge about iterators, we can improve the I/O project in\nChapter 12 by using iterators to make places in the code clearer and more\nconcise. Let’s look at how iterators can improve our implementation of the\n`Config::build` function and the `search` function.\n\n### Removing a `clone` Using an Iterator\n\nIn Listing 12-6, we added code that took a slice of `String` values and created\nan instance of the `Config` struct by indexing into the slice and cloning the\nvalues, allowing the `Config` struct to own those values. In Listing 13-17,\nwe’ve reproduced the implementation of the `Config::build` function as it was\nin Listing 12-23:\n\n<span class=\"filename\">Filename: src/lib.rs</span>\n\n```rust,ignore\n{{#rustdoc_include ../listings/ch13-functional-features/listing-12-23-reproduced/src/lib.rs:ch13}}\n```\n\n<span class=\"caption\">Listing 13-17: Reproduction of the `Config::build`\nfunction from Listing 12-23</span>\n\nAt the time, we said not to worry about the inefficient `clone` calls because\nwe would remove them in the future. Well, that time is now!\n\nWe needed `clone` here because we have a slice with `String` elements in the\nparameter `args`, but the `build` function doesn’t own `args`. To return\nownership of a `Config` instance, we had to clone the values from the `query`\nand `file_path` fields of `Config` so the `Config` instance can own its values.\n\nWith our new knowledge about iterators, we can change the `build` function to\ntake ownership of an iterator as its argument instead of borrowing a slice.\nWe’ll use the iterator functionality instead of the code that checks the length\nof the slice and indexes into specific locations. This will clarify what the\n`Config::build` function is doing because the iterator will access the values.\n\nOnce `Config::build` takes ownership of the iterator and stops using indexing\noperations that borrow, we can move the `String` values from the iterator into\n`Config` rather than calling `clone` and making a new allocation.\n\n#### Using the Returned Iterator Directly\n\nOpen your I/O project’s *src/main.rs* file, which should look like this:\n\n<span class=\"filename\">Filename: src/main.rs</span>\n\n```rust,ignore\n{{#rustdoc_include ../listings/ch13-functional-features/listing-12-24-reproduced/src/main.rs:ch13}}\n```\n\nWe’ll first change the start of the `main` function that we had in Listing\n12-24 to the code in Listing 13-18, which this time uses an iterator. This\nwon’t compile until we update `Config::build` as well.\n\n<span class=\"filename\">Filename: src/main.rs</span>\n\n```rust,ignore,does_not_compile\n{{#rustdoc_include ../listings/ch13-functional-features/listing-13-18/src/main.rs:here}}\n```\n\n<span class=\"caption\">Listing 13-18: Passing the return value of `env::args` to\n`Config::build`</span>\n\nThe `env::args` function returns an iterator! Rather than collecting the\niterator values into a vector and then passing a slice to `Config::build`, now\nwe’re passing ownership of the iterator returned from `env::args` to\n`Config::build` directly.\n\nNext, we need to update the definition of `Config::build`. In your I/O\nproject’s *src/lib.rs* file, let’s change the signature of `Config::build` to\nlook like Listing 13-19. This still won’t compile because we need to update the\nfunction body.\n\n<span class=\"filename\">Filename: src/lib.rs</span>\n\n```rust,ignore,does_not_compile\n{{#rustdoc_include ../listings/ch13-functional-features/listing-13-19/src/lib.rs:here}}\n```\n\n<span class=\"caption\">Listing 13-19: Updating the signature of `Config::build`\nto expect an iterator</span>\n\nThe standard library documentation for the `env::args` function shows that the\ntype of the iterator it returns is `std::env::Args`, and that type implements\nthe `Iterator` trait and returns `String` values.\n\nWe’ve updated the signature of the `Config::build` function so the parameter\n`args` has a generic type with the trait bounds `impl Iterator<Item = String>`\ninstead of `&[String]`. This usage of the `impl Trait` syntax we discussed in\nthe [“Traits as Parameters”][impl-trait]<!-- ignore --> section of Chapter 10\nmeans that `args` can be any type that implements the `Iterator` type and\nreturns `String` items.\n\nBecause we’re taking ownership of `args` and we’ll be mutating `args` by\niterating over it, we can add the `mut` keyword into the specification of the\n`args` parameter to make it mutable.\n\n#### Using `Iterator` Trait Methods Instead of Indexing\n\nNext, we’ll fix the body of `Config::build`. Because `args` implements the\n`Iterator` trait, we know we can call the `next` method on it! Listing 13-20\nupdates the code from Listing 12-23 to use the `next` method:\n\n<span class=\"filename\">Filename: src/lib.rs</span>\n\n```rust,noplayground\n{{#rustdoc_include ../listings/ch13-functional-features/listing-13-20/src/lib.rs:here}}\n```\n\n<span class=\"caption\">Listing 13-20: Changing the body of `Config::build` to use\niterator methods</span>\n\nRemember that the first value in the return value of `env::args` is the name of\nthe program. We want to ignore that and get to the next value, so first we call\n`next` and do nothing with the return value. Second, we call `next` to get the\nvalue we want to put in the `query` field of `Config`. If `next` returns a\n`Some`, we use a `match` to extract the value. If it returns `None`, it means\nnot enough arguments were given and we return early with an `Err` value. We do\nthe same thing for the `file_path` value.\n\n### Making Code Clearer with Iterator Adaptors\n\nWe can also take advantage of iterators in the `search` function in our I/O\nproject, which is reproduced here in Listing 13-21 as it was in Listing 12-19:\n\n<span class=\"filename\">Filename: src/lib.rs</span>\n\n```rust,ignore\n{{#rustdoc_include ../listings/ch12-an-io-project/listing-12-19/src/lib.rs:ch13}}\n```\n\n<span class=\"caption\">Listing 13-21: The implementation of the `search`\nfunction from Listing 12-19</span>\n\nWe can write this code in a more concise way using iterator adaptor methods.\nDoing so also lets us avoid having a mutable intermediate `results` vector. The\nfunctional programming style prefers to minimize the amount of mutable state to\nmake code clearer. Removing the mutable state might enable a future enhancement\nto make searching happen in parallel, because we wouldn’t have to manage\nconcurrent access to the `results` vector. Listing 13-22 shows this change:\n\n<span class=\"filename\">Filename: src/lib.rs</span>\n\n```rust,ignore\n{{#rustdoc_include ../listings/ch13-functional-features/listing-13-22/src/lib.rs:here}}\n```\n\n<span class=\"caption\">Listing 13-22: Using iterator adaptor methods in the\nimplementation of the `search` function</span>\n\nRecall that the purpose of the `search` function is to return all lines in\n`contents` that contain the `query`. Similar to the `filter` example in Listing\n13-16, this code uses the `filter` adaptor to keep only the lines that\n`line.contains(query)` returns `true` for. We then collect the matching lines\ninto another vector with `collect`. Much simpler! Feel free to make the same\nchange to use iterator methods in the `search_case_insensitive` function as\nwell.\n\n### Choosing Between Loops or Iterators\n\nThe next logical question is which style you should choose in your own code and\nwhy: the original implementation in Listing 13-21 or the version using\niterators in Listing 13-22. Most Rust programmers prefer to use the iterator\nstyle. It’s a bit tougher to get the hang of at first, but once you get a feel\nfor the various iterator adaptors and what they do, iterators can be easier to\nunderstand. Instead of fiddling with the various bits of looping and building\nnew vectors, the code focuses on the high-level objective of the loop. This\nabstracts away some of the commonplace code so it’s easier to see the concepts\nthat are unique to this code, such as the filtering condition each element in\nthe iterator must pass.\n\nBut are the two implementations truly equivalent? The intuitive assumption\nmight be that the more low-level loop will be faster. Let’s talk about\nperformance.\n\n[impl-trait]: ch10-02-traits.html#traits-as-parameters\n",
          "document_id": 65
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "What is zero-overhead?",
              "id": 8,
              "answers": [
                {
                  "answer_id": 8,
                  "document_id": 66,
                  "question_id": 8,
                  "text": "> In general, C++ implementations obey the zero-overhead principle: What you\n> don’t use, you don’t pay for. And further: What you do use, you couldn’t hand\n> code any better.",
                  "answer_start": 1577,
                  "answer_end": 1752,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "How iterators work on assembly level?",
              "id": 9,
              "answers": [
                {
                  "answer_id": 9,
                  "document_id": 66,
                  "question_id": 9,
                  "text": "Well,\nas of this writing, it compiles down to the same assembly you’d write by hand.",
                  "answer_start": 3400,
                  "answer_end": 3484,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "Is iterator faster than loop?",
              "id": 10,
              "answers": [
                {
                  "answer_id": 10,
                  "document_id": 66,
                  "question_id": 10,
                  "text": "The iterator version was slightly faster!",
                  "answer_start": 689,
                  "answer_end": 730,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What is unrolling?",
              "id": 119,
              "answers": [
                {
                  "answer_id": 119,
                  "document_id": 66,
                  "question_id": 119,
                  "text": "*Unrolling* is an optimization that removes the overhead of the loop\ncontrolling code and instead generates repetitive code for each iteration of\nthe loop.",
                  "answer_start": 3641,
                  "answer_end": 3796,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "Is there a runtime cost for using iterators?",
              "id": 120,
              "answers": [
                {
                  "answer_id": 120,
                  "document_id": 66,
                  "question_id": 120,
                  "text": "They make code seem like it’s higher level but don’t impose a\nruntime performance penalty for doing so.",
                  "answer_start": 4122,
                  "answer_end": 4225,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "## Comparing Performance: Loops vs. Iterators\n\nTo determine whether to use loops or iterators, you need to know which\nimplementation is faster: the version of the `search` function with an explicit\n`for` loop or the version with iterators.\n\nWe ran a benchmark by loading the entire contents of *The Adventures of\nSherlock Holmes* by Sir Arthur Conan Doyle into a `String` and looking for the\nword *the* in the contents. Here are the results of the benchmark on the\nversion of `search` using the `for` loop and the version using iterators:\n\n```text\ntest bench_search_for  ... bench:  19,620,300 ns/iter (+/- 915,700)\ntest bench_search_iter ... bench:  19,234,900 ns/iter (+/- 657,200)\n```\n\nThe iterator version was slightly faster! We won’t explain the benchmark code\nhere, because the point is not to prove that the two versions are equivalent\nbut to get a general sense of how these two implementations compare\nperformance-wise.\n\nFor a more comprehensive benchmark, you should check using various texts of\nvarious sizes as the `contents`, different words and words of different lengths\nas the `query`, and all kinds of other variations. The point is this:\niterators, although a high-level abstraction, get compiled down to roughly the\nsame code as if you’d written the lower-level code yourself. Iterators are one\nof Rust’s *zero-cost abstractions*, by which we mean using the abstraction\nimposes no additional runtime overhead. This is analogous to how Bjarne\nStroustrup, the original designer and implementor of C++, defines\n*zero-overhead* in “Foundations of C++” (2012):\n\n> In general, C++ implementations obey the zero-overhead principle: What you\n> don’t use, you don’t pay for. And further: What you do use, you couldn’t hand\n> code any better.\n\nAs another example, the following code is taken from an audio decoder. The\ndecoding algorithm uses the linear prediction mathematical operation to\nestimate future values based on a linear function of the previous samples. This\ncode uses an iterator chain to do some math on three variables in scope: a\n`buffer` slice of data, an array of 12 `coefficients`, and an amount by which\nto shift data in `qlp_shift`. We’ve declared the variables within this example\nbut not given them any values; although this code doesn’t have much meaning\noutside of its context, it’s still a concise, real-world example of how Rust\ntranslates high-level ideas to low-level code.\n\n```rust,ignore\nlet buffer: &mut [i32];\nlet coefficients: [i64; 12];\nlet qlp_shift: i16;\n\nfor i in 12..buffer.len() {\n    let prediction = coefficients.iter()\n                                 .zip(&buffer[i - 12..i])\n                                 .map(|(&c, &s)| c * s as i64)\n                                 .sum::<i64>() >> qlp_shift;\n    let delta = buffer[i];\n    buffer[i] = prediction as i32 + delta;\n}\n```\n\nTo calculate the value of `prediction`, this code iterates through each of the\n12 values in `coefficients` and uses the `zip` method to pair the coefficient\nvalues with the previous 12 values in `buffer`. Then, for each pair, we\nmultiply the values together, sum all the results, and shift the bits in the\nsum `qlp_shift` bits to the right.\n\nCalculations in applications like audio decoders often prioritize performance\nmost highly. Here, we’re creating an iterator, using two adaptors, and then\nconsuming the value. What assembly code would this Rust code compile to? Well,\nas of this writing, it compiles down to the same assembly you’d write by hand.\nThere’s no loop at all corresponding to the iteration over the values in\n`coefficients`: Rust knows that there are 12 iterations, so it “unrolls” the\nloop. *Unrolling* is an optimization that removes the overhead of the loop\ncontrolling code and instead generates repetitive code for each iteration of\nthe loop.\n\nAll of the coefficients get stored in registers, which means accessing the\nvalues is very fast. There are no bounds checks on the array access at runtime.\nAll these optimizations that Rust is able to apply make the resulting code\nextremely efficient. Now that you know this, you can use iterators and closures\nwithout fear! They make code seem like it’s higher level but don’t impose a\nruntime performance penalty for doing so.\n\n## Summary\n\nClosures and iterators are Rust features inspired by functional programming\nlanguage ideas. They contribute to Rust’s capability to clearly express\nhigh-level ideas at low-level performance. The implementations of closures and\niterators are such that runtime performance is not affected. This is part of\nRust’s goal to strive to provide zero-cost abstractions.\n\nNow that we’ve improved the expressiveness of our I/O project, let’s look at\nsome more features of `cargo` that will help us share the project with the\nworld.\n",
          "document_id": 66
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "What can Cargo do?",
              "id": 11,
              "answers": [
                {
                  "answer_id": 11,
                  "document_id": 67,
                  "question_id": 11,
                  "text": "* Customize your build through release profiles\n* Publish libraries on [crates.io](https://crates.io/)‹!-- ignore -->\n* Organize large projects with workspaces\n* Install binaries from [crates.io](https://crates.io/)‹!-- ignore -->\n* Extend Cargo using custom commands",
                  "answer_start": 261,
                  "answer_end": 528,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What is Rust build tool?",
              "id": 12,
              "answers": [
                {
                  "answer_id": 12,
                  "document_id": 67,
                  "question_id": 12,
                  "text": "Cargo",
                  "answer_start": 84,
                  "answer_end": 89,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "Where to read more about cargo?",
              "id": 121,
              "answers": [
                {
                  "answer_id": 121,
                  "document_id": 67,
                  "question_id": 121,
                  "text": "https://doc.rust-lang.org/cargo/",
                  "answer_start": 673,
                  "answer_end": 705,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "# More About Cargo and Crates.io\n\nSo far we’ve used only the most basic features of Cargo to build, run, and test\nour code, but it can do a lot more. In this chapter, we’ll discuss some of its\nother, more advanced features to show you how to do the following:\n\n* Customize your build through release profiles\n* Publish libraries on [crates.io](https://crates.io/)<!-- ignore -->\n* Organize large projects with workspaces\n* Install binaries from [crates.io](https://crates.io/)<!-- ignore -->\n* Extend Cargo using custom commands\n\nCargo can do even more than the functionality we cover in this chapter, so for\na full explanation of all its features, see [its\ndocumentation](https://doc.rust-lang.org/cargo/).\n",
          "document_id": 67
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "How can I build project?",
              "id": 13,
              "answers": [
                {
                  "answer_id": 13,
                  "document_id": 68,
                  "question_id": 13,
                  "text": "cargo build",
                  "answer_start": 776,
                  "answer_end": 787,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "How to configure build?",
              "id": 15,
              "answers": [
                {
                  "answer_id": 15,
                  "document_id": 68,
                  "question_id": 15,
                  "text": "By adding `[profile.*]` sections for any profile you want to customize, you\noverride any subset of the default settings.",
                  "answer_start": 1165,
                  "answer_end": 1285,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What are the main build profiles?",
              "id": 16,
              "answers": [
                {
                  "answer_id": 16,
                  "document_id": 68,
                  "question_id": 16,
                  "text": "Cargo has two main profiles: the `dev` profile Cargo uses when you run `cargo\nbuild` and the `release` profile Cargo uses when you run `cargo build\n--release`. The `dev` profile is defined with good defaults for development,\nand the `release` profile has good defaults for release builds.",
                  "answer_start": 287,
                  "answer_end": 575,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What is opt-level?",
              "id": 122,
              "answers": [
                {
                  "answer_id": 122,
                  "document_id": 68,
                  "question_id": 122,
                  "text": "The `opt-level` setting controls the number of optimizations Rust will apply to\nyour code, with a range of 0 to 3.",
                  "answer_start": 1520,
                  "answer_end": 1634,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "How to override a default setting?",
              "id": 123,
              "answers": [
                {
                  "answer_id": 123,
                  "document_id": 68,
                  "question_id": 123,
                  "text": "You can override a default setting by adding a different value for it in\n*Cargo.toml*.",
                  "answer_start": 2199,
                  "answer_end": 2285,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "Where can I find more information about configuration?",
              "id": 124,
              "answers": [
                {
                  "answer_id": 124,
                  "document_id": 68,
                  "question_id": 124,
                  "text": "https://doc.rust-lang.org/cargo/reference/profiles.html",
                  "answer_start": 2922,
                  "answer_end": 2977,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "## Customizing Builds with Release Profiles\n\nIn Rust, *release profiles* are predefined and customizable profiles with\ndifferent configurations that allow a programmer to have more control over\nvarious options for compiling code. Each profile is configured independently of\nthe others.\n\nCargo has two main profiles: the `dev` profile Cargo uses when you run `cargo\nbuild` and the `release` profile Cargo uses when you run `cargo build\n--release`. The `dev` profile is defined with good defaults for development,\nand the `release` profile has good defaults for release builds.\n\nThese profile names might be familiar from the output of your builds:\n\n<!-- manual-regeneration\nanywhere, run:\ncargo build\ncargo build --release\nand ensure output below is accurate\n-->\n\n```console\n$ cargo build\n    Finished dev [unoptimized + debuginfo] target(s) in 0.0s\n$ cargo build --release\n    Finished release [optimized] target(s) in 0.0s\n```\n\nThe `dev` and `release` are these different profiles used by the compiler.\n\nCargo has default settings for each of the profiles that apply when you haven't\nexplicitly added any `[profile.*]` sections in the project’s *Cargo.toml* file.\nBy adding `[profile.*]` sections for any profile you want to customize, you\noverride any subset of the default settings. For example, here are the default\nvalues for the `opt-level` setting for the `dev` and `release` profiles:\n\n<span class=\"filename\">Filename: Cargo.toml</span>\n\n```toml\n[profile.dev]\nopt-level = 0\n\n[profile.release]\nopt-level = 3\n```\n\nThe `opt-level` setting controls the number of optimizations Rust will apply to\nyour code, with a range of 0 to 3. Applying more optimizations extends\ncompiling time, so if you’re in development and compiling your code often,\nyou’ll want fewer optimizations to compile faster even if the resulting code\nruns slower. The default `opt-level` for `dev` is therefore `0`. When you’re\nready to release your code, it’s best to spend more time compiling. You’ll only\ncompile in release mode once, but you’ll run the compiled program many times,\nso release mode trades longer compile time for code that runs faster. That is\nwhy the default `opt-level` for the `release` profile is `3`.\n\nYou can override a default setting by adding a different value for it in\n*Cargo.toml*. For example, if we want to use optimization level 1 in the\ndevelopment profile, we can add these two lines to our project’s *Cargo.toml*\nfile:\n\n<span class=\"filename\">Filename: Cargo.toml</span>\n\n```toml\n[profile.dev]\nopt-level = 1\n```\n\nThis code overrides the default setting of `0`. Now when we run `cargo build`,\nCargo will use the defaults for the `dev` profile plus our customization to\n`opt-level`. Because we set `opt-level` to `1`, Cargo will apply more\noptimizations than the default, but not as many as in a release build.\n\nFor the full list of configuration options and defaults for each profile, see\n[Cargo’s documentation](https://doc.rust-lang.org/cargo/reference/profiles.html).\n",
          "document_id": 68
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "What are documentation comments?",
              "id": 18,
              "answers": [
                {
                  "answer_id": 18,
                  "document_id": 69,
                  "question_id": 18,
                  "text": "Documentation comments use three slashes, `///`, instead of two and support\nMarkdown notation for formatting the text.",
                  "answer_start": 1187,
                  "answer_end": 1305,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "How to generate documentation?",
              "id": 19,
              "answers": [
                {
                  "answer_id": 19,
                  "document_id": 69,
                  "question_id": 19,
                  "text": "`cargo doc`",
                  "answer_start": 10813,
                  "answer_end": 10824,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "How many versions of crate can be created?",
              "id": 20,
              "answers": [
                {
                  "answer_id": 20,
                  "document_id": 69,
                  "question_id": 20,
                  "text": "there is\nno limit to the number of crate versions you can publish.",
                  "answer_start": 17806,
                  "answer_end": 17872,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What panics section should contain?",
              "id": 125,
              "answers": [
                {
                  "answer_id": 125,
                  "document_id": 69,
                  "question_id": 125,
                  "text": "* **Panics**: The scenarios in which the function being documented could\n  panic. Callers of the function who don’t want their programs to panic should\n  make sure they don’t call the function in these situations.",
                  "answer_start": 2908,
                  "answer_end": 3121,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What errors section should contain?",
              "id": 126,
              "answers": [
                {
                  "answer_id": 126,
                  "document_id": 69,
                  "question_id": 126,
                  "text": "* **Errors**: If the function returns a `Result`, describing the kinds of\n  errors that might occur and what conditions might cause those errors to be\n  returned can be helpful to callers so they can write code to handle the\n  different kinds of errors in different ways.",
                  "answer_start": 3122,
                  "answer_end": 3393,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What safety section should contain?",
              "id": 127,
              "answers": [
                {
                  "answer_id": 127,
                  "document_id": 69,
                  "question_id": 127,
                  "text": "* **Safety**: If the function is `unsafe` to call (we discuss unsafety in\n  Chapter 19), there should be a section explaining why the function is unsafe\n  and covering the invariants that the function expects callers to uphold.",
                  "answer_start": 3394,
                  "answer_end": 3621,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "How to add comment to a whole module?",
              "id": 128,
              "answers": [
                {
                  "answer_id": 128,
                  "document_id": 69,
                  "question_id": 128,
                  "text": "The style of doc comment `//!` adds documentation to the item that contains the\ncomments rather than to the items following the comments.",
                  "answer_start": 4945,
                  "answer_end": 5082,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "Can you open documentation automatically after creation?",
              "id": 129,
              "answers": [
                {
                  "answer_id": 129,
                  "document_id": 69,
                  "question_id": 129,
                  "text": "running `cargo doc --open` will build the HTML for your\ncurrent crate’s documentation (as well as the documentation for all of your\ncrate’s dependencies) and open the result in a web browser",
                  "answer_start": 2140,
                  "answer_end": 2330,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "How to arrange module's public interface?",
              "id": 130,
              "answers": [
                {
                  "answer_id": 130,
                  "document_id": 69,
                  "question_id": 130,
                  "text": "you can re-export items to make a public structure that’s different\nfrom your private structure by using `pub use`",
                  "answer_start": 7833,
                  "answer_end": 7947,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "Can crates have duplicate names?",
              "id": 133,
              "answers": [
                {
                  "answer_id": 133,
                  "document_id": 69,
                  "question_id": 133,
                  "text": "Your crate will need a unique name.",
                  "answer_start": 13699,
                  "answer_end": 13734,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What must be done before uploading a crate?",
              "id": 132,
              "answers": [
                {
                  "answer_id": 132,
                  "document_id": 69,
                  "question_id": 132,
                  "text": "Before you can publish any crates, you need to create an account on\n[crates.io](https://crates.io/)‹!-- ignore --> and get an API token.",
                  "answer_start": 12542,
                  "answer_end": 12678,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "Can you delete published crate?",
              "id": 134,
              "answers": [
                {
                  "answer_id": 134,
                  "document_id": 69,
                  "question_id": 134,
                  "text": "Be careful, because a publish is *permanent*. The version can never be\noverwritten, and the code cannot be deleted.",
                  "answer_start": 17376,
                  "answer_end": 17491,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What yanking means?",
              "id": 135,
              "answers": [
                {
                  "answer_id": 135,
                  "document_id": 69,
                  "question_id": 135,
                  "text": "Yanking a version prevents new projects from depending on that version while\nallowing all existing projects that depend on it to continue.",
                  "answer_start": 19455,
                  "answer_end": 19593,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "## Publishing a Crate to Crates.io\n\nWe’ve used packages from [crates.io](https://crates.io/)<!-- ignore --> as\ndependencies of our project, but you can also share your code with other people\nby publishing your own packages. The crate registry at\n[crates.io](https://crates.io/)<!-- ignore --> distributes the source code of\nyour packages, so it primarily hosts code that is open source.\n\nRust and Cargo have features that make your published package easier for people\nto find and use. We’ll talk about some of these features next and then explain\nhow to publish a package.\n\n### Making Useful Documentation Comments\n\nAccurately documenting your packages will help other users know how and when to\nuse them, so it’s worth investing the time to write documentation. In Chapter\n3, we discussed how to comment Rust code using two slashes, `//`. Rust also has\na particular kind of comment for documentation, known conveniently as a\n*documentation comment*, that will generate HTML documentation. The HTML\ndisplays the contents of documentation comments for public API items intended\nfor programmers interested in knowing how to *use* your crate as opposed to how\nyour crate is *implemented*.\n\nDocumentation comments use three slashes, `///`, instead of two and support\nMarkdown notation for formatting the text. Place documentation comments just\nbefore the item they’re documenting. Listing 14-1 shows documentation comments\nfor an `add_one` function in a crate named `my_crate`.\n\n<span class=\"filename\">Filename: src/lib.rs</span>\n\n```rust,ignore\n{{#rustdoc_include ../listings/ch14-more-about-cargo/listing-14-01/src/lib.rs}}\n```\n\n<span class=\"caption\">Listing 14-1: A documentation comment for a\nfunction</span>\n\nHere, we give a description of what the `add_one` function does, start a\nsection with the heading `Examples`, and then provide code that demonstrates\nhow to use the `add_one` function. We can generate the HTML documentation from\nthis documentation comment by running `cargo doc`. This command runs the\n`rustdoc` tool distributed with Rust and puts the generated HTML documentation\nin the *target/doc* directory.\n\nFor convenience, running `cargo doc --open` will build the HTML for your\ncurrent crate’s documentation (as well as the documentation for all of your\ncrate’s dependencies) and open the result in a web browser. Navigate to the\n`add_one` function and you’ll see how the text in the documentation comments is\nrendered, as shown in Figure 14-1:\n\n<img alt=\"Rendered HTML documentation for the `add_one` function of `my_crate`\" src=\"img/trpl14-01.png\" class=\"center\" />\n\n<span class=\"caption\">Figure 14-1: HTML documentation for the `add_one`\nfunction</span>\n\n#### Commonly Used Sections\n\nWe used the `# Examples` Markdown heading in Listing 14-1 to create a section\nin the HTML with the title “Examples.” Here are some other sections that crate\nauthors commonly use in their documentation:\n\n* **Panics**: The scenarios in which the function being documented could\n  panic. Callers of the function who don’t want their programs to panic should\n  make sure they don’t call the function in these situations.\n* **Errors**: If the function returns a `Result`, describing the kinds of\n  errors that might occur and what conditions might cause those errors to be\n  returned can be helpful to callers so they can write code to handle the\n  different kinds of errors in different ways.\n* **Safety**: If the function is `unsafe` to call (we discuss unsafety in\n  Chapter 19), there should be a section explaining why the function is unsafe\n  and covering the invariants that the function expects callers to uphold.\n\nMost documentation comments don’t need all of these sections, but this is a\ngood checklist to remind you of the aspects of your code users will be\ninterested in knowing about.\n\n#### Documentation Comments as Tests\n\nAdding example code blocks in your documentation comments can help demonstrate\nhow to use your library, and doing so has an additional bonus: running `cargo\ntest` will run the code examples in your documentation as tests! Nothing is\nbetter than documentation with examples. But nothing is worse than examples\nthat don’t work because the code has changed since the documentation was\nwritten. If we run `cargo test` with the documentation for the `add_one`\nfunction from Listing 14-1, we will see a section in the test results like this:\n\n<!-- manual-regeneration\ncd listings/ch14-more-about-cargo/listing-14-01/\ncargo test\ncopy just the doc-tests section below\n-->\n\n```text\n   Doc-tests my_crate\n\nrunning 1 test\ntest src/lib.rs - add_one (line 5) ... ok\n\ntest result: ok. 1 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.27s\n```\n\nNow if we change either the function or the example so the `assert_eq!` in the\nexample panics and run `cargo test` again, we’ll see that the doc tests catch\nthat the example and the code are out of sync with each other!\n\n#### Commenting Contained Items\n\nThe style of doc comment `//!` adds documentation to the item that contains the\ncomments rather than to the items following the comments. We typically use\nthese doc comments inside the crate root file (*src/lib.rs* by convention) or\ninside a module to document the crate or the module as a whole.\n\nFor example, to add documentation that describes the purpose of the `my_crate`\ncrate that contains the `add_one` function, we add documentation comments that\nstart with `//!` to the beginning of the *src/lib.rs* file, as shown in Listing\n14-2:\n\n<span class=\"filename\">Filename: src/lib.rs</span>\n\n```rust,ignore\n{{#rustdoc_include ../listings/ch14-more-about-cargo/listing-14-02/src/lib.rs:here}}\n```\n\n<span class=\"caption\">Listing 14-2: Documentation for the `my_crate` crate as a\nwhole</span>\n\nNotice there isn’t any code after the last line that begins with `//!`. Because\nwe started the comments with `//!` instead of `///`, we’re documenting the item\nthat contains this comment rather than an item that follows this comment. In\nthis case, that item is the *src/lib.rs* file, which is the crate root. These\ncomments describe the entire crate.\n\nWhen we run `cargo doc --open`, these comments will display on the front\npage of the documentation for `my_crate` above the list of public items in the\ncrate, as shown in Figure 14-2:\n\n<img alt=\"Rendered HTML documentation with a comment for the crate as a whole\" src=\"img/trpl14-02.png\" class=\"center\" />\n\n<span class=\"caption\">Figure 14-2: Rendered documentation for `my_crate`,\nincluding the comment describing the crate as a whole</span>\n\nDocumentation comments within items are useful for describing crates and\nmodules especially. Use them to explain the overall purpose of the container to\nhelp your users understand the crate’s organization.\n\n### Exporting a Convenient Public API with `pub use`\n\nThe structure of your public API is a major consideration when publishing a\ncrate. People who use your crate are less familiar with the structure than you\nare and might have difficulty finding the pieces they want to use if your crate\nhas a large module hierarchy.\n\nIn Chapter 7, we covered how to make items public using the `pub` keyword, and\nbring items into a scope with the `use` keyword. However, the structure that\nmakes sense to you while you’re developing a crate might not be very convenient\nfor your users. You might want to organize your structs in a hierarchy\ncontaining multiple levels, but then people who want to use a type you’ve\ndefined deep in the hierarchy might have trouble finding out that type exists.\nThey might also be annoyed at having to enter `use`\n`my_crate::some_module::another_module::UsefulType;` rather than `use`\n`my_crate::UsefulType;`.\n\nThe good news is that if the structure *isn’t* convenient for others to use\nfrom another library, you don’t have to rearrange your internal organization:\ninstead, you can re-export items to make a public structure that’s different\nfrom your private structure by using `pub use`. Re-exporting takes a public\nitem in one location and makes it public in another location, as if it were\ndefined in the other location instead.\n\nFor example, say we made a library named `art` for modeling artistic concepts.\nWithin this library are two modules: a `kinds` module containing two enums\nnamed `PrimaryColor` and `SecondaryColor` and a `utils` module containing a\nfunction named `mix`, as shown in Listing 14-3:\n\n<span class=\"filename\">Filename: src/lib.rs</span>\n\n```rust,noplayground,test_harness\n{{#rustdoc_include ../listings/ch14-more-about-cargo/listing-14-03/src/lib.rs:here}}\n```\n\n<span class=\"caption\">Listing 14-3: An `art` library with items organized into\n`kinds` and `utils` modules</span>\n\nFigure 14-3 shows what the front page of the documentation for this crate\ngenerated by `cargo doc` would look like:\n\n<img alt=\"Rendered documentation for the `art` crate that lists the `kinds` and `utils` modules\" src=\"img/trpl14-03.png\" class=\"center\" />\n\n<span class=\"caption\">Figure 14-3: Front page of the documentation for `art`\nthat lists the `kinds` and `utils` modules</span>\n\nNote that the `PrimaryColor` and `SecondaryColor` types aren’t listed on the\nfront page, nor is the `mix` function. We have to click `kinds` and `utils` to\nsee them.\n\nAnother crate that depends on this library would need `use` statements that\nbring the items from `art` into scope, specifying the module structure that’s\ncurrently defined. Listing 14-4 shows an example of a crate that uses the\n`PrimaryColor` and `mix` items from the `art` crate:\n\n<span class=\"filename\">Filename: src/main.rs</span>\n\n```rust,ignore\n{{#rustdoc_include ../listings/ch14-more-about-cargo/listing-14-04/src/main.rs}}\n```\n\n<span class=\"caption\">Listing 14-4: A crate using the `art` crate’s items with\nits internal structure exported</span>\n\nThe author of the code in Listing 14-4, which uses the `art` crate, had to\nfigure out that `PrimaryColor` is in the `kinds` module and `mix` is in the\n`utils` module. The module structure of the `art` crate is more relevant to\ndevelopers working on the `art` crate than to those using it. The internal\nstructure doesn’t contain any useful information for someone trying to\nunderstand how to use the `art` crate, but rather causes confusion because\ndevelopers who use it have to figure out where to look, and must specify the\nmodule names in the `use` statements.\n\nTo remove the internal organization from the public API, we can modify the\n`art` crate code in Listing 14-3 to add `pub use` statements to re-export the\nitems at the top level, as shown in Listing 14-5:\n\n<span class=\"filename\">Filename: src/lib.rs</span>\n\n```rust,ignore\n{{#rustdoc_include ../listings/ch14-more-about-cargo/listing-14-05/src/lib.rs:here}}\n```\n\n<span class=\"caption\">Listing 14-5: Adding `pub use` statements to re-export\nitems</span>\n\nThe API documentation that `cargo doc` generates for this crate will now list\nand link re-exports on the front page, as shown in Figure 14-4, making the\n`PrimaryColor` and `SecondaryColor` types and the `mix` function easier to find.\n\n<img alt=\"Rendered documentation for the `art` crate with the re-exports on the front page\" src=\"img/trpl14-04.png\" class=\"center\" />\n\n<span class=\"caption\">Figure 14-4: The front page of the documentation for `art`\nthat lists the re-exports</span>\n\nThe `art` crate users can still see and use the internal structure from Listing\n14-3 as demonstrated in Listing 14-4, or they can use the more convenient\nstructure in Listing 14-5, as shown in Listing 14-6:\n\n<span class=\"filename\">Filename: src/main.rs</span>\n\n```rust,ignore\n{{#rustdoc_include ../listings/ch14-more-about-cargo/listing-14-06/src/main.rs:here}}\n```\n\n<span class=\"caption\">Listing 14-6: A program using the re-exported items from\nthe `art` crate</span>\n\nIn cases where there are many nested modules, re-exporting the types at the top\nlevel with `pub use` can make a significant difference in the experience of\npeople who use the crate. Another common use of `pub use` is to re-export\ndefinitions of a dependency in the current crate to make that crate's\ndefinitions part of your crate’s public API.\n\nCreating a useful public API structure is more of an art than a science, and\nyou can iterate to find the API that works best for your users. Choosing `pub\nuse` gives you flexibility in how you structure your crate internally and\ndecouples that internal structure from what you present to your users. Look at\nsome of the code of crates you’ve installed to see if their internal structure\ndiffers from their public API.\n\n### Setting Up a Crates.io Account\n\nBefore you can publish any crates, you need to create an account on\n[crates.io](https://crates.io/)<!-- ignore --> and get an API token. To do so,\nvisit the home page at [crates.io](https://crates.io/)<!-- ignore --> and log\nin via a GitHub account. (The GitHub account is currently a requirement, but\nthe site might support other ways of creating an account in the future.) Once\nyou’re logged in, visit your account settings at\n[https://crates.io/me/](https://crates.io/me/)<!-- ignore --> and retrieve your\nAPI key. Then run the `cargo login` command with your API key, like this:\n\n```console\n$ cargo login abcdefghijklmnopqrstuvwxyz012345\n```\n\nThis command will inform Cargo of your API token and store it locally in\n*~/.cargo/credentials*. Note that this token is a *secret*: do not share it\nwith anyone else. If you do share it with anyone for any reason, you should\nrevoke it and generate a new token on [crates.io](https://crates.io/)<!-- ignore\n-->.\n\n### Adding Metadata to a New Crate\n\nLet’s say you have a crate you want to publish. Before publishing, you’ll need\nto add some metadata in the `[package]` section of the crate’s *Cargo.toml*\nfile.\n\nYour crate will need a unique name. While you’re working on a crate locally,\nyou can name a crate whatever you’d like. However, crate names on\n[crates.io](https://crates.io/)<!-- ignore --> are allocated on a first-come,\nfirst-served basis. Once a crate name is taken, no one else can publish a crate\nwith that name. Before attempting to publish a crate, search for the name you\nwant to use. If the name has been used, you will need to find another name and\nedit the `name` field in the *Cargo.toml* file under the `[package]` section to\nuse the new name for publishing, like so:\n\n<span class=\"filename\">Filename: Cargo.toml</span>\n\n```toml\n[package]\nname = \"guessing_game\"\n```\n\nEven if you’ve chosen a unique name, when you run `cargo publish` to publish\nthe crate at this point, you’ll get a warning and then an error:\n\n<!-- manual-regeneration\ncd listings/ch14-more-about-cargo/listing-14-01/\ncargo publish\ncopy just the relevant lines below\n-->\n\n```console\n$ cargo publish\n    Updating crates.io index\nwarning: manifest has no description, license, license-file, documentation, homepage or repository.\nSee https://doc.rust-lang.org/cargo/reference/manifest.html#package-metadata for more info.\n--snip--\nerror: failed to publish to registry at https://crates.io\n\nCaused by:\n  the remote server responded with an error: missing or empty metadata fields: description, license. Please see https://doc.rust-lang.org/cargo/reference/manifest.html for how to upload metadata\n```\n\nThis errors because you’re missing some crucial information: a description and\nlicense are required so people will know what your crate does and under what\nterms they can use it. In *Cargo.toml*, add a description that's just a\nsentence or two, because it will appear with your crate in search results. For\nthe `license` field, you need to give a *license identifier value*. The [Linux\nFoundation’s Software Package Data Exchange (SPDX)][spdx] lists the identifiers\nyou can use for this value. For example, to specify that you’ve licensed your\ncrate using the MIT License, add the `MIT` identifier:\n\n<span class=\"filename\">Filename: Cargo.toml</span>\n\n```toml\n[package]\nname = \"guessing_game\"\nlicense = \"MIT\"\n```\n\nIf you want to use a license that doesn’t appear in the SPDX, you need to place\nthe text of that license in a file, include the file in your project, and then\nuse `license-file` to specify the name of that file instead of using the\n`license` key.\n\nGuidance on which license is appropriate for your project is beyond the scope\nof this book. Many people in the Rust community license their projects in the\nsame way as Rust by using a dual license of `MIT OR Apache-2.0`. This practice\ndemonstrates that you can also specify multiple license identifiers separated\nby `OR` to have multiple licenses for your project.\n\nWith a unique name, the version, your description, and a license added, the\n*Cargo.toml* file for a project that is ready to publish might look like this:\n\n<span class=\"filename\">Filename: Cargo.toml</span>\n\n```toml\n[package]\nname = \"guessing_game\"\nversion = \"0.1.0\"\nedition = \"2021\"\ndescription = \"A fun game where you guess what number the computer has chosen.\"\nlicense = \"MIT OR Apache-2.0\"\n\n[dependencies]\n```\n\n[Cargo’s documentation](https://doc.rust-lang.org/cargo/) describes other\nmetadata you can specify to ensure others can discover and use your crate more\neasily.\n\n### Publishing to Crates.io\n\nNow that you’ve created an account, saved your API token, chosen a name for\nyour crate, and specified the required metadata, you’re ready to publish!\nPublishing a crate uploads a specific version to\n[crates.io](https://crates.io/)<!-- ignore --> for others to use.\n\nBe careful, because a publish is *permanent*. The version can never be\noverwritten, and the code cannot be deleted. One major goal of\n[crates.io](https://crates.io/)<!-- ignore --> is to act as a permanent archive\nof code so that builds of all projects that depend on crates from\n[crates.io](https://crates.io/)<!-- ignore --> will continue to work. Allowing\nversion deletions would make fulfilling that goal impossible. However, there is\nno limit to the number of crate versions you can publish.\n\nRun the `cargo publish` command again. It should succeed now:\n\n<!-- manual-regeneration\ngo to some valid crate, publish a new version\ncargo publish\ncopy just the relevant lines below\n-->\n\n```console\n$ cargo publish\n    Updating crates.io index\n   Packaging guessing_game v0.1.0 (file:///projects/guessing_game)\n   Verifying guessing_game v0.1.0 (file:///projects/guessing_game)\n   Compiling guessing_game v0.1.0\n(file:///projects/guessing_game/target/package/guessing_game-0.1.0)\n    Finished dev [unoptimized + debuginfo] target(s) in 0.19s\n   Uploading guessing_game v0.1.0 (file:///projects/guessing_game)\n```\n\nCongratulations! You’ve now shared your code with the Rust community, and\nanyone can easily add your crate as a dependency of their project.\n\n### Publishing a New Version of an Existing Crate\n\nWhen you’ve made changes to your crate and are ready to release a new version,\nyou change the `version` value specified in your *Cargo.toml* file and\nrepublish. Use the [Semantic Versioning rules][semver] to decide what an\nappropriate next version number is based on the kinds of changes you’ve made.\nThen run `cargo publish` to upload the new version.\n\n<!-- Old link, do not remove -->\n<a id=\"removing-versions-from-cratesio-with-cargo-yank\"></a>\n\n### Deprecating Versions from Crates.io with `cargo yank`\n\nAlthough you can’t remove previous versions of a crate, you can prevent any\nfuture projects from adding them as a new dependency. This is useful when a\ncrate version is broken for one reason or another. In such situations, Cargo\nsupports *yanking* a crate version.\n\nYanking a version prevents new projects from depending on that version while\nallowing all existing projects that depend on it to continue. Essentially, a\nyank means that all projects with a *Cargo.lock* will not break, and any future\n*Cargo.lock* files generated will not use the yanked version.\n\nTo yank a version of a crate, in the directory of the crate that you’ve\npreviously published, run `cargo yank` and specify which version you want to\nyank. For example, if we've published a crate named `guessing_game` version\n1.0.1 and we want to yank it, in the project directory for `guessing_game` we'd\nrun:\n\n<!-- manual-regeneration:\ncargo yank carol-test --version 2.1.0\ncargo yank carol-test --version 2.1.0 --undo\n-->\n\n```console\n$ cargo yank --vers 1.0.1\n    Updating crates.io index\n        Yank guessing_game@1.0.1\n```\n\nBy adding `--undo` to the command, you can also undo a yank and allow projects\nto start depending on a version again:\n\n```console\n$ cargo yank --vers 1.0.1 --undo\n    Updating crates.io index\n      Unyank guessing_game@1.0.1\n```\n\nA yank *does not* delete any code. It cannot, for example, delete accidentally\nuploaded secrets. If that happens, you must reset those secrets immediately.\n\n[spdx]: http://spdx.org/licenses/\n[semver]: http://semver.org/\n",
          "document_id": 69
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "What is workspace?",
              "id": 21,
              "answers": [
                {
                  "answer_id": 21,
                  "document_id": 70,
                  "question_id": 21,
                  "text": "A *workspace* is a set of packages that share the same *Cargo.lock* and output\ndirectory.",
                  "answer_start": 413,
                  "answer_end": 502,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "How to build workspace?",
              "id": 22,
              "answers": [
                {
                  "answer_id": 22,
                  "document_id": 70,
                  "question_id": 22,
                  "text": "we can build the workspace by running `cargo build`",
                  "answer_start": 1956,
                  "answer_end": 2007,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "Where are compiled artifacts?",
              "id": 23,
              "answers": [
                {
                  "answer_id": 23,
                  "document_id": 70,
                  "question_id": 23,
                  "text": "The workspace has one *target* directory at the top level that the compiled\nartifacts will be placed into",
                  "answer_start": 2182,
                  "answer_end": 2287,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "How many cargo.lock files are in workspace?",
              "id": 136,
              "answers": [
                {
                  "answer_id": 136,
                  "document_id": 70,
                  "question_id": 136,
                  "text": "the workspace has only one *Cargo.lock* file at the top level,\nrather than having a *Cargo.lock* in each crate’s directory",
                  "answer_start": 6325,
                  "answer_end": 6447,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "How to specify crate for running tests?",
              "id": 137,
              "answers": [
                {
                  "answer_id": 137,
                  "document_id": 70,
                  "question_id": 137,
                  "text": "We can also run tests for one particular crate in a workspace from the\ntop-level directory by using the `-p` flag and specifying the name of the crate\nwe want to test",
                  "answer_start": 11414,
                  "answer_end": 11580,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "How to specify which crate to publish?",
              "id": 138,
              "answers": [
                {
                  "answer_id": 138,
                  "document_id": 70,
                  "question_id": 138,
                  "text": "we can publish a particular crate in our workspace by using the `-p`\nflag and specifying the name of the crate we want to publish",
                  "answer_start": 12536,
                  "answer_end": 12665,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "## Cargo Workspaces\n\nIn Chapter 12, we built a package that included a binary crate and a library\ncrate. As your project develops, you might find that the library crate\ncontinues to get bigger and you want to split your package further into\nmultiple library crates. Cargo offers a feature called *workspaces* that can\nhelp manage multiple related packages that are developed in tandem.\n\n### Creating a Workspace\n\nA *workspace* is a set of packages that share the same *Cargo.lock* and output\ndirectory. Let’s make a project using a workspace—we’ll use trivial code so we\ncan concentrate on the structure of the workspace. There are multiple ways to\nstructure a workspace, so we'll just show one common way. We’ll have a\nworkspace containing a binary and two libraries. The binary, which will provide\nthe main functionality, will depend on the two libraries. One library will\nprovide an `add_one` function, and a second library an `add_two` function.\nThese three crates will be part of the same workspace. We’ll start by creating\na new directory for the workspace:\n\n```console\n$ mkdir add\n$ cd add\n```\n\nNext, in the *add* directory, we create the *Cargo.toml* file that will\nconfigure the entire workspace. This file won’t have a `[package]` section.\nInstead, it will start with a `[workspace]` section that will allow us to add\nmembers to the workspace by specifying the path to the package with our binary\ncrate; in this case, that path is *adder*:\n\n<span class=\"filename\">Filename: Cargo.toml</span>\n\n```toml\n{{#include ../listings/ch14-more-about-cargo/no-listing-01-workspace-with-adder-crate/add/Cargo.toml}}\n```\n\nNext, we’ll create the `adder` binary crate by running `cargo new` within the\n*add* directory:\n\n<!-- manual-regeneration\ncd listings/ch14-more-about-cargo/output-only-01-adder-crate/add\nrm -rf adder\ncargo new adder\ncopy output below\n-->\n\n```console\n$ cargo new adder\n     Created binary (application) `adder` package\n```\n\nAt this point, we can build the workspace by running `cargo build`. The files\nin your *add* directory should look like this:\n\n```text\n├── Cargo.lock\n├── Cargo.toml\n├── adder\n│   ├── Cargo.toml\n│   └── src\n│       └── main.rs\n└── target\n```\n\nThe workspace has one *target* directory at the top level that the compiled\nartifacts will be placed into; the `adder` package doesn’t have its own\n*target* directory. Even if we were to run `cargo build` from inside the\n*adder* directory, the compiled artifacts would still end up in *add/target*\nrather than *add/adder/target*. Cargo structures the *target* directory in a\nworkspace like this because the crates in a workspace are meant to depend on\neach other. If each crate had its own *target* directory, each crate would have\nto recompile each of the other crates in the workspace to place the artifacts\nin its own *target* directory. By sharing one *target* directory, the crates\ncan avoid unnecessary rebuilding.\n\n### Creating the Second Package in the Workspace\n\nNext, let’s create another member package in the workspace and call it\n`add_one`. Change the top-level *Cargo.toml* to specify the *add_one* path in\nthe `members` list:\n\n<span class=\"filename\">Filename: Cargo.toml</span>\n\n```toml\n{{#include ../listings/ch14-more-about-cargo/no-listing-02-workspace-with-two-crates/add/Cargo.toml}}\n```\n\nThen generate a new library crate named `add_one`:\n\n<!-- manual-regeneration\ncd listings/ch14-more-about-cargo/output-only-02-add-one/add\nrm -rf add_one\ncargo new add_one --lib\ncopy output below\n-->\n\n```console\n$ cargo new add_one --lib\n     Created library `add_one` package\n```\n\nYour *add* directory should now have these directories and files:\n\n```text\n├── Cargo.lock\n├── Cargo.toml\n├── add_one\n│   ├── Cargo.toml\n│   └── src\n│       └── lib.rs\n├── adder\n│   ├── Cargo.toml\n│   └── src\n│       └── main.rs\n└── target\n```\n\nIn the *add_one/src/lib.rs* file, let’s add an `add_one` function:\n\n<span class=\"filename\">Filename: add_one/src/lib.rs</span>\n\n```rust,noplayground\n{{#rustdoc_include ../listings/ch14-more-about-cargo/no-listing-02-workspace-with-two-crates/add/add_one/src/lib.rs}}\n```\n\nNow we can have the `adder` package with our binary depend on the `add_one`\npackage that has our library. First, we’ll need to add a path dependency on\n`add_one` to *adder/Cargo.toml*.\n\n<span class=\"filename\">Filename: adder/Cargo.toml</span>\n\n```toml\n{{#include ../listings/ch14-more-about-cargo/no-listing-02-workspace-with-two-crates/add/adder/Cargo.toml:6:7}}\n```\n\nCargo doesn’t assume that crates in a workspace will depend on each other, so\nwe need to be explicit about the dependency relationships.\n\nNext, let’s use the `add_one` function (from the `add_one` crate) in the\n`adder` crate. Open the *adder/src/main.rs* file and add a `use` line at the\ntop to bring the new `add_one` library crate into scope. Then change the `main`\nfunction to call the `add_one` function, as in Listing 14-7.\n\n<span class=\"filename\">Filename: adder/src/main.rs</span>\n\n```rust,ignore\n{{#rustdoc_include ../listings/ch14-more-about-cargo/listing-14-07/add/adder/src/main.rs}}\n```\n\n<span class=\"caption\">Listing 14-7: Using the `add_one` library crate from the\n `adder` crate</span>\n\nLet’s build the workspace by running `cargo build` in the top-level *add*\ndirectory!\n\n<!-- manual-regeneration\ncd listings/ch14-more-about-cargo/listing-14-07/add\ncargo build\ncopy output below; the output updating script doesn't handle subdirectories in paths properly\n-->\n\n```console\n$ cargo build\n   Compiling add_one v0.1.0 (file:///projects/add/add_one)\n   Compiling adder v0.1.0 (file:///projects/add/adder)\n    Finished dev [unoptimized + debuginfo] target(s) in 0.68s\n```\n\nTo run the binary crate from the *add* directory, we can specify which\npackage in the workspace we want to run by using the `-p` argument and the\npackage name with `cargo run`:\n\n<!-- manual-regeneration\ncd listings/ch14-more-about-cargo/listing-14-07/add\ncargo run -p adder\ncopy output below; the output updating script doesn't handle subdirectories in paths properly\n-->\n\n```console\n$ cargo run -p adder\n    Finished dev [unoptimized + debuginfo] target(s) in 0.0s\n     Running `target/debug/adder`\nHello, world! 10 plus one is 11!\n```\n\nThis runs the code in *adder/src/main.rs*, which depends on the `add_one` crate.\n\n#### Depending on an External Package in a Workspace\n\nNotice that the workspace has only one *Cargo.lock* file at the top level,\nrather than having a *Cargo.lock* in each crate’s directory. This ensures that\nall crates are using the same version of all dependencies. If we add the `rand`\npackage to the *adder/Cargo.toml* and *add_one/Cargo.toml* files, Cargo will\nresolve both of those to one version of `rand` and record that in the one\n*Cargo.lock*. Making all crates in the workspace use the same dependencies\nmeans the crates will always be compatible with each other. Let’s add the\n`rand` crate to the `[dependencies]` section in the *add_one/Cargo.toml* file\nso we can use the `rand` crate in the `add_one` crate:\n\n<!-- When updating the version of `rand` used, also update the version of\n`rand` used in these files so they all match:\n* ch02-00-guessing-game-tutorial.md\n* ch07-04-bringing-paths-into-scope-with-the-use-keyword.md\n-->\n\n<span class=\"filename\">Filename: add_one/Cargo.toml</span>\n\n```toml\n{{#include ../listings/ch14-more-about-cargo/no-listing-03-workspace-with-external-dependency/add/add_one/Cargo.toml:6:7}}\n```\n\nWe can now add `use rand;` to the *add_one/src/lib.rs* file, and building the\nwhole workspace by running `cargo build` in the *add* directory will bring in\nand compile the `rand` crate. We will get one warning because we aren’t\nreferring to the `rand` we brought into scope:\n\n<!-- manual-regeneration\ncd listings/ch14-more-about-cargo/no-listing-03-workspace-with-external-dependency/add\ncargo build\ncopy output below; the output updating script doesn't handle subdirectories in paths properly\n-->\n\n```console\n$ cargo build\n    Updating crates.io index\n  Downloaded rand v0.8.5\n   --snip--\n   Compiling rand v0.8.5\n   Compiling add_one v0.1.0 (file:///projects/add/add_one)\nwarning: unused import: `rand`\n --> add_one/src/lib.rs:1:5\n  |\n1 | use rand;\n  |     ^^^^\n  |\n  = note: `#[warn(unused_imports)]` on by default\n\nwarning: `add_one` (lib) generated 1 warning\n   Compiling adder v0.1.0 (file:///projects/add/adder)\n    Finished dev [unoptimized + debuginfo] target(s) in 10.18s\n```\n\nThe top-level *Cargo.lock* now contains information about the dependency of\n`add_one` on `rand`. However, even though `rand` is used somewhere in the\nworkspace, we can’t use it in other crates in the workspace unless we add\n`rand` to their *Cargo.toml* files as well. For example, if we add `use rand;`\nto the *adder/src/main.rs* file for the `adder` package, we’ll get an error:\n\n<!-- manual-regeneration\ncd listings/ch14-more-about-cargo/output-only-03-use-rand/add\ncargo build\ncopy output below; the output updating script doesn't handle subdirectories in paths properly\n-->\n\n```console\n$ cargo build\n  --snip--\n   Compiling adder v0.1.0 (file:///projects/add/adder)\nerror[E0432]: unresolved import `rand`\n --> adder/src/main.rs:2:5\n  |\n2 | use rand;\n  |     ^^^^ no external crate `rand`\n```\n\nTo fix this, edit the *Cargo.toml* file for the `adder` package and indicate\nthat `rand` is a dependency for it as well. Building the `adder` package will\nadd `rand` to the list of dependencies for `adder` in *Cargo.lock*, but no\nadditional copies of `rand` will be downloaded. Cargo has ensured that every\ncrate in every package in the workspace using the `rand` package will be using\nthe same version, saving us space and ensuring that the crates in the workspace\nwill be compatible with each other.\n\n#### Adding a Test to a Workspace\n\nFor another enhancement, let’s add a test of the `add_one::add_one` function\nwithin the `add_one` crate:\n\n<span class=\"filename\">Filename: add_one/src/lib.rs</span>\n\n```rust,noplayground\n{{#rustdoc_include ../listings/ch14-more-about-cargo/no-listing-04-workspace-with-tests/add/add_one/src/lib.rs}}\n```\n\nNow run `cargo test` in the top-level *add* directory. Running `cargo test` in\na workspace structured like this one will run the tests for all the crates in\nthe workspace:\n\n<!-- manual-regeneration\ncd listings/ch14-more-about-cargo/no-listing-04-workspace-with-tests/add\ncargo test\ncopy output below; the output updating script doesn't handle subdirectories in\npaths properly\n-->\n\n```console\n$ cargo test\n   Compiling add_one v0.1.0 (file:///projects/add/add_one)\n   Compiling adder v0.1.0 (file:///projects/add/adder)\n    Finished test [unoptimized + debuginfo] target(s) in 0.27s\n     Running unittests src/lib.rs (target/debug/deps/add_one-f0253159197f7841)\n\nrunning 1 test\ntest tests::it_works ... ok\n\ntest result: ok. 1 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.00s\n\n     Running unittests src/main.rs (target/debug/deps/adder-49979ff40686fa8e)\n\nrunning 0 tests\n\ntest result: ok. 0 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.00s\n\n   Doc-tests add_one\n\nrunning 0 tests\n\ntest result: ok. 0 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.00s\n```\n\nThe first section of the output shows that the `it_works` test in the `add_one`\ncrate passed. The next section shows that zero tests were found in the `adder`\ncrate, and then the last section shows zero documentation tests were found in\nthe `add_one` crate.\n\nWe can also run tests for one particular crate in a workspace from the\ntop-level directory by using the `-p` flag and specifying the name of the crate\nwe want to test:\n\n<!-- manual-regeneration\ncd listings/ch14-more-about-cargo/no-listing-04-workspace-with-tests/add\ncargo test -p add_one\ncopy output below; the output updating script doesn't handle subdirectories in paths properly\n-->\n\n```console\n$ cargo test -p add_one\n    Finished test [unoptimized + debuginfo] target(s) in 0.00s\n     Running unittests src/lib.rs (target/debug/deps/add_one-b3235fea9a156f74)\n\nrunning 1 test\ntest tests::it_works ... ok\n\ntest result: ok. 1 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.00s\n\n   Doc-tests add_one\n\nrunning 0 tests\n\ntest result: ok. 0 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.00s\n```\n\nThis output shows `cargo test` only ran the tests for the `add_one` crate and\ndidn’t run the `adder` crate tests.\n\nIf you publish the crates in the workspace to [crates.io](https://crates.io/),\neach crate in the workspace will need to be published separately. Like `cargo\ntest`, we can publish a particular crate in our workspace by using the `-p`\nflag and specifying the name of the crate we want to publish.\n\nFor additional practice, add an `add_two` crate to this workspace in a similar\nway as the `add_one` crate!\n\nAs your project grows, consider using a workspace: it’s easier to understand\nsmaller, individual components than one big blob of code. Furthermore, keeping\nthe crates in a workspace can make coordination between crates easier if they\nare often changed at the same time.\n",
          "document_id": 70
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "What does cargo install do?",
              "id": 26,
              "answers": [
                {
                  "answer_id": 26,
                  "document_id": 71,
                  "question_id": 26,
                  "text": "v",
                  "answer_start": 26,
                  "answer_end": 27,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "How to install a crate?",
              "id": 139,
              "answers": [
                {
                  "answer_id": 139,
                  "document_id": 71,
                  "question_id": 139,
                  "text": "$ cargo install ripgrep",
                  "answer_start": 1475,
                  "answer_end": 1498,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "Where are installed crates stored?",
              "id": 140,
              "answers": [
                {
                  "answer_id": 140,
                  "document_id": 71,
                  "question_id": 140,
                  "text": "All binaries installed with `cargo install` are stored in the installation\nroot’s *bin* folder.",
                  "answer_start": 857,
                  "answer_end": 952,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "<!-- Old link, do not remove -->\n<a id=\"installing-binaries-from-cratesio-with-cargo-install\"></a>\n\n## Installing Binaries with `cargo install`\n\nThe `cargo install` command allows you to install and use binary crates\nlocally. This isn’t intended to replace system packages; it’s meant to be a\nconvenient way for Rust developers to install tools that others have shared on\n[crates.io](https://crates.io/)<!-- ignore -->. Note that you can only install\npackages that have binary targets. A *binary target* is the runnable program\nthat is created if the crate has a *src/main.rs* file or another file specified\nas a binary, as opposed to a library target that isn’t runnable on its own but\nis suitable for including within other programs. Usually, crates have\ninformation in the *README* file about whether a crate is a library, has a\nbinary target, or both.\n\nAll binaries installed with `cargo install` are stored in the installation\nroot’s *bin* folder. If you installed Rust using *rustup.rs* and don’t have any\ncustom configurations, this directory will be *$HOME/.cargo/bin*. Ensure that\ndirectory is in your `$PATH` to be able to run programs you’ve installed with\n`cargo install`.\n\nFor example, in Chapter 12 we mentioned that there’s a Rust implementation of\nthe `grep` tool called `ripgrep` for searching files. To install `ripgrep`, we\ncan run the following:\n\n<!-- manual-regeneration\ncargo install something you don't have, copy relevant output below\n-->\n\n```console\n$ cargo install ripgrep\n    Updating crates.io index\n  Downloaded ripgrep v13.0.0\n  Downloaded 1 crate (243.3 KB) in 0.88s\n  Installing ripgrep v13.0.0\n--snip--\n   Compiling ripgrep v13.0.0\n    Finished release [optimized + debuginfo] target(s) in 3m 10s\n  Installing ~/.cargo/bin/rg\n   Installed package `ripgrep v13.0.0` (executable `rg`)\n```\n\nThe second-to-last line of the output shows the location and the name of the\ninstalled binary, which in the case of `ripgrep` is `rg`. As long as the\ninstallation directory is in your `$PATH`, as mentioned previously, you can\nthen run `rg --help` and start using a faster, rustier tool for searching files!\n",
          "document_id": 71
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "How to add custom command?",
              "id": 27,
              "answers": [
                {
                  "answer_id": 27,
                  "document_id": 72,
                  "question_id": 27,
                  "text": "Cargo is designed so you can extend it with new subcommands without having to\nmodify Cargo. If a binary in your `$PATH` is named `cargo-something`, you can\nrun it as if it was a Cargo subcommand by running `cargo something`.",
                  "answer_start": 41,
                  "answer_end": 265,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "How crates differ from the standard library?",
              "id": 28,
              "answers": [
                {
                  "answer_id": 28,
                  "document_id": 72,
                  "question_id": 28,
                  "text": "Rust’s\nstandard library is small and stable, but crates are easy to share, use, and\nimprove on a timeline different from that of the language.",
                  "answer_start": 657,
                  "answer_end": 799,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "## Extending Cargo with Custom Commands\n\nCargo is designed so you can extend it with new subcommands without having to\nmodify Cargo. If a binary in your `$PATH` is named `cargo-something`, you can\nrun it as if it was a Cargo subcommand by running `cargo something`. Custom\ncommands like this are also listed when you run `cargo --list`. Being able to\nuse `cargo install` to install extensions and then run them just like the\nbuilt-in Cargo tools is a super convenient benefit of Cargo’s design!\n\n## Summary\n\nSharing code with Cargo and [crates.io](https://crates.io/)<!-- ignore --> is\npart of what makes the Rust ecosystem useful for many different tasks. Rust’s\nstandard library is small and stable, but crates are easy to share, use, and\nimprove on a timeline different from that of the language. Don’t be shy about\nsharing code that’s useful to you on [crates.io](https://crates.io/)<!-- ignore\n-->; it’s likely that it will be useful to someone else as well!\n",
          "document_id": 72
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "What is Box<T>?",
              "id": 29,
              "answers": [
                {
                  "answer_id": 29,
                  "document_id": 73,
                  "question_id": 29,
                  "text": "for allocating values on the heap",
                  "answer_start": 2610,
                  "answer_end": 2643,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What is Rc<T>?",
              "id": 30,
              "answers": [
                {
                  "answer_id": 30,
                  "document_id": 73,
                  "question_id": 30,
                  "text": "a reference counting type that enables multiple ownership",
                  "answer_start": 2655,
                  "answer_end": 2712,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What is RefCell<T>?",
              "id": 31,
              "answers": [
                {
                  "answer_id": 31,
                  "document_id": 73,
                  "question_id": 31,
                  "text": "a type that enforces\n  the borrowing rules at runtime instead of compile time",
                  "answer_start": 2772,
                  "answer_end": 2849,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What are typical smart pointer traits?",
              "id": 32,
              "answers": [
                {
                  "answer_id": 32,
                  "document_id": 73,
                  "question_id": 32,
                  "text": "smart pointers implement the `Deref` and `Drop` traits",
                  "answer_start": 1862,
                  "answer_end": 1916,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "How smart pointers differ from references?",
              "id": 33,
              "answers": [
                {
                  "answer_id": 33,
                  "document_id": 73,
                  "question_id": 33,
                  "text": "while references only borrow data, in\nmany cases, smart pointers *own* the data they point to",
                  "answer_start": 1237,
                  "answer_end": 1330,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What is smart pointer?",
              "id": 34,
              "answers": [
                {
                  "answer_id": 34,
                  "document_id": 73,
                  "question_id": 34,
                  "text": "*Smart pointers*, on the other hand, are data structures that act like a\npointer but also have additional metadata and capabilities.",
                  "answer_start": 426,
                  "answer_end": 558,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "# Smart Pointers\n\nA *pointer* is a general concept for a variable that contains an address in\nmemory. This address refers to, or “points at,” some other data. The most\ncommon kind of pointer in Rust is a reference, which you learned about in\nChapter 4. References are indicated by the `&` symbol and borrow the value they\npoint to. They don’t have any special capabilities other than referring to\ndata, and have no overhead.\n\n*Smart pointers*, on the other hand, are data structures that act like a\npointer but also have additional metadata and capabilities. The concept of\nsmart pointers isn’t unique to Rust: smart pointers originated in C++ and exist\nin other languages as well. Rust has a variety of smart pointers defined in the\nstandard library that provide functionality beyond that provided by references.\nTo explore the general concept, we’ll look at a couple of different examples of\nsmart pointers, including a *reference counting* smart pointer type. This\npointer enables you to allow data to have multiple owners by keeping track of\nthe number of owners and, when no owners remain, cleaning up the data.\n\nRust, with its concept of ownership and borrowing, has an additional difference\nbetween references and smart pointers: while references only borrow data, in\nmany cases, smart pointers *own* the data they point to.\n\nThough we didn’t call them as such at the time, we’ve already encountered a few\nsmart pointers in this book, including `String` and `Vec<T>` in Chapter 8. Both\nthese types count as smart pointers because they own some memory and allow you\nto manipulate it. They also have metadata and extra capabilities or guarantees.\n`String`, for example, stores its capacity as metadata and has the extra\nability to ensure its data will always be valid UTF-8.\n\nSmart pointers are usually implemented using structs. Unlike an ordinary\nstruct, smart pointers implement the `Deref` and `Drop` traits. The `Deref`\ntrait allows an instance of the smart pointer struct to behave like a reference\nso you can write your code to work with either references or smart pointers.\nThe `Drop` trait allows you to customize the code that’s run when an instance\nof the smart pointer goes out of scope. In this chapter, we’ll discuss both\ntraits and demonstrate why they’re important to smart pointers.\n\nGiven that the smart pointer pattern is a general design pattern used\nfrequently in Rust, this chapter won’t cover every existing smart pointer. Many\nlibraries have their own smart pointers, and you can even write your own. We’ll\ncover the most common smart pointers in the standard library:\n\n* `Box<T>` for allocating values on the heap\n* `Rc<T>`, a reference counting type that enables multiple ownership\n* `Ref<T>` and `RefMut<T>`, accessed through `RefCell<T>`, a type that enforces\n  the borrowing rules at runtime instead of compile time\n\nIn addition, we’ll cover the *interior mutability* pattern where an immutable\ntype exposes an API for mutating an interior value. We’ll also discuss\n*reference cycles*: how they can leak memory and how to prevent them.\n\nLet’s dive in!\n",
          "document_id": 73
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "Where does Box<T> store data?",
              "id": 35,
              "answers": [
                {
                  "answer_id": 35,
                  "document_id": 74,
                  "question_id": 35,
                  "text": "Boxes allow you to store data on the heap rather than the stack.",
                  "answer_start": 131,
                  "answer_end": 195,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "How to pass around large amounts of data?",
              "id": 36,
              "answers": [
                {
                  "answer_id": 36,
                  "document_id": 74,
                  "question_id": 36,
                  "text": "To improve performance in\nthis situation, we can store the large amount of data on the heap in a box.\nThen, only the small amount of pointer data is copied around on the stack,\nwhile the data it references stays in one place on the heap.",
                  "answer_start": 1241,
                  "answer_end": 1478,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "When boxed value gets deallocated?",
              "id": 37,
              "answers": [
                {
                  "answer_id": 37,
                  "document_id": 74,
                  "question_id": 37,
                  "text": "Just like any owned value, when a box goes out of\nscope, as `b` does at the end of `main`, it will be deallocated. The\ndeallocation happens both for the box (stored on the stack) and the data it\npoints to (stored on the heap).",
                  "answer_start": 2493,
                  "answer_end": 2719,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "How to create recursive data type?",
              "id": 38,
              "answers": [
                {
                  "answer_id": 38,
                  "document_id": 74,
                  "question_id": 38,
                  "text": "we can enable\nrecursive types by inserting a box in the recursive type definition",
                  "answer_start": 3491,
                  "answer_end": 3572,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What is the size of box?",
              "id": 39,
              "answers": [
                {
                  "answer_id": 39,
                  "document_id": 74,
                  "question_id": 39,
                  "text": "Because a `Box‹T>` is a pointer, Rust always knows how much space a `Box‹T>`\nneeds: a pointer’s size doesn’t change based on the amount of data it’s\npointing to",
                  "answer_start": 9649,
                  "answer_end": 9809,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "## Using `Box<T>` to Point to Data on the Heap\n\nThe most straightforward smart pointer is a *box*, whose type is written\n`Box<T>`. Boxes allow you to store data on the heap rather than the stack. What\nremains on the stack is the pointer to the heap data. Refer to Chapter 4 to\nreview the difference between the stack and the heap.\n\nBoxes don’t have performance overhead, other than storing their data on the\nheap instead of on the stack. But they don’t have many extra capabilities\neither. You’ll use them most often in these situations:\n\n* When you have a type whose size can’t be known at compile time and you want\n  to use a value of that type in a context that requires an exact size\n* When you have a large amount of data and you want to transfer ownership but\n  ensure the data won’t be copied when you do so\n* When you want to own a value and you care only that it’s a type that\n  implements a particular trait rather than being of a specific type\n\nWe’ll demonstrate the first situation in the [“Enabling Recursive Types with\nBoxes”](#enabling-recursive-types-with-boxes)<!-- ignore --> section. In the\nsecond case, transferring ownership of a large amount of data can take a long\ntime because the data is copied around on the stack. To improve performance in\nthis situation, we can store the large amount of data on the heap in a box.\nThen, only the small amount of pointer data is copied around on the stack,\nwhile the data it references stays in one place on the heap. The third case is\nknown as a *trait object*, and Chapter 17 devotes an entire section, [“Using\nTrait Objects That Allow for Values of Different Types,”][trait-objects]<!--\nignore --> just to that topic. So what you learn here you’ll apply again in\nChapter 17!\n\n### Using a `Box<T>` to Store Data on the Heap\n\nBefore we discuss the heap storage use case for `Box<T>`, we’ll cover the\nsyntax and how to interact with values stored within a `Box<T>`.\n\nListing 15-1 shows how to use a box to store an `i32` value on the heap:\n\n<span class=\"filename\">Filename: src/main.rs</span>\n\n```rust\n{{#rustdoc_include ../listings/ch15-smart-pointers/listing-15-01/src/main.rs}}\n```\n\n<span class=\"caption\">Listing 15-1: Storing an `i32` value on the heap using a\nbox</span>\n\nWe define the variable `b` to have the value of a `Box` that points to the\nvalue `5`, which is allocated on the heap. This program will print `b = 5`; in\nthis case, we can access the data in the box similar to how we would if this\ndata were on the stack. Just like any owned value, when a box goes out of\nscope, as `b` does at the end of `main`, it will be deallocated. The\ndeallocation happens both for the box (stored on the stack) and the data it\npoints to (stored on the heap).\n\nPutting a single value on the heap isn’t very useful, so you won’t use boxes by\nthemselves in this way very often. Having values like a single `i32` on the\nstack, where they’re stored by default, is more appropriate in the majority of\nsituations. Let’s look at a case where boxes allow us to define types that we\nwouldn’t be allowed to if we didn’t have boxes.\n\n### Enabling Recursive Types with Boxes\n\nA value of *recursive type* can have another value of the same type as part of\nitself. Recursive types pose an issue because at compile time Rust needs to\nknow how much space a type takes up. However, the nesting of values of\nrecursive types could theoretically continue infinitely, so Rust can’t know how\nmuch space the value needs. Because boxes have a known size, we can enable\nrecursive types by inserting a box in the recursive type definition.\n\nAs an example of a recursive type, let’s explore the *cons list*. This is a data\ntype commonly found in functional programming languages. The cons list type\nwe’ll define is straightforward except for the recursion; therefore, the\nconcepts in the example we’ll work with will be useful any time you get into\nmore complex situations involving recursive types.\n\n#### More Information About the Cons List\n\nA *cons list* is a data structure that comes from the Lisp programming language\nand its dialects and is made up of nested pairs, and is the Lisp version of a\nlinked list. Its name comes from the `cons` function (short for “construct\nfunction”) in Lisp that constructs a new pair from its two arguments. By\ncalling `cons` on a pair consisting of a value and another pair, we can\nconstruct cons lists made up of recursive pairs.\n\nFor example, here’s a pseudocode representation of a cons list containing the\nlist 1, 2, 3 with each pair in parentheses:\n\n```text\n(1, (2, (3, Nil)))\n```\n\nEach item in a cons list contains two elements: the value of the current item\nand the next item. The last item in the list contains only a value called `Nil`\nwithout a next item. A cons list is produced by recursively calling the `cons`\nfunction. The canonical name to denote the base case of the recursion is `Nil`.\nNote that this is not the same as the “null” or “nil” concept in Chapter 6,\nwhich is an invalid or absent value.\n\nThe cons list isn’t a commonly used data structure in Rust. Most of the time\nwhen you have a list of items in Rust, `Vec<T>` is a better choice to use.\nOther, more complex recursive data types *are* useful in various situations,\nbut by starting with the cons list in this chapter, we can explore how boxes\nlet us define a recursive data type without much distraction.\n\nListing 15-2 contains an enum definition for a cons list. Note that this code\nwon’t compile yet because the `List` type doesn’t have a known size, which\nwe’ll demonstrate.\n\n<span class=\"filename\">Filename: src/main.rs</span>\n\n```rust,ignore,does_not_compile\n{{#rustdoc_include ../listings/ch15-smart-pointers/listing-15-02/src/main.rs:here}}\n```\n\n<span class=\"caption\">Listing 15-2: The first attempt at defining an enum to\nrepresent a cons list data structure of `i32` values</span>\n\n> Note: We’re implementing a cons list that holds only `i32` values for the\n> purposes of this example. We could have implemented it using generics, as we\n> discussed in Chapter 10, to define a cons list type that could store values of\n> any type.\n\nUsing the `List` type to store the list `1, 2, 3` would look like the code in\nListing 15-3:\n\n<span class=\"filename\">Filename: src/main.rs</span>\n\n```rust,ignore,does_not_compile\n{{#rustdoc_include ../listings/ch15-smart-pointers/listing-15-03/src/main.rs:here}}\n```\n\n<span class=\"caption\">Listing 15-3: Using the `List` enum to store the list `1,\n2, 3`</span>\n\nThe first `Cons` value holds `1` and another `List` value. This `List` value is\nanother `Cons` value that holds `2` and another `List` value. This `List` value\nis one more `Cons` value that holds `3` and a `List` value, which is finally\n`Nil`, the non-recursive variant that signals the end of the list.\n\nIf we try to compile the code in Listing 15-3, we get the error shown in\nListing 15-4:\n\n```console\n{{#include ../listings/ch15-smart-pointers/listing-15-03/output.txt}}\n```\n\n<span class=\"caption\">Listing 15-4: The error we get when attempting to define\na recursive enum</span>\n\nThe error shows this type “has infinite size.” The reason is that we’ve defined\n`List` with a variant that is recursive: it holds another value of itself\ndirectly. As a result, Rust can’t figure out how much space it needs to store a\n`List` value. Let’s break down why we get this error. First, we’ll look at how\nRust decides how much space it needs to store a value of a non-recursive type.\n\n#### Computing the Size of a Non-Recursive Type\n\nRecall the `Message` enum we defined in Listing 6-2 when we discussed enum\ndefinitions in Chapter 6:\n\n```rust\n{{#rustdoc_include ../listings/ch06-enums-and-pattern-matching/listing-06-02/src/main.rs:here}}\n```\n\nTo determine how much space to allocate for a `Message` value, Rust goes\nthrough each of the variants to see which variant needs the most space. Rust\nsees that `Message::Quit` doesn’t need any space, `Message::Move` needs enough\nspace to store two `i32` values, and so forth. Because only one variant will be\nused, the most space a `Message` value will need is the space it would take to\nstore the largest of its variants.\n\nContrast this with what happens when Rust tries to determine how much space a\nrecursive type like the `List` enum in Listing 15-2 needs. The compiler starts\nby looking at the `Cons` variant, which holds a value of type `i32` and a value\nof type `List`. Therefore, `Cons` needs an amount of space equal to the size of\nan `i32` plus the size of a `List`. To figure out how much memory the `List`\ntype needs, the compiler looks at the variants, starting with the `Cons`\nvariant. The `Cons` variant holds a value of type `i32` and a value of type\n`List`, and this process continues infinitely, as shown in Figure 15-1.\n\n<img alt=\"An infinite Cons list\" src=\"img/trpl15-01.svg\" class=\"center\" style=\"width: 50%;\" />\n\n<span class=\"caption\">Figure 15-1: An infinite `List` consisting of infinite\n`Cons` variants</span>\n\n#### Using `Box<T>` to Get a Recursive Type with a Known Size\n\nBecause Rust can’t figure out how much space to allocate for recursively\ndefined types, the compiler gives an error with this helpful suggestion:\n\n<!-- manual-regeneration\nafter doing automatic regeneration, look at listings/ch15-smart-pointers/listing-15-03/output.txt and copy the relevant line\n-->\n\n```text\nhelp: insert some indirection (e.g., a `Box`, `Rc`, or `&`) to make `List` representable\n  |\n2 |     Cons(i32, Box<List>),\n  |               ++++    +\n```\n\nIn this suggestion, “indirection” means that instead of storing a value\ndirectly, we should change the data structure to store the value indirectly by\nstoring a pointer to the value instead.\n\nBecause a `Box<T>` is a pointer, Rust always knows how much space a `Box<T>`\nneeds: a pointer’s size doesn’t change based on the amount of data it’s\npointing to. This means we can put a `Box<T>` inside the `Cons` variant instead\nof another `List` value directly. The `Box<T>` will point to the next `List`\nvalue that will be on the heap rather than inside the `Cons` variant.\nConceptually, we still have a list, created with lists holding other lists, but\nthis implementation is now more like placing the items next to one another\nrather than inside one another.\n\nWe can change the definition of the `List` enum in Listing 15-2 and the usage\nof the `List` in Listing 15-3 to the code in Listing 15-5, which will compile:\n\n<span class=\"filename\">Filename: src/main.rs</span>\n\n```rust\n{{#rustdoc_include ../listings/ch15-smart-pointers/listing-15-05/src/main.rs}}\n```\n\n<span class=\"caption\">Listing 15-5: Definition of `List` that uses `Box<T>` in\norder to have a known size</span>\n\nThe `Cons` variant needs the size of an `i32` plus the space to store the\nbox’s pointer data. The `Nil` variant stores no values, so it needs less space\nthan the `Cons` variant. We now know that any `List` value will take up the\nsize of an `i32` plus the size of a box’s pointer data. By using a box, we’ve\nbroken the infinite, recursive chain, so the compiler can figure out the size\nit needs to store a `List` value. Figure 15-2 shows what the `Cons` variant\nlooks like now.\n\n<img alt=\"A finite Cons list\" src=\"img/trpl15-02.svg\" class=\"center\" />\n\n<span class=\"caption\">Figure 15-2: A `List` that is not infinitely sized\nbecause `Cons` holds a `Box`</span>\n\nBoxes provide only the indirection and heap allocation; they don’t have any\nother special capabilities, like those we’ll see with the other smart pointer\ntypes. They also don’t have the performance overhead that these special\ncapabilities incur, so they can be useful in cases like the cons list where the\nindirection is the only feature we need. We’ll look at more use cases for boxes\nin Chapter 17, too.\n\nThe `Box<T>` type is a smart pointer because it implements the `Deref` trait,\nwhich allows `Box<T>` values to be treated like references. When a `Box<T>`\nvalue goes out of scope, the heap data that the box is pointing to is cleaned\nup as well because of the `Drop` trait implementation. These two traits will be\neven more important to the functionality provided by the other smart pointer\ntypes we’ll discuss in the rest of this chapter. Let’s explore these two traits\nin more detail.\n\n[trait-objects]: ch17-02-trait-objects.html#using-trait-objects-that-allow-for-values-of-different-types\n",
          "document_id": 74
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "What is Deref?",
              "id": 40,
              "answers": [
                {
                  "answer_id": 40,
                  "document_id": 75,
                  "question_id": 40,
                  "text": "Implementing the `Deref` trait allows you to customize the behavior of the\n*dereference operator* `*`",
                  "answer_start": 75,
                  "answer_end": 176,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What method is needed to implement Deref?",
              "id": 41,
              "answers": [
                {
                  "answer_id": 41,
                  "document_id": 75,
                  "question_id": 41,
                  "text": "The `Deref` trait, provided\nby the standard library, requires us to implement one method named `deref` that\nborrows `self` and returns a reference to the inner data.",
                  "answer_start": 5836,
                  "answer_end": 6001,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What type X = SomeType means?",
              "id": 43,
              "answers": [
                {
                  "answer_id": 43,
                  "document_id": 75,
                  "question_id": 43,
                  "text": "The `type Target = T;` syntax defines an associated type for the `Deref`\ntrait to use. Associated types are a slightly different way of declaring a\ngeneric parameter",
                  "answer_start": 6322,
                  "answer_end": 6487,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What is Deref coercion?",
              "id": 44,
              "answers": [
                {
                  "answer_id": 44,
                  "document_id": 75,
                  "question_id": 44,
                  "text": "*Deref coercion* converts a reference to a type that implements the `Deref`\ntrait into a reference to another type.",
                  "answer_start": 8569,
                  "answer_end": 8684,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "How to use deref coercion?",
              "id": 45,
              "answers": [
                {
                  "answer_id": 45,
                  "document_id": 75,
                  "question_id": 45,
                  "text": "For example, deref coercion can convert\n`&String` to `&str` because `String` implements the `Deref` trait such that it\nreturns `&str`.",
                  "answer_start": 8685,
                  "answer_end": 8819,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "Why deref coercion is used?",
              "id": 46,
              "answers": [
                {
                  "answer_id": 46,
                  "document_id": 75,
                  "question_id": 46,
                  "text": "Deref coercion was added to Rust so that programmers writing function and\nmethod calls don’t need to add as many explicit references and dereferences\nwith `&` and `*`.",
                  "answer_start": 9265,
                  "answer_end": 9432,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "When deref coercion is done?",
              "id": 47,
              "answers": [
                {
                  "answer_id": 47,
                  "document_id": 75,
                  "question_id": 47,
                  "text": "Rust does deref coercion when it finds types and trait implementations in three\ncases:\n\n* From `&T` to `&U` when `T: Deref‹Target=U>`\n* From `&mut T` to `&mut U` when `T: DerefMut‹Target=U>`\n* From `&mut T` to `&U` when `T: Deref‹Target=U>`",
                  "answer_start": 12498,
                  "answer_end": 12738,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "Can immutable reference become mutable?",
              "id": 48,
              "answers": [
                {
                  "answer_id": 48,
                  "document_id": 75,
                  "question_id": 48,
                  "text": "immutable references will\nnever coerce to mutable references",
                  "answer_start": 13170,
                  "answer_end": 13230,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "## Treating Smart Pointers Like Regular References with the `Deref` Trait\n\nImplementing the `Deref` trait allows you to customize the behavior of the\n*dereference operator* `*` (not to be confused with the multiplication or glob\noperator). By implementing `Deref` in such a way that a smart pointer can be\ntreated like a regular reference, you can write code that operates on\nreferences and use that code with smart pointers too.\n\nLet’s first look at how the dereference operator works with regular references.\nThen we’ll try to define a custom type that behaves like `Box<T>`, and see why\nthe dereference operator doesn’t work like a reference on our newly defined\ntype. We’ll explore how implementing the `Deref` trait makes it possible for\nsmart pointers to work in ways similar to references. Then we’ll look at\nRust’s *deref coercion* feature and how it lets us work with either references\nor smart pointers.\n\n> Note: there’s one big difference between the `MyBox<T>` type we’re about to\n> build and the real `Box<T>`: our version will not store its data on the heap.\n> We are focusing this example on `Deref`, so where the data is actually stored\n> is less important than the pointer-like behavior.\n\n<!-- Old link, do not remove -->\n<a id=\"following-the-pointer-to-the-value-with-the-dereference-operator\"></a>\n\n### Following the Pointer to the Value\n\nA regular reference is a type of pointer, and one way to think of a pointer is\nas an arrow to a value stored somewhere else. In Listing 15-6, we create a\nreference to an `i32` value and then use the dereference operator to follow the\nreference to the value:\n\n<span class=\"filename\">Filename: src/main.rs</span>\n\n```rust\n{{#rustdoc_include ../listings/ch15-smart-pointers/listing-15-06/src/main.rs}}\n```\n\n<span class=\"caption\">Listing 15-6: Using the dereference operator to follow a\nreference to an `i32` value</span>\n\nThe variable `x` holds an `i32` value `5`. We set `y` equal to a reference to\n`x`. We can assert that `x` is equal to `5`. However, if we want to make an\nassertion about the value in `y`, we have to use `*y` to follow the reference\nto the value it’s pointing to (hence *dereference*) so the compiler can compare\nthe actual value. Once we dereference `y`, we have access to the integer value\n`y` is pointing to that we can compare with `5`.\n\nIf we tried to write `assert_eq!(5, y);` instead, we would get this compilation\nerror:\n\n```console\n{{#include ../listings/ch15-smart-pointers/output-only-01-comparing-to-reference/output.txt}}\n```\n\nComparing a number and a reference to a number isn’t allowed because they’re\ndifferent types. We must use the dereference operator to follow the reference\nto the value it’s pointing to.\n\n### Using `Box<T>` Like a Reference\n\nWe can rewrite the code in Listing 15-6 to use a `Box<T>` instead of a\nreference; the dereference operator used on the `Box<T>` in Listing 15-7\nfunctions in the same way as the dereference operator used on the reference in\nListing 15-6:\n\n<span class=\"filename\">Filename: src/main.rs</span>\n\n```rust\n{{#rustdoc_include ../listings/ch15-smart-pointers/listing-15-07/src/main.rs}}\n```\n\n<span class=\"caption\">Listing 15-7: Using the dereference operator on a\n`Box<i32>`</span>\n\nThe main difference between Listing 15-7 and Listing 15-6 is that here we set\n`y` to be an instance of a `Box<T>` pointing to a copied value of `x` rather\nthan a reference pointing to the value of `x`. In the last assertion, we can\nuse the dereference operator to follow the pointer of the `Box<T>` in the same\nway that we did when `y` was a reference. Next, we’ll explore what is special\nabout `Box<T>` that enables us to use the dereference operator by defining our\nown type.\n\n### Defining Our Own Smart Pointer\n\nLet’s build a smart pointer similar to the `Box<T>` type provided by the\nstandard library to experience how smart pointers behave differently from\nreferences by default. Then we’ll look at how to add the ability to use the\ndereference operator.\n\nThe `Box<T>` type is ultimately defined as a tuple struct with one element, so\nListing 15-8 defines a `MyBox<T>` type in the same way. We’ll also define a\n`new` function to match the `new` function defined on `Box<T>`.\n\n<span class=\"filename\">Filename: src/main.rs</span>\n\n```rust\n{{#rustdoc_include ../listings/ch15-smart-pointers/listing-15-08/src/main.rs:here}}\n```\n\n<span class=\"caption\">Listing 15-8: Defining a `MyBox<T>` type</span>\n\nWe define a struct named `MyBox` and declare a generic parameter `T`, because\nwe want our type to hold values of any type. The `MyBox` type is a tuple struct\nwith one element of type `T`. The `MyBox::new` function takes one parameter of\ntype `T` and returns a `MyBox` instance that holds the value passed in.\n\nLet’s try adding the `main` function in Listing 15-7 to Listing 15-8 and\nchanging it to use the `MyBox<T>` type we’ve defined instead of `Box<T>`. The\ncode in Listing 15-9 won’t compile because Rust doesn’t know how to dereference\n`MyBox`.\n\n<span class=\"filename\">Filename: src/main.rs</span>\n\n```rust,ignore,does_not_compile\n{{#rustdoc_include ../listings/ch15-smart-pointers/listing-15-09/src/main.rs:here}}\n```\n\n<span class=\"caption\">Listing 15-9: Attempting to use `MyBox<T>` in the same\nway we used references and `Box<T>`</span>\n\nHere’s the resulting compilation error:\n\n```console\n{{#include ../listings/ch15-smart-pointers/listing-15-09/output.txt}}\n```\n\nOur `MyBox<T>` type can’t be dereferenced because we haven’t implemented that\nability on our type. To enable dereferencing with the `*` operator, we\nimplement the `Deref` trait.\n\n### Treating a Type Like a Reference by Implementing the `Deref` Trait\n\nAs discussed in the [“Implementing a Trait on a Type”][impl-trait]<!-- ignore\n--> section of Chapter 10, to implement a trait, we need to provide\nimplementations for the trait’s required methods. The `Deref` trait, provided\nby the standard library, requires us to implement one method named `deref` that\nborrows `self` and returns a reference to the inner data. Listing 15-10\ncontains an implementation of `Deref` to add to the definition of `MyBox`:\n\n<span class=\"filename\">Filename: src/main.rs</span>\n\n```rust\n{{#rustdoc_include ../listings/ch15-smart-pointers/listing-15-10/src/main.rs:here}}\n```\n\n<span class=\"caption\">Listing 15-10: Implementing `Deref` on `MyBox<T>`</span>\n\nThe `type Target = T;` syntax defines an associated type for the `Deref`\ntrait to use. Associated types are a slightly different way of declaring a\ngeneric parameter, but you don’t need to worry about them for now; we’ll cover\nthem in more detail in Chapter 19.\n\nWe fill in the body of the `deref` method with `&self.0` so `deref` returns a\nreference to the value we want to access with the `*` operator; recall from the\n[“Using Tuple Structs without Named Fields to Create Different\nTypes”][tuple-structs]<!-- ignore --> section of Chapter 5 that `.0` accesses\nthe first value in a tuple struct. The `main` function in Listing 15-9 that\ncalls `*` on the `MyBox<T>` value now compiles, and the assertions pass!\n\nWithout the `Deref` trait, the compiler can only dereference `&` references.\nThe `deref` method gives the compiler the ability to take a value of any type\nthat implements `Deref` and call the `deref` method to get a `&` reference that\nit knows how to dereference.\n\nWhen we entered `*y` in Listing 15-9, behind the scenes Rust actually ran this\ncode:\n\n```rust,ignore\n*(y.deref())\n```\n\nRust substitutes the `*` operator with a call to the `deref` method and then a\nplain dereference so we don’t have to think about whether or not we need to\ncall the `deref` method. This Rust feature lets us write code that functions\nidentically whether we have a regular reference or a type that implements\n`Deref`.\n\nThe reason the `deref` method returns a reference to a value, and that the\nplain dereference outside the parentheses in `*(y.deref())` is still necessary,\nis to do with the ownership system. If the `deref` method returned the value\ndirectly instead of a reference to the value, the value would be moved out of\n`self`. We don’t want to take ownership of the inner value inside `MyBox<T>` in\nthis case or in most cases where we use the dereference operator.\n\nNote that the `*` operator is replaced with a call to the `deref` method and\nthen a call to the `*` operator just once, each time we use a `*` in our code.\nBecause the substitution of the `*` operator does not recurse infinitely, we\nend up with data of type `i32`, which matches the `5` in `assert_eq!` in\nListing 15-9.\n\n### Implicit Deref Coercions with Functions and Methods\n\n*Deref coercion* converts a reference to a type that implements the `Deref`\ntrait into a reference to another type. For example, deref coercion can convert\n`&String` to `&str` because `String` implements the `Deref` trait such that it\nreturns `&str`. Deref coercion is a convenience Rust performs on arguments to\nfunctions and methods, and works only on types that implement the `Deref`\ntrait. It happens automatically when we pass a reference to a particular type’s\nvalue as an argument to a function or method that doesn’t match the parameter\ntype in the function or method definition. A sequence of calls to the `deref`\nmethod converts the type we provided into the type the parameter needs.\n\nDeref coercion was added to Rust so that programmers writing function and\nmethod calls don’t need to add as many explicit references and dereferences\nwith `&` and `*`. The deref coercion feature also lets us write more code that\ncan work for either references or smart pointers.\n\nTo see deref coercion in action, let’s use the `MyBox<T>` type we defined in\nListing 15-8 as well as the implementation of `Deref` that we added in Listing\n15-10. Listing 15-11 shows the definition of a function that has a string slice\nparameter:\n\n<span class=\"filename\">Filename: src/main.rs</span>\n\n```rust\n{{#rustdoc_include ../listings/ch15-smart-pointers/listing-15-11/src/main.rs:here}}\n```\n\n<span class=\"caption\">Listing 15-11: A `hello` function that has the parameter\n`name` of type `&str`</span>\n\nWe can call the `hello` function with a string slice as an argument, such as\n`hello(\"Rust\");` for example. Deref coercion makes it possible to call `hello`\nwith a reference to a value of type `MyBox<String>`, as shown in Listing 15-12:\n\n<span class=\"filename\">Filename: src/main.rs</span>\n\n```rust\n{{#rustdoc_include ../listings/ch15-smart-pointers/listing-15-12/src/main.rs:here}}\n```\n\n<span class=\"caption\">Listing 15-12: Calling `hello` with a reference to a\n`MyBox<String>` value, which works because of deref coercion</span>\n\nHere we’re calling the `hello` function with the argument `&m`, which is a\nreference to a `MyBox<String>` value. Because we implemented the `Deref` trait\non `MyBox<T>` in Listing 15-10, Rust can turn `&MyBox<String>` into `&String`\nby calling `deref`. The standard library provides an implementation of `Deref`\non `String` that returns a string slice, and this is in the API documentation\nfor `Deref`. Rust calls `deref` again to turn the `&String` into `&str`, which\nmatches the `hello` function’s definition.\n\nIf Rust didn’t implement deref coercion, we would have to write the code in\nListing 15-13 instead of the code in Listing 15-12 to call `hello` with a value\nof type `&MyBox<String>`.\n\n<span class=\"filename\">Filename: src/main.rs</span>\n\n```rust\n{{#rustdoc_include ../listings/ch15-smart-pointers/listing-15-13/src/main.rs:here}}\n```\n\n<span class=\"caption\">Listing 15-13: The code we would have to write if Rust\ndidn’t have deref coercion</span>\n\nThe `(*m)` dereferences the `MyBox<String>` into a `String`. Then the `&` and\n`[..]` take a string slice of the `String` that is equal to the whole string to\nmatch the signature of `hello`. This code without deref coercions is harder to\nread, write, and understand with all of these symbols involved. Deref coercion\nallows Rust to handle these conversions for us automatically.\n\nWhen the `Deref` trait is defined for the types involved, Rust will analyze the\ntypes and use `Deref::deref` as many times as necessary to get a reference to\nmatch the parameter’s type. The number of times that `Deref::deref` needs to be\ninserted is resolved at compile time, so there is no runtime penalty for taking\nadvantage of deref coercion!\n\n### How Deref Coercion Interacts with Mutability\n\nSimilar to how you use the `Deref` trait to override the `*` operator on\nimmutable references, you can use the `DerefMut` trait to override the `*`\noperator on mutable references.\n\nRust does deref coercion when it finds types and trait implementations in three\ncases:\n\n* From `&T` to `&U` when `T: Deref<Target=U>`\n* From `&mut T` to `&mut U` when `T: DerefMut<Target=U>`\n* From `&mut T` to `&U` when `T: Deref<Target=U>`\n\nThe first two cases are the same as each other except that the second\nimplements mutability. The first case states that if you have a `&T`, and `T`\nimplements `Deref` to some type `U`, you can get a `&U` transparently. The\nsecond case states that the same deref coercion happens for mutable references.\n\nThe third case is trickier: Rust will also coerce a mutable reference to an\nimmutable one. But the reverse is *not* possible: immutable references will\nnever coerce to mutable references. Because of the borrowing rules, if you have\na mutable reference, that mutable reference must be the only reference to that\ndata (otherwise, the program wouldn’t compile). Converting one mutable\nreference to one immutable reference will never break the borrowing rules.\nConverting an immutable reference to a mutable reference would require that the\ninitial immutable reference is the only immutable reference to that data, but\nthe borrowing rules don’t guarantee that. Therefore, Rust can’t make the\nassumption that converting an immutable reference to a mutable reference is\npossible.\n\n[impl-trait]: ch10-02-traits.html#implementing-a-trait-on-a-type\n[tuple-structs]: ch05-01-defining-structs.html#using-tuple-structs-without-named-fields-to-create-different-types\n",
          "document_id": 75
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "How to create destructor?",
              "id": 49,
              "answers": [
                {
                  "answer_id": 49,
                  "document_id": 76,
                  "question_id": 49,
                  "text": "You specify the code to run when a value goes out of scope by implementing the\n`Drop` trait.",
                  "answer_start": 1210,
                  "answer_end": 1302,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What method does Drop need?",
              "id": 50,
              "answers": [
                {
                  "answer_id": 50,
                  "document_id": 76,
                  "question_id": 50,
                  "text": "The `Drop` trait requires you to implement one method named\n`drop` that takes a mutable reference to `self`.",
                  "answer_start": 1303,
                  "answer_end": 1411,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What should be included in drop method?",
              "id": 51,
              "answers": [
                {
                  "answer_id": 51,
                  "document_id": 76,
                  "question_id": 51,
                  "text": "The body of the\n`drop` function is where you would place any logic that you wanted to run when\nan instance of your type goes out of scope.",
                  "answer_start": 2224,
                  "answer_end": 2362,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "In what order are values dropped?",
              "id": 52,
              "answers": [
                {
                  "answer_id": 52,
                  "document_id": 76,
                  "question_id": 52,
                  "text": "Variables are dropped in the reverse order of\ntheir creation",
                  "answer_start": 3036,
                  "answer_end": 3096,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "How to force variable deletion?",
              "id": 53,
              "answers": [
                {
                  "answer_id": 53,
                  "document_id": 76,
                  "question_id": 53,
                  "text": "Rust doesn’t let you call the `Drop` trait’s `drop` method manually; instead\nyou have to call the `std::mem::drop` function provided by the standard library\nif you want to force a value to be dropped before the end of its scope.",
                  "answer_start": 3821,
                  "answer_end": 4049,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "How destructor is called in Rust?",
              "id": 54,
              "answers": [
                {
                  "answer_id": 54,
                  "document_id": 76,
                  "question_id": 54,
                  "text": "The `drop` function in Rust is one\nparticular destructor.",
                  "answer_start": 4946,
                  "answer_end": 5003,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What can be done with Drop trait?",
              "id": 55,
              "answers": [
                {
                  "answer_id": 55,
                  "document_id": 76,
                  "question_id": 55,
                  "text": "You can use code specified in a `Drop` trait implementation in many ways to\nmake cleanup convenient and safe: for instance, you could use it to create your\nown memory allocator!",
                  "answer_start": 6412,
                  "answer_end": 6589,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "## Running Code on Cleanup with the `Drop` Trait\n\nThe second trait important to the smart pointer pattern is `Drop`, which lets\nyou customize what happens when a value is about to go out of scope. You can\nprovide an implementation for the `Drop` trait on any type, and that code can\nbe used to release resources like files or network connections.\n\nWe’re introducing `Drop` in the context of smart pointers because the\nfunctionality of the `Drop` trait is almost always used when implementing a\nsmart pointer. For example, when a `Box<T>` is dropped it will deallocate the\nspace on the heap that the box points to.\n\nIn some languages, for some types, the programmer must call code to free memory\nor resources every time they finish using an instance of those types. Examples\ninclude file handles, sockets, or locks. If they forget, the system might\nbecome overloaded and crash. In Rust, you can specify that a particular bit of\ncode be run whenever a value goes out of scope, and the compiler will insert\nthis code automatically. As a result, you don’t need to be careful about\nplacing cleanup code everywhere in a program that an instance of a particular\ntype is finished with—you still won’t leak resources!\n\nYou specify the code to run when a value goes out of scope by implementing the\n`Drop` trait. The `Drop` trait requires you to implement one method named\n`drop` that takes a mutable reference to `self`. To see when Rust calls `drop`,\nlet’s implement `drop` with `println!` statements for now.\n\nListing 15-14 shows a `CustomSmartPointer` struct whose only custom\nfunctionality is that it will print `Dropping CustomSmartPointer!` when the\ninstance goes out of scope, to show when Rust runs the `drop` function.\n\n<span class=\"filename\">Filename: src/main.rs</span>\n\n```rust\n{{#rustdoc_include ../listings/ch15-smart-pointers/listing-15-14/src/main.rs}}\n```\n\n<span class=\"caption\">Listing 15-14: A `CustomSmartPointer` struct that\nimplements the `Drop` trait where we would put our cleanup code</span>\n\nThe `Drop` trait is included in the prelude, so we don’t need to bring it into\nscope. We implement the `Drop` trait on `CustomSmartPointer` and provide an\nimplementation for the `drop` method that calls `println!`. The body of the\n`drop` function is where you would place any logic that you wanted to run when\nan instance of your type goes out of scope. We’re printing some text here to\ndemonstrate visually when Rust will call `drop`.\n\nIn `main`, we create two instances of `CustomSmartPointer` and then print\n`CustomSmartPointers created`. At the end of `main`, our instances of\n`CustomSmartPointer` will go out of scope, and Rust will call the code we put\nin the `drop` method, printing our final message. Note that we didn’t need to\ncall the `drop` method explicitly.\n\nWhen we run this program, we’ll see the following output:\n\n```console\n{{#include ../listings/ch15-smart-pointers/listing-15-14/output.txt}}\n```\n\nRust automatically called `drop` for us when our instances went out of scope,\ncalling the code we specified. Variables are dropped in the reverse order of\ntheir creation, so `d` was dropped before `c`. This example’s purpose is to\ngive you a visual guide to how the `drop` method works; usually you would\nspecify the cleanup code that your type needs to run rather than a print\nmessage.\n\n### Dropping a Value Early with `std::mem::drop`\n\nUnfortunately, it’s not straightforward to disable the automatic `drop`\nfunctionality. Disabling `drop` isn’t usually necessary; the whole point of the\n`Drop` trait is that it’s taken care of automatically. Occasionally, however,\nyou might want to clean up a value early. One example is when using smart\npointers that manage locks: you might want to force the `drop` method that\nreleases the lock so that other code in the same scope can acquire the lock.\nRust doesn’t let you call the `Drop` trait’s `drop` method manually; instead\nyou have to call the `std::mem::drop` function provided by the standard library\nif you want to force a value to be dropped before the end of its scope.\n\nIf we try to call the `Drop` trait’s `drop` method manually by modifying the\n`main` function from Listing 15-14, as shown in Listing 15-15, we’ll get a\ncompiler error:\n\n<span class=\"filename\">Filename: src/main.rs</span>\n\n```rust,ignore,does_not_compile\n{{#rustdoc_include ../listings/ch15-smart-pointers/listing-15-15/src/main.rs:here}}\n```\n\n<span class=\"caption\">Listing 15-15: Attempting to call the `drop` method from\nthe `Drop` trait manually to clean up early</span>\n\nWhen we try to compile this code, we’ll get this error:\n\n```console\n{{#include ../listings/ch15-smart-pointers/listing-15-15/output.txt}}\n```\n\nThis error message states that we’re not allowed to explicitly call `drop`. The\nerror message uses the term *destructor*, which is the general programming term\nfor a function that cleans up an instance. A *destructor* is analogous to a\n*constructor*, which creates an instance. The `drop` function in Rust is one\nparticular destructor.\n\nRust doesn’t let us call `drop` explicitly because Rust would still\nautomatically call `drop` on the value at the end of `main`. This would cause a\n*double free* error because Rust would be trying to clean up the same value\ntwice.\n\nWe can’t disable the automatic insertion of `drop` when a value goes out of\nscope, and we can’t call the `drop` method explicitly. So, if we need to force\na value to be cleaned up early, we use the `std::mem::drop` function.\n\nThe `std::mem::drop` function is different from the `drop` method in the `Drop`\ntrait. We call it by passing as an argument the value we want to force drop.\nThe function is in the prelude, so we can modify `main` in Listing 15-15 to\ncall the `drop` function, as shown in Listing 15-16:\n\n<span class=\"filename\">Filename: src/main.rs</span>\n\n```rust\n{{#rustdoc_include ../listings/ch15-smart-pointers/listing-15-16/src/main.rs:here}}\n```\n\n<span class=\"caption\">Listing 15-16: Calling `std::mem::drop` to explicitly\ndrop a value before it goes out of scope</span>\n\nRunning this code will print the following:\n\n```console\n{{#include ../listings/ch15-smart-pointers/listing-15-16/output.txt}}\n```\n\nThe text ```Dropping CustomSmartPointer with data `some data`!``` is printed\nbetween the `CustomSmartPointer created.` and `CustomSmartPointer dropped\nbefore the end of main.` text, showing that the `drop` method code is called to\ndrop `c` at that point.\n\nYou can use code specified in a `Drop` trait implementation in many ways to\nmake cleanup convenient and safe: for instance, you could use it to create your\nown memory allocator! With the `Drop` trait and Rust’s ownership system, you\ndon’t have to remember to clean up because Rust does it automatically.\n\nYou also don’t have to worry about problems resulting from accidentally\ncleaning up values still in use: the ownership system that makes sure\nreferences are always valid also ensures that `drop` gets called only once when\nthe value is no longer being used.\n\nNow that we’ve examined `Box<T>` and some of the characteristics of smart\npointers, let’s look at a few other smart pointers defined in the standard\nlibrary.\n",
          "document_id": 76
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "Is multiple ownership possible?",
              "id": 56,
              "answers": [
                {
                  "answer_id": 56,
                  "document_id": 77,
                  "question_id": 56,
                  "text": "You have to enable multiple ownership explicitly by using the Rust type\n`Rc‹T>`",
                  "answer_start": 480,
                  "answer_end": 559,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "When to use Rc<T>?",
              "id": 57,
              "answers": [
                {
                  "answer_id": 57,
                  "document_id": 77,
                  "question_id": 57,
                  "text": "We use the `Rc‹T>` type when we want to allocate some data on the heap for\nmultiple parts of our program to read and we can’t determine at compile time\nwhich part will finish using the data last.",
                  "answer_start": 1202,
                  "answer_end": 1397,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "Can Rc<T> be used in multithreading?",
              "id": 58,
              "answers": [
                {
                  "answer_id": 58,
                  "document_id": 77,
                  "question_id": 58,
                  "text": "Note that `Rc‹T>` is only for use in single-threaded scenarios.",
                  "answer_start": 1562,
                  "answer_end": 1625,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What happens when Rc<T> is cloned?",
              "id": 59,
              "answers": [
                {
                  "answer_id": 59,
                  "document_id": 77,
                  "question_id": 59,
                  "text": "The call to `Rc::clone` only increments the\nreference count",
                  "answer_start": 5125,
                  "answer_end": 5184,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "How to get Rc's current reference count?",
              "id": 60,
              "answers": [
                {
                  "answer_id": 60,
                  "document_id": 77,
                  "question_id": 60,
                  "text": "we get by calling the `Rc::strong_count` function",
                  "answer_start": 6257,
                  "answer_end": 6306,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "Are Rc's values mutable?",
              "id": 61,
              "answers": [
                {
                  "answer_id": 61,
                  "document_id": 77,
                  "question_id": 61,
                  "text": "Via immutable references, `Rc‹T>` allows you to share data between multiple\nparts of your program for reading only.",
                  "answer_start": 7463,
                  "answer_end": 7578,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "## `Rc<T>`, the Reference Counted Smart Pointer\n\nIn the majority of cases, ownership is clear: you know exactly which variable\nowns a given value. However, there are cases when a single value might have\nmultiple owners. For example, in graph data structures, multiple edges might\npoint to the same node, and that node is conceptually owned by all of the edges\nthat point to it. A node shouldn’t be cleaned up unless it doesn’t have any\nedges pointing to it and so has no owners.\n\nYou have to enable multiple ownership explicitly by using the Rust type\n`Rc<T>`, which is an abbreviation for *reference counting*. The `Rc<T>` type\nkeeps track of the number of references to a value to determine whether or not\nthe value is still in use. If there are zero references to a value, the value\ncan be cleaned up without any references becoming invalid.\n\nImagine `Rc<T>` as a TV in a family room. When one person enters to watch TV,\nthey turn it on. Others can come into the room and watch the TV. When the last\nperson leaves the room, they turn off the TV because it’s no longer being used.\nIf someone turns off the TV while others are still watching it, there would be\nuproar from the remaining TV watchers!\n\nWe use the `Rc<T>` type when we want to allocate some data on the heap for\nmultiple parts of our program to read and we can’t determine at compile time\nwhich part will finish using the data last. If we knew which part would finish\nlast, we could just make that part the data’s owner, and the normal ownership\nrules enforced at compile time would take effect.\n\nNote that `Rc<T>` is only for use in single-threaded scenarios. When we discuss\nconcurrency in Chapter 16, we’ll cover how to do reference counting in\nmultithreaded programs.\n\n### Using `Rc<T>` to Share Data\n\nLet’s return to our cons list example in Listing 15-5. Recall that we defined\nit using `Box<T>`. This time, we’ll create two lists that both share ownership\nof a third list. Conceptually, this looks similar to Figure 15-3:\n\n<img alt=\"Two lists that share ownership of a third list\" src=\"img/trpl15-03.svg\" class=\"center\" />\n\n<span class=\"caption\">Figure 15-3: Two lists, `b` and `c`, sharing ownership of\na third list, `a`</span>\n\nWe’ll create list `a` that contains 5 and then 10. Then we’ll make two more\nlists: `b` that starts with 3 and `c` that starts with 4. Both `b` and `c`\nlists will then continue on to the first `a` list containing 5 and 10. In other\nwords, both lists will share the first list containing 5 and 10.\n\nTrying to implement this scenario using our definition of `List` with `Box<T>`\nwon’t work, as shown in Listing 15-17:\n\n<span class=\"filename\">Filename: src/main.rs</span>\n\n```rust,ignore,does_not_compile\n{{#rustdoc_include ../listings/ch15-smart-pointers/listing-15-17/src/main.rs}}\n```\n\n<span class=\"caption\">Listing 15-17: Demonstrating we’re not allowed to have\ntwo lists using `Box<T>` that try to share ownership of a third list</span>\n\nWhen we compile this code, we get this error:\n\n```console\n{{#include ../listings/ch15-smart-pointers/listing-15-17/output.txt}}\n```\n\nThe `Cons` variants own the data they hold, so when we create the `b` list, `a`\nis moved into `b` and `b` owns `a`. Then, when we try to use `a` again when\ncreating `c`, we’re not allowed to because `a` has been moved.\n\nWe could change the definition of `Cons` to hold references instead, but then\nwe would have to specify lifetime parameters. By specifying lifetime\nparameters, we would be specifying that every element in the list will live at\nleast as long as the entire list. This is the case for the elements and lists\nin Listing 15-17, but not in every scenario.\n\nInstead, we’ll change our definition of `List` to use `Rc<T>` in place of\n`Box<T>`, as shown in Listing 15-18. Each `Cons` variant will now hold a value\nand an `Rc<T>` pointing to a `List`. When we create `b`, instead of taking\nownership of `a`, we’ll clone the `Rc<List>` that `a` is holding, thereby\nincreasing the number of references from one to two and letting `a` and `b`\nshare ownership of the data in that `Rc<List>`. We’ll also clone `a` when\ncreating `c`, increasing the number of references from two to three. Every time\nwe call `Rc::clone`, the reference count to the data within the `Rc<List>` will\nincrease, and the data won’t be cleaned up unless there are zero references to\nit.\n\n<span class=\"filename\">Filename: src/main.rs</span>\n\n```rust\n{{#rustdoc_include ../listings/ch15-smart-pointers/listing-15-18/src/main.rs}}\n```\n\n<span class=\"caption\">Listing 15-18: A definition of `List` that uses\n`Rc<T>`</span>\n\nWe need to add a `use` statement to bring `Rc<T>` into scope because it’s not\nin the prelude. In `main`, we create the list holding 5 and 10 and store it in\na new `Rc<List>` in `a`. Then when we create `b` and `c`, we call the\n`Rc::clone` function and pass a reference to the `Rc<List>` in `a` as an\nargument.\n\nWe could have called `a.clone()` rather than `Rc::clone(&a)`, but Rust’s\nconvention is to use `Rc::clone` in this case. The implementation of\n`Rc::clone` doesn’t make a deep copy of all the data like most types’\nimplementations of `clone` do. The call to `Rc::clone` only increments the\nreference count, which doesn’t take much time. Deep copies of data can take a\nlot of time. By using `Rc::clone` for reference counting, we can visually\ndistinguish between the deep-copy kinds of clones and the kinds of clones that\nincrease the reference count. When looking for performance problems in the\ncode, we only need to consider the deep-copy clones and can disregard calls to\n`Rc::clone`.\n\n### Cloning an `Rc<T>` Increases the Reference Count\n\nLet’s change our working example in Listing 15-18 so we can see the reference\ncounts changing as we create and drop references to the `Rc<List>` in `a`.\n\nIn Listing 15-19, we’ll change `main` so it has an inner scope around list `c`;\nthen we can see how the reference count changes when `c` goes out of scope.\n\n<span class=\"filename\">Filename: src/main.rs</span>\n\n```rust\n{{#rustdoc_include ../listings/ch15-smart-pointers/listing-15-19/src/main.rs:here}}\n```\n\n<span class=\"caption\">Listing 15-19: Printing the reference count</span>\n\nAt each point in the program where the reference count changes, we print the\nreference count, which we get by calling the `Rc::strong_count` function. This\nfunction is named `strong_count` rather than `count` because the `Rc<T>` type\nalso has a `weak_count`; we’ll see what `weak_count` is used for in the\n[“Preventing Reference Cycles: Turning an `Rc<T>` into a\n`Weak<T>`”][preventing-ref-cycles]<!-- ignore --> section.\n\nThis code prints the following:\n\n```console\n{{#include ../listings/ch15-smart-pointers/listing-15-19/output.txt}}\n```\n\nWe can see that the `Rc<List>` in `a` has an initial reference count of 1; then\neach time we call `clone`, the count goes up by 1. When `c` goes out of scope,\nthe count goes down by 1. We don’t have to call a function to decrease the\nreference count like we have to call `Rc::clone` to increase the reference\ncount: the implementation of the `Drop` trait decreases the reference count\nautomatically when an `Rc<T>` value goes out of scope.\n\nWhat we can’t see in this example is that when `b` and then `a` go out of scope\nat the end of `main`, the count is then 0, and the `Rc<List>` is cleaned up\ncompletely. Using `Rc<T>` allows a single value to have multiple owners, and\nthe count ensures that the value remains valid as long as any of the owners\nstill exist.\n\nVia immutable references, `Rc<T>` allows you to share data between multiple\nparts of your program for reading only. If `Rc<T>` allowed you to have multiple\nmutable references too, you might violate one of the borrowing rules discussed\nin Chapter 4: multiple mutable borrows to the same place can cause data races\nand inconsistencies. But being able to mutate data is very useful! In the next\nsection, we’ll discuss the interior mutability pattern and the `RefCell<T>`\ntype that you can use in conjunction with an `Rc<T>` to work with this\nimmutability restriction.\n\n[preventing-ref-cycles]: ch15-06-reference-cycles.html#preventing-reference-cycles-turning-an-rct-into-a-weakt\n",
          "document_id": 77
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "What is interior mutability?",
              "id": 62,
              "answers": [
                {
                  "answer_id": 62,
                  "document_id": 78,
                  "question_id": 62,
                  "text": "*Interior mutability* is a design pattern in Rust that allows you to mutate\ndata even when there are immutable references to that data",
                  "answer_start": 53,
                  "answer_end": 187,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "How RefCell<T> differs from Box<T>?",
              "id": 63,
              "answers": [
                {
                  "answer_id": 63,
                  "document_id": 78,
                  "question_id": 63,
                  "text": "With references and `Box‹T>`, the borrowing rules’ invariants are enforced at\ncompile time. With `RefCell‹T>`, these invariants are enforced *at runtime*.",
                  "answer_start": 1383,
                  "answer_end": 1537,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "Can RefCell<T> be used in multithreading?",
              "id": 65,
              "answers": [
                {
                  "answer_id": 65,
                  "document_id": 78,
                  "question_id": 65,
                  "text": "Similar to `Rc‹T>`, `RefCell‹T>` is only for use in single-threaded scenarios\nand will give you a compile-time error if you try using it in a multithreaded\ncontext.",
                  "answer_start": 3069,
                  "answer_end": 3233,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What is the advantage of RefCell<T>?",
              "id": 64,
              "answers": [
                {
                  "answer_id": 64,
                  "document_id": 78,
                  "question_id": 64,
                  "text": "The `RefCell‹T>` type is useful when you’re sure your\ncode follows the borrowing rules but the compiler is unable to understand and\nguarantee that.",
                  "answer_start": 2920,
                  "answer_end": 3067,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What are the differences between Rust smart pointers?",
              "id": 66,
              "answers": [
                {
                  "answer_id": 66,
                  "document_id": 78,
                  "question_id": 66,
                  "text": "Here is a recap of the reasons to choose `Box‹T>`, `Rc‹T>`, or `RefCell‹T>`:\n\n* `Rc‹T>` enables multiple owners of the same data; `Box‹T>` and `RefCell‹T>`\n  have single owners.\n* `Box‹T>` allows immutable or mutable borrows checked at compile time; `Rc‹T>`\n  allows only immutable borrows checked at compile time; `RefCell‹T>` allows\n  immutable or mutable borrows checked at runtime.\n* Because `RefCell‹T>` allows mutable borrows checked at runtime, you can\n  mutate the value inside the `RefCell‹T>` even when the `RefCell‹T>` is\n  immutable.",
                  "answer_start": 3339,
                  "answer_end": 3884,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What happens if you break ownership rules with RefCell<T>?",
              "id": 67,
              "answers": [
                {
                  "answer_id": 67,
                  "document_id": 78,
                  "question_id": 67,
                  "text": " If you violate the rules, you’ll get a `panic!` instead of\na compiler error.",
                  "answer_start": 5092,
                  "answer_end": 5169,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "Can you create mock?",
              "id": 69,
              "answers": [
                {
                  "answer_id": 69,
                  "document_id": 78,
                  "question_id": 69,
                  "text": "Rust doesn’t have mock object functionality built into the standard library\nas some other languages do. However, you can definitely create a struct that\nwill serve the same purposes as a mock object.",
                  "answer_start": 5997,
                  "answer_end": 6196,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "## `RefCell<T>` and the Interior Mutability Pattern\n\n*Interior mutability* is a design pattern in Rust that allows you to mutate\ndata even when there are immutable references to that data; normally, this\naction is disallowed by the borrowing rules. To mutate data, the pattern uses\n`unsafe` code inside a data structure to bend Rust’s usual rules that govern\nmutation and borrowing. Unsafe code indicates to the compiler that we’re\nchecking the rules manually instead of relying on the compiler to check them\nfor us; we will discuss unsafe code more in Chapter 19.\n\nWe can use types that use the interior mutability pattern only when we can\nensure that the borrowing rules will be followed at runtime, even though the\ncompiler can’t guarantee that. The `unsafe` code involved is then wrapped in a\nsafe API, and the outer type is still immutable.\n\nLet’s explore this concept by looking at the `RefCell<T>` type that follows the\ninterior mutability pattern.\n\n### Enforcing Borrowing Rules at Runtime with `RefCell<T>`\n\nUnlike `Rc<T>`, the `RefCell<T>` type represents single ownership over the data\nit holds. So, what makes `RefCell<T>` different from a type like `Box<T>`?\nRecall the borrowing rules you learned in Chapter 4:\n\n* At any given time, you can have *either* (but not both) one mutable reference\n  or any number of immutable references.\n* References must always be valid.\n\nWith references and `Box<T>`, the borrowing rules’ invariants are enforced at\ncompile time. With `RefCell<T>`, these invariants are enforced *at runtime*.\nWith references, if you break these rules, you’ll get a compiler error. With\n`RefCell<T>`, if you break these rules, your program will panic and exit.\n\nThe advantages of checking the borrowing rules at compile time are that errors\nwill be caught sooner in the development process, and there is no impact on\nruntime performance because all the analysis is completed beforehand. For those\nreasons, checking the borrowing rules at compile time is the best choice in the\nmajority of cases, which is why this is Rust’s default.\n\nThe advantage of checking the borrowing rules at runtime instead is that\ncertain memory-safe scenarios are then allowed, where they would’ve been\ndisallowed by the compile-time checks. Static analysis, like the Rust compiler,\nis inherently conservative. Some properties of code are impossible to detect by\nanalyzing the code: the most famous example is the Halting Problem, which is\nbeyond the scope of this book but is an interesting topic to research.\n\nBecause some analysis is impossible, if the Rust compiler can’t be sure the\ncode complies with the ownership rules, it might reject a correct program; in\nthis way, it’s conservative. If Rust accepted an incorrect program, users\nwouldn’t be able to trust in the guarantees Rust makes. However, if Rust\nrejects a correct program, the programmer will be inconvenienced, but nothing\ncatastrophic can occur. The `RefCell<T>` type is useful when you’re sure your\ncode follows the borrowing rules but the compiler is unable to understand and\nguarantee that.\n\nSimilar to `Rc<T>`, `RefCell<T>` is only for use in single-threaded scenarios\nand will give you a compile-time error if you try using it in a multithreaded\ncontext. We’ll talk about how to get the functionality of `RefCell<T>` in a\nmultithreaded program in Chapter 16.\n\nHere is a recap of the reasons to choose `Box<T>`, `Rc<T>`, or `RefCell<T>`:\n\n* `Rc<T>` enables multiple owners of the same data; `Box<T>` and `RefCell<T>`\n  have single owners.\n* `Box<T>` allows immutable or mutable borrows checked at compile time; `Rc<T>`\n  allows only immutable borrows checked at compile time; `RefCell<T>` allows\n  immutable or mutable borrows checked at runtime.\n* Because `RefCell<T>` allows mutable borrows checked at runtime, you can\n  mutate the value inside the `RefCell<T>` even when the `RefCell<T>` is\n  immutable.\n\nMutating the value inside an immutable value is the *interior mutability*\npattern. Let’s look at a situation in which interior mutability is useful and\nexamine how it’s possible.\n\n### Interior Mutability: A Mutable Borrow to an Immutable Value\n\nA consequence of the borrowing rules is that when you have an immutable value,\nyou can’t borrow it mutably. For example, this code won’t compile:\n\n```rust,ignore,does_not_compile\n{{#rustdoc_include ../listings/ch15-smart-pointers/no-listing-01-cant-borrow-immutable-as-mutable/src/main.rs}}\n```\n\nIf you tried to compile this code, you’d get the following error:\n\n```console\n{{#include ../listings/ch15-smart-pointers/no-listing-01-cant-borrow-immutable-as-mutable/output.txt}}\n```\n\nHowever, there are situations in which it would be useful for a value to mutate\nitself in its methods but appear immutable to other code. Code outside the\nvalue’s methods would not be able to mutate the value. Using `RefCell<T>` is\none way to get the ability to have interior mutability, but `RefCell<T>`\ndoesn’t get around the borrowing rules completely: the borrow checker in the\ncompiler allows this interior mutability, and the borrowing rules are checked\nat runtime instead. If you violate the rules, you’ll get a `panic!` instead of\na compiler error.\n\nLet’s work through a practical example where we can use `RefCell<T>` to mutate\nan immutable value and see why that is useful.\n\n#### A Use Case for Interior Mutability: Mock Objects\n\nSometimes during testing a programmer will use a type in place of another type,\nin order to observe particular behavior and assert it’s implemented correctly.\nThis placeholder type is called a *test double*. Think of it in the sense of a\n“stunt double” in filmmaking, where a person steps in and substitutes for an\nactor to do a particular tricky scene. Test doubles stand in for other types\nwhen we’re running tests. *Mock objects* are specific types of test doubles\nthat record what happens during a test so you can assert that the correct\nactions took place.\n\nRust doesn’t have objects in the same sense as other languages have objects,\nand Rust doesn’t have mock object functionality built into the standard library\nas some other languages do. However, you can definitely create a struct that\nwill serve the same purposes as a mock object.\n\nHere’s the scenario we’ll test: we’ll create a library that tracks a value\nagainst a maximum value and sends messages based on how close to the maximum\nvalue the current value is. This library could be used to keep track of a\nuser’s quota for the number of API calls they’re allowed to make, for example.\n\nOur library will only provide the functionality of tracking how close to the\nmaximum a value is and what the messages should be at what times. Applications\nthat use our library will be expected to provide the mechanism for sending the\nmessages: the application could put a message in the application, send an\nemail, send a text message, or something else. The library doesn’t need to know\nthat detail. All it needs is something that implements a trait we’ll provide\ncalled `Messenger`. Listing 15-20 shows the library code:\n\n<span class=\"filename\">Filename: src/lib.rs</span>\n\n```rust,noplayground\n{{#rustdoc_include ../listings/ch15-smart-pointers/listing-15-20/src/lib.rs}}\n```\n\n<span class=\"caption\">Listing 15-20: A library to keep track of how close a\nvalue is to a maximum value and warn when the value is at certain levels</span>\n\nOne important part of this code is that the `Messenger` trait has one method\ncalled `send` that takes an immutable reference to `self` and the text of the\nmessage. This trait is the interface our mock object needs to implement so that\nthe mock can be used in the same way a real object is. The other important part\nis that we want to test the behavior of the `set_value` method on the\n`LimitTracker`. We can change what we pass in for the `value` parameter, but\n`set_value` doesn’t return anything for us to make assertions on. We want to be\nable to say that if we create a `LimitTracker` with something that implements\nthe `Messenger` trait and a particular value for `max`, when we pass different\nnumbers for `value`, the messenger is told to send the appropriate messages.\n\nWe need a mock object that, instead of sending an email or text message when we\ncall `send`, will only keep track of the messages it’s told to send. We can\ncreate a new instance of the mock object, create a `LimitTracker` that uses the\nmock object, call the `set_value` method on `LimitTracker`, and then check that\nthe mock object has the messages we expect. Listing 15-21 shows an attempt to\nimplement a mock object to do just that, but the borrow checker won’t allow it:\n\n<span class=\"filename\">Filename: src/lib.rs</span>\n\n```rust,ignore,does_not_compile\n{{#rustdoc_include ../listings/ch15-smart-pointers/listing-15-21/src/lib.rs:here}}\n```\n\n<span class=\"caption\">Listing 15-21: An attempt to implement a `MockMessenger`\nthat isn’t allowed by the borrow checker</span>\n\nThis test code defines a `MockMessenger` struct that has a `sent_messages`\nfield with a `Vec` of `String` values to keep track of the messages it’s told\nto send. We also define an associated function `new` to make it convenient to\ncreate new `MockMessenger` values that start with an empty list of messages. We\nthen implement the `Messenger` trait for `MockMessenger` so we can give a\n`MockMessenger` to a `LimitTracker`. In the definition of the `send` method, we\ntake the message passed in as a parameter and store it in the `MockMessenger`\nlist of `sent_messages`.\n\nIn the test, we’re testing what happens when the `LimitTracker` is told to set\n`value` to something that is more than 75 percent of the `max` value. First, we\ncreate a new `MockMessenger`, which will start with an empty list of messages.\nThen we create a new `LimitTracker` and give it a reference to the new\n`MockMessenger` and a `max` value of 100. We call the `set_value` method on the\n`LimitTracker` with a value of 80, which is more than 75 percent of 100. Then\nwe assert that the list of messages that the `MockMessenger` is keeping track\nof should now have one message in it.\n\nHowever, there’s one problem with this test, as shown here:\n\n```console\n{{#include ../listings/ch15-smart-pointers/listing-15-21/output.txt}}\n```\n\nWe can’t modify the `MockMessenger` to keep track of the messages, because the\n`send` method takes an immutable reference to `self`. We also can’t take the\nsuggestion from the error text to use `&mut self` instead, because then the\nsignature of `send` wouldn’t match the signature in the `Messenger` trait\ndefinition (feel free to try and see what error message you get).\n\nThis is a situation in which interior mutability can help! We’ll store the\n`sent_messages` within a `RefCell<T>`, and then the `send` method will be\nable to modify `sent_messages` to store the messages we’ve seen. Listing 15-22\nshows what that looks like:\n\n<span class=\"filename\">Filename: src/lib.rs</span>\n\n```rust,noplayground\n{{#rustdoc_include ../listings/ch15-smart-pointers/listing-15-22/src/lib.rs:here}}\n```\n\n<span class=\"caption\">Listing 15-22: Using `RefCell<T>` to mutate an inner\nvalue while the outer value is considered immutable</span>\n\nThe `sent_messages` field is now of type `RefCell<Vec<String>>` instead of\n`Vec<String>`. In the `new` function, we create a new `RefCell<Vec<String>>`\ninstance around the empty vector.\n\nFor the implementation of the `send` method, the first parameter is still an\nimmutable borrow of `self`, which matches the trait definition. We call\n`borrow_mut` on the `RefCell<Vec<String>>` in `self.sent_messages` to get a\nmutable reference to the value inside the `RefCell<Vec<String>>`, which is the\nvector. Then we can call `push` on the mutable reference to the vector to keep\ntrack of the messages sent during the test.\n\nThe last change we have to make is in the assertion: to see how many items are\nin the inner vector, we call `borrow` on the `RefCell<Vec<String>>` to get an\nimmutable reference to the vector.\n\nNow that you’ve seen how to use `RefCell<T>`, let’s dig into how it works!\n\n#### Keeping Track of Borrows at Runtime with `RefCell<T>`\n\nWhen creating immutable and mutable references, we use the `&` and `&mut`\nsyntax, respectively. With `RefCell<T>`, we use the `borrow` and `borrow_mut`\nmethods, which are part of the safe API that belongs to `RefCell<T>`. The\n`borrow` method returns the smart pointer type `Ref<T>`, and `borrow_mut`\nreturns the smart pointer type `RefMut<T>`. Both types implement `Deref`, so we\ncan treat them like regular references.\n\nThe `RefCell<T>` keeps track of how many `Ref<T>` and `RefMut<T>` smart\npointers are currently active. Every time we call `borrow`, the `RefCell<T>`\nincreases its count of how many immutable borrows are active. When a `Ref<T>`\nvalue goes out of scope, the count of immutable borrows goes down by one. Just\nlike the compile-time borrowing rules, `RefCell<T>` lets us have many immutable\nborrows or one mutable borrow at any point in time.\n\nIf we try to violate these rules, rather than getting a compiler error as we\nwould with references, the implementation of `RefCell<T>` will panic at\nruntime. Listing 15-23 shows a modification of the implementation of `send` in\nListing 15-22. We’re deliberately trying to create two mutable borrows active\nfor the same scope to illustrate that `RefCell<T>` prevents us from doing this\nat runtime.\n\n<span class=\"filename\">Filename: src/lib.rs</span>\n\n```rust,ignore,panics\n{{#rustdoc_include ../listings/ch15-smart-pointers/listing-15-23/src/lib.rs:here}}\n```\n\n<span class=\"caption\">Listing 15-23: Creating two mutable references in the\nsame scope to see that `RefCell<T>` will panic</span>\n\nWe create a variable `one_borrow` for the `RefMut<T>` smart pointer returned\nfrom `borrow_mut`. Then we create another mutable borrow in the same way in the\nvariable `two_borrow`. This makes two mutable references in the same scope,\nwhich isn’t allowed. When we run the tests for our library, the code in Listing\n15-23 will compile without any errors, but the test will fail:\n\n```console\n{{#include ../listings/ch15-smart-pointers/listing-15-23/output.txt}}\n```\n\nNotice that the code panicked with the message `already borrowed:\nBorrowMutError`. This is how `RefCell<T>` handles violations of the borrowing\nrules at runtime.\n\nChoosing to catch borrowing errors at runtime rather than compile time, as\nwe’ve done here, means you’d potentially be finding mistakes in your code later\nin the development process: possibly not until your code was deployed to\nproduction. Also, your code would incur a small runtime performance penalty as\na result of keeping track of the borrows at runtime rather than compile time.\nHowever, using `RefCell<T>` makes it possible to write a mock object that can\nmodify itself to keep track of the messages it has seen while you’re using it\nin a context where only immutable values are allowed. You can use `RefCell<T>`\ndespite its trade-offs to get more functionality than regular references\nprovide.\n\n### Having Multiple Owners of Mutable Data by Combining `Rc<T>` and `RefCell<T>`\n\nA common way to use `RefCell<T>` is in combination with `Rc<T>`. Recall that\n`Rc<T>` lets you have multiple owners of some data, but it only gives immutable\naccess to that data. If you have an `Rc<T>` that holds a `RefCell<T>`, you can\nget a value that can have multiple owners *and* that you can mutate!\n\nFor example, recall the cons list example in Listing 15-18 where we used\n`Rc<T>` to allow multiple lists to share ownership of another list. Because\n`Rc<T>` holds only immutable values, we can’t change any of the values in the\nlist once we’ve created them. Let’s add in `RefCell<T>` to gain the ability to\nchange the values in the lists. Listing 15-24 shows that by using a\n`RefCell<T>` in the `Cons` definition, we can modify the value stored in all\nthe lists:\n\n<span class=\"filename\">Filename: src/main.rs</span>\n\n```rust\n{{#rustdoc_include ../listings/ch15-smart-pointers/listing-15-24/src/main.rs}}\n```\n\n<span class=\"caption\">Listing 15-24: Using `Rc<RefCell<i32>>` to create a\n`List` that we can mutate</span>\n\nWe create a value that is an instance of `Rc<RefCell<i32>>` and store it in a\nvariable named `value` so we can access it directly later. Then we create a\n`List` in `a` with a `Cons` variant that holds `value`. We need to clone\n`value` so both `a` and `value` have ownership of the inner `5` value rather\nthan transferring ownership from `value` to `a` or having `a` borrow from\n`value`.\n\nWe wrap the list `a` in an `Rc<T>` so when we create lists `b` and `c`, they\ncan both refer to `a`, which is what we did in Listing 15-18.\n\nAfter we’ve created the lists in `a`, `b`, and `c`, we want to add 10 to the\nvalue in `value`. We do this by calling `borrow_mut` on `value`, which uses the\nautomatic dereferencing feature we discussed in Chapter 5 (see the section\n[“Where’s the `->` Operator?”][wheres-the---operator]<!-- ignore -->) to\ndereference the `Rc<T>` to the inner `RefCell<T>` value. The `borrow_mut`\nmethod returns a `RefMut<T>` smart pointer, and we use the dereference operator\non it and change the inner value.\n\nWhen we print `a`, `b`, and `c`, we can see that they all have the modified\nvalue of 15 rather than 5:\n\n```console\n{{#include ../listings/ch15-smart-pointers/listing-15-24/output.txt}}\n```\n\nThis technique is pretty neat! By using `RefCell<T>`, we have an outwardly\nimmutable `List` value. But we can use the methods on `RefCell<T>` that provide\naccess to its interior mutability so we can modify our data when we need to.\nThe runtime checks of the borrowing rules protect us from data races, and it’s\nsometimes worth trading a bit of speed for this flexibility in our data\nstructures. Note that `RefCell<T>` does not work for multithreaded code!\n`Mutex<T>` is the thread-safe version of `RefCell<T>` and we’ll discuss\n`Mutex<T>` in Chapter 16.\n\n[wheres-the---operator]: ch05-03-method-syntax.html#wheres-the---operator\n",
          "document_id": 78
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "Can you leak memory in Rust?",
              "id": 70,
              "answers": [
                {
                  "answer_id": 70,
                  "document_id": 79,
                  "question_id": 70,
                  "text": "Preventing memory leaks entirely is not one of Rust’s guarantees",
                  "answer_start": 191,
                  "answer_end": 255,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "How to create a memory leak?",
              "id": 71,
              "answers": [
                {
                  "answer_id": 71,
                  "document_id": 79,
                  "question_id": 71,
                  "text": "We can see that Rust allows memory leaks\nby using `Rc‹T>` and `RefCell‹T>`: it’s possible to create references where\nitems refer to each other in a cycle. This creates memory leaks because the\nreference count of each item in the cycle will never reach 0, and the values\nwill never be dropped.",
                  "answer_start": 303,
                  "answer_end": 595,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "How to prevent reference cycles?",
              "id": 72,
              "answers": [
                {
                  "answer_id": 72,
                  "document_id": 79,
                  "question_id": 72,
                  "text": "Another solution for avoiding reference cycles is reorganizing your data\nstructures so that some references express ownership and some references don’t.\nAs a result, you can have cycles made up of some ownership relationships and\nsome non-ownership relationships, and only the ownership relationships affect\nwhether or not a value can be dropped.",
                  "answer_start": 4930,
                  "answer_end": 5276,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What is the difference between strong and weak references?",
              "id": 73,
              "answers": [
                {
                  "answer_id": 73,
                  "document_id": 79,
                  "question_id": 73,
                  "text": "Strong references are how you can share ownership of\nan `Rc‹T>` instance. Weak references don’t express an ownership relationship,\nand their count doesn’t affect when an `Rc‹T>` instance is cleaned up.",
                  "answer_start": 5959,
                  "answer_end": 6160,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "## Reference Cycles Can Leak Memory\n\nRust’s memory safety guarantees make it difficult, but not impossible, to\naccidentally create memory that is never cleaned up (known as a *memory leak*).\nPreventing memory leaks entirely is not one of Rust’s guarantees, meaning\nmemory leaks are memory safe in Rust. We can see that Rust allows memory leaks\nby using `Rc<T>` and `RefCell<T>`: it’s possible to create references where\nitems refer to each other in a cycle. This creates memory leaks because the\nreference count of each item in the cycle will never reach 0, and the values\nwill never be dropped.\n\n### Creating a Reference Cycle\n\nLet’s look at how a reference cycle might happen and how to prevent it,\nstarting with the definition of the `List` enum and a `tail` method in Listing\n15-25:\n\n<span class=\"filename\">Filename: src/main.rs</span>\n\n```rust\n{{#rustdoc_include ../listings/ch15-smart-pointers/listing-15-25/src/main.rs}}\n```\n\n<span class=\"caption\">Listing 15-25: A cons list definition that holds a\n`RefCell<T>` so we can modify what a `Cons` variant is referring to</span>\n\nWe’re using another variation of the `List` definition from Listing 15-5. The\nsecond element in the `Cons` variant is now `RefCell<Rc<List>>`, meaning that\ninstead of having the ability to modify the `i32` value as we did in Listing\n15-24, we want to modify the `List` value a `Cons` variant is pointing to.\nWe’re also adding a `tail` method to make it convenient for us to access the\nsecond item if we have a `Cons` variant.\n\nIn Listing 15-26, we’re adding a `main` function that uses the definitions in\nListing 15-25. This code creates a list in `a` and a list in `b` that points to\nthe list in `a`. Then it modifies the list in `a` to point to `b`, creating a\nreference cycle. There are `println!` statements along the way to show what the\nreference counts are at various points in this process.\n\n<span class=\"filename\">Filename: src/main.rs</span>\n\n```rust\n{{#rustdoc_include ../listings/ch15-smart-pointers/listing-15-26/src/main.rs:here}}\n```\n\n<span class=\"caption\">Listing 15-26: Creating a reference cycle of two `List`\nvalues pointing to each other</span>\n\nWe create an `Rc<List>` instance holding a `List` value in the variable `a`\nwith an initial list of `5, Nil`. We then create an `Rc<List>` instance holding\nanother `List` value in the variable `b` that contains the value 10 and points\nto the list in `a`.\n\nWe modify `a` so it points to `b` instead of `Nil`, creating a cycle. We do\nthat by using the `tail` method to get a reference to the `RefCell<Rc<List>>`\nin `a`, which we put in the variable `link`. Then we use the `borrow_mut`\nmethod on the `RefCell<Rc<List>>` to change the value inside from an `Rc<List>`\nthat holds a `Nil` value to the `Rc<List>` in `b`.\n\nWhen we run this code, keeping the last `println!` commented out for the\nmoment, we’ll get this output:\n\n```console\n{{#include ../listings/ch15-smart-pointers/listing-15-26/output.txt}}\n```\n\nThe reference count of the `Rc<List>` instances in both `a` and `b` are 2 after\nwe change the list in `a` to point to `b`. At the end of `main`, Rust drops the\nvariable `b`, which decreases the reference count of the `b` `Rc<List>` instance\nfrom 2 to 1. The memory that `Rc<List>` has on the heap won’t be dropped at\nthis point, because its reference count is 1, not 0. Then Rust drops `a`, which\ndecreases the reference count of the `a` `Rc<List>` instance from 2 to 1 as\nwell. This instance’s memory can’t be dropped either, because the other\n`Rc<List>` instance still refers to it. The memory allocated to the list will\nremain uncollected forever. To visualize this reference cycle, we’ve created a\ndiagram in Figure 15-4.\n\n<img alt=\"Reference cycle of lists\" src=\"img/trpl15-04.svg\" class=\"center\" />\n\n<span class=\"caption\">Figure 15-4: A reference cycle of lists `a` and `b`\npointing to each other</span>\n\nIf you uncomment the last `println!` and run the program, Rust will try to\nprint this cycle with `a` pointing to `b` pointing to `a` and so forth until it\noverflows the stack.\n\nCompared to a real-world program, the consequences of creating a reference cycle\nin this example aren’t very dire: right after we create the reference cycle,\nthe program ends. However, if a more complex program allocated lots of memory\nin a cycle and held onto it for a long time, the program would use more memory\nthan it needed and might overwhelm the system, causing it to run out of\navailable memory.\n\nCreating reference cycles is not easily done, but it’s not impossible either.\nIf you have `RefCell<T>` values that contain `Rc<T>` values or similar nested\ncombinations of types with interior mutability and reference counting, you must\nensure that you don’t create cycles; you can’t rely on Rust to catch them.\nCreating a reference cycle would be a logic bug in your program that you should\nuse automated tests, code reviews, and other software development practices to\nminimize.\n\nAnother solution for avoiding reference cycles is reorganizing your data\nstructures so that some references express ownership and some references don’t.\nAs a result, you can have cycles made up of some ownership relationships and\nsome non-ownership relationships, and only the ownership relationships affect\nwhether or not a value can be dropped. In Listing 15-25, we always want `Cons`\nvariants to own their list, so reorganizing the data structure isn’t possible.\nLet’s look at an example using graphs made up of parent nodes and child nodes\nto see when non-ownership relationships are an appropriate way to prevent\nreference cycles.\n\n### Preventing Reference Cycles: Turning an `Rc<T>` into a `Weak<T>`\n\nSo far, we’ve demonstrated that calling `Rc::clone` increases the\n`strong_count` of an `Rc<T>` instance, and an `Rc<T>` instance is only cleaned\nup if its `strong_count` is 0. You can also create a *weak reference* to the\nvalue within an `Rc<T>` instance by calling `Rc::downgrade` and passing a\nreference to the `Rc<T>`. Strong references are how you can share ownership of\nan `Rc<T>` instance. Weak references don’t express an ownership relationship,\nand their count doesn’t affect when an `Rc<T>` instance is cleaned up. They\nwon’t cause a reference cycle because any cycle involving some weak references\nwill be broken once the strong reference count of values involved is 0.\n\nWhen you call `Rc::downgrade`, you get a smart pointer of type `Weak<T>`.\nInstead of increasing the `strong_count` in the `Rc<T>` instance by 1, calling\n`Rc::downgrade` increases the `weak_count` by 1. The `Rc<T>` type uses\n`weak_count` to keep track of how many `Weak<T>` references exist, similar to\n`strong_count`. The difference is the `weak_count` doesn’t need to be 0 for the\n`Rc<T>` instance to be cleaned up.\n\nBecause the value that `Weak<T>` references might have been dropped, to do\nanything with the value that a `Weak<T>` is pointing to, you must make sure the\nvalue still exists. Do this by calling the `upgrade` method on a `Weak<T>`\ninstance, which will return an `Option<Rc<T>>`. You’ll get a result of `Some`\nif the `Rc<T>` value has not been dropped yet and a result of `None` if the\n`Rc<T>` value has been dropped. Because `upgrade` returns an `Option<Rc<T>>`,\nRust will ensure that the `Some` case and the `None` case are handled, and\nthere won’t be an invalid pointer.\n\nAs an example, rather than using a list whose items know only about the next\nitem, we’ll create a tree whose items know about their children items *and*\ntheir parent items.\n\n#### Creating a Tree Data Structure: a `Node` with Child Nodes\n\nTo start, we’ll build a tree with nodes that know about their child nodes.\nWe’ll create a struct named `Node` that holds its own `i32` value as well as\nreferences to its children `Node` values:\n\n<span class=\"filename\">Filename: src/main.rs</span>\n\n```rust\n{{#rustdoc_include ../listings/ch15-smart-pointers/listing-15-27/src/main.rs:here}}\n```\n\nWe want a `Node` to own its children, and we want to share that ownership with\nvariables so we can access each `Node` in the tree directly. To do this, we\ndefine the `Vec<T>` items to be values of type `Rc<Node>`. We also want to\nmodify which nodes are children of another node, so we have a `RefCell<T>` in\n`children` around the `Vec<Rc<Node>>`.\n\nNext, we’ll use our struct definition and create one `Node` instance named\n`leaf` with the value 3 and no children, and another instance named `branch`\nwith the value 5 and `leaf` as one of its children, as shown in Listing 15-27:\n\n<span class=\"filename\">Filename: src/main.rs</span>\n\n```rust\n{{#rustdoc_include ../listings/ch15-smart-pointers/listing-15-27/src/main.rs:there}}\n```\n\n<span class=\"caption\">Listing 15-27: Creating a `leaf` node with no children\nand a `branch` node with `leaf` as one of its children</span>\n\nWe clone the `Rc<Node>` in `leaf` and store that in `branch`, meaning the\n`Node` in `leaf` now has two owners: `leaf` and `branch`. We can get from\n`branch` to `leaf` through `branch.children`, but there’s no way to get from\n`leaf` to `branch`. The reason is that `leaf` has no reference to `branch` and\ndoesn’t know they’re related. We want `leaf` to know that `branch` is its\nparent. We’ll do that next.\n\n#### Adding a Reference from a Child to Its Parent\n\nTo make the child node aware of its parent, we need to add a `parent` field to\nour `Node` struct definition. The trouble is in deciding what the type of\n`parent` should be. We know it can’t contain an `Rc<T>`, because that would\ncreate a reference cycle with `leaf.parent` pointing to `branch` and\n`branch.children` pointing to `leaf`, which would cause their `strong_count`\nvalues to never be 0.\n\nThinking about the relationships another way, a parent node should own its\nchildren: if a parent node is dropped, its child nodes should be dropped as\nwell. However, a child should not own its parent: if we drop a child node, the\nparent should still exist. This is a case for weak references!\n\nSo instead of `Rc<T>`, we’ll make the type of `parent` use `Weak<T>`,\nspecifically a `RefCell<Weak<Node>>`. Now our `Node` struct definition looks\nlike this:\n\n<span class=\"filename\">Filename: src/main.rs</span>\n\n```rust\n{{#rustdoc_include ../listings/ch15-smart-pointers/listing-15-28/src/main.rs:here}}\n```\n\nA node will be able to refer to its parent node but doesn’t own its parent.\nIn Listing 15-28, we update `main` to use this new definition so the `leaf`\nnode will have a way to refer to its parent, `branch`:\n\n<span class=\"filename\">Filename: src/main.rs</span>\n\n```rust\n{{#rustdoc_include ../listings/ch15-smart-pointers/listing-15-28/src/main.rs:there}}\n```\n\n<span class=\"caption\">Listing 15-28: A `leaf` node with a weak reference to its\nparent node `branch`</span>\n\nCreating the `leaf` node looks similar to Listing 15-27 with the exception of\nthe `parent` field: `leaf` starts out without a parent, so we create a new,\nempty `Weak<Node>` reference instance.\n\nAt this point, when we try to get a reference to the parent of `leaf` by using\nthe `upgrade` method, we get a `None` value. We see this in the output from the\nfirst `println!` statement:\n\n```text\nleaf parent = None\n```\n\nWhen we create the `branch` node, it will also have a new `Weak<Node>`\nreference in the `parent` field, because `branch` doesn’t have a parent node.\nWe still have `leaf` as one of the children of `branch`. Once we have the\n`Node` instance in `branch`, we can modify `leaf` to give it a `Weak<Node>`\nreference to its parent. We use the `borrow_mut` method on the\n`RefCell<Weak<Node>>` in the `parent` field of `leaf`, and then we use the\n`Rc::downgrade` function to create a `Weak<Node>` reference to `branch` from\nthe `Rc<Node>` in `branch.`\n\nWhen we print the parent of `leaf` again, this time we’ll get a `Some` variant\nholding `branch`: now `leaf` can access its parent! When we print `leaf`, we\nalso avoid the cycle that eventually ended in a stack overflow like we had in\nListing 15-26; the `Weak<Node>` references are printed as `(Weak)`:\n\n```text\nleaf parent = Some(Node { value: 5, parent: RefCell { value: (Weak) },\nchildren: RefCell { value: [Node { value: 3, parent: RefCell { value: (Weak) },\nchildren: RefCell { value: [] } }] } })\n```\n\nThe lack of infinite output indicates that this code didn’t create a reference\ncycle. We can also tell this by looking at the values we get from calling\n`Rc::strong_count` and `Rc::weak_count`.\n\n#### Visualizing Changes to `strong_count` and `weak_count`\n\nLet’s look at how the `strong_count` and `weak_count` values of the `Rc<Node>`\ninstances change by creating a new inner scope and moving the creation of\n`branch` into that scope. By doing so, we can see what happens when `branch` is\ncreated and then dropped when it goes out of scope. The modifications are shown\nin Listing 15-29:\n\n<span class=\"filename\">Filename: src/main.rs</span>\n\n```rust\n{{#rustdoc_include ../listings/ch15-smart-pointers/listing-15-29/src/main.rs:here}}\n```\n\n<span class=\"caption\">Listing 15-29: Creating `branch` in an inner scope and\nexamining strong and weak reference counts</span>\n\nAfter `leaf` is created, its `Rc<Node>` has a strong count of 1 and a weak\ncount of 0. In the inner scope, we create `branch` and associate it with\n`leaf`, at which point when we print the counts, the `Rc<Node>` in `branch`\nwill have a strong count of 1 and a weak count of 1 (for `leaf.parent` pointing\nto `branch` with a `Weak<Node>`). When we print the counts in `leaf`, we’ll see\nit will have a strong count of 2, because `branch` now has a clone of the\n`Rc<Node>` of `leaf` stored in `branch.children`, but will still have a weak\ncount of 0.\n\nWhen the inner scope ends, `branch` goes out of scope and the strong count of\nthe `Rc<Node>` decreases to 0, so its `Node` is dropped. The weak count of 1\nfrom `leaf.parent` has no bearing on whether or not `Node` is dropped, so we\ndon’t get any memory leaks!\n\nIf we try to access the parent of `leaf` after the end of the scope, we’ll get\n`None` again. At the end of the program, the `Rc<Node>` in `leaf` has a strong\ncount of 1 and a weak count of 0, because the variable `leaf` is now the only\nreference to the `Rc<Node>` again.\n\nAll of the logic that manages the counts and value dropping is built into\n`Rc<T>` and `Weak<T>` and their implementations of the `Drop` trait. By\nspecifying that the relationship from a child to its parent should be a\n`Weak<T>` reference in the definition of `Node`, you’re able to have parent\nnodes point to child nodes and vice versa without creating a reference cycle\nand memory leaks.\n\n## Summary\n\nThis chapter covered how to use smart pointers to make different guarantees and\ntrade-offs from those Rust makes by default with regular references. The\n`Box<T>` type has a known size and points to data allocated on the heap. The\n`Rc<T>` type keeps track of the number of references to data on the heap so\nthat data can have multiple owners. The `RefCell<T>` type with its interior\nmutability gives us a type that we can use when we need an immutable type but\nneed to change an inner value of that type; it also enforces the borrowing\nrules at runtime instead of at compile time.\n\nAlso discussed were the `Deref` and `Drop` traits, which enable a lot of the\nfunctionality of smart pointers. We explored reference cycles that can cause\nmemory leaks and how to prevent them using `Weak<T>`.\n\nIf this chapter has piqued your interest and you want to implement your own\nsmart pointers, check out [“The Rustonomicon”][nomicon] for more useful\ninformation.\n\nNext, we’ll talk about concurrency in Rust. You’ll even learn about a few new\nsmart pointers.\n\n[nomicon]: ../nomicon/index.html\n",
          "document_id": 79
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "How concurrency is improved in Rust?",
              "id": 79,
              "answers": [
                {
                  "answer_id": 79,
                  "document_id": 80,
                  "question_id": 79,
                  "text": "By leveraging ownership and type checking, many concurrency errors\nare compile-time errors in Rust rather than runtime errors.",
                  "answer_start": 808,
                  "answer_end": 934,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "How many concurrency solutions are supported?",
              "id": 80,
              "answers": [
                {
                  "answer_id": 80,
                  "document_id": 80,
                  "question_id": 80,
                  "text": "Rust\noffers a variety of tools for modeling problems in whatever way is appropriate\nfor your situation and requirements.",
                  "answer_start": 2429,
                  "answer_end": 2549,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What are the most common concurrency features in Rust?",
              "id": 81,
              "answers": [
                {
                  "answer_id": 81,
                  "document_id": 80,
                  "question_id": 81,
                  "text": "* *Message-passing* concurrency, where channels send messages between threads\n* *Shared-state* concurrency, where multiple threads have access to some piece\n  of data\n* The `Sync` and `Send` traits, which extend Rust’s concurrency guarantees to\n  user-defined types as well as types provided by the standard library",
                  "answer_start": 2673,
                  "answer_end": 2988,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "# Fearless Concurrency\n\nHandling concurrent programming safely and efficiently is another of Rust’s\nmajor goals. *Concurrent programming*, where different parts of a program\nexecute independently, and *parallel programming*, where different parts of a\nprogram execute at the same time, are becoming increasingly important as more\ncomputers take advantage of their multiple processors. Historically,\nprogramming in these contexts has been difficult and error prone: Rust hopes to\nchange that.\n\nInitially, the Rust team thought that ensuring memory safety and preventing\nconcurrency problems were two separate challenges to be solved with different\nmethods. Over time, the team discovered that the ownership and type systems are\na powerful set of tools to help manage memory safety *and* concurrency\nproblems! By leveraging ownership and type checking, many concurrency errors\nare compile-time errors in Rust rather than runtime errors. Therefore, rather\nthan making you spend lots of time trying to reproduce the exact circumstances\nunder which a runtime concurrency bug occurs, incorrect code will refuse to\ncompile and present an error explaining the problem. As a result, you can fix\nyour code while you’re working on it rather than potentially after it has been\nshipped to production. We’ve nicknamed this aspect of Rust *fearless*\n*concurrency*. Fearless concurrency allows you to write code that is free of\nsubtle bugs and is easy to refactor without introducing new bugs.\n\n> Note: For simplicity’s sake, we’ll refer to many of the problems as\n> *concurrent* rather than being more precise by saying *concurrent and/or\n> parallel*. If this book were about concurrency and/or parallelism, we’d be\n> more specific. For this chapter, please mentally substitute *concurrent\n> and/or parallel* whenever we use *concurrent*.\n\nMany languages are dogmatic about the solutions they offer for handling\nconcurrent problems. For example, Erlang has elegant functionality for\nmessage-passing concurrency but has only obscure ways to share state between\nthreads. Supporting only a subset of possible solutions is a reasonable\nstrategy for higher-level languages, because a higher-level language promises\nbenefits from giving up some control to gain abstractions. However, lower-level\nlanguages are expected to provide the solution with the best performance in any\ngiven situation and have fewer abstractions over the hardware. Therefore, Rust\noffers a variety of tools for modeling problems in whatever way is appropriate\nfor your situation and requirements.\n\nHere are the topics we’ll cover in this chapter:\n\n* How to create threads to run multiple pieces of code at the same time\n* *Message-passing* concurrency, where channels send messages between threads\n* *Shared-state* concurrency, where multiple threads have access to some piece\n  of data\n* The `Sync` and `Send` traits, which extend Rust’s concurrency guarantees to\n  user-defined types as well as types provided by the standard library\n",
          "document_id": 80
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "What are typical problems with multithreading?",
              "id": 82,
              "answers": [
                {
                  "answer_id": 82,
                  "document_id": 81,
                  "question_id": 82,
                  "text": "* Race conditions, where threads are accessing data or resources in an\n  inconsistent order\n* Deadlocks, where two threads are waiting for each other, preventing both\n  threads from continuing\n* Bugs that happen only in certain situations and are hard to reproduce and fix\n  reliably",
                  "answer_start": 804,
                  "answer_end": 1087,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What is the Rust's standard threading model?",
              "id": 83,
              "answers": [
                {
                  "answer_id": 83,
                  "document_id": 81,
                  "question_id": 83,
                  "text": "The Rust standard library uses a *1:1* model of thread implementation,\nwhereby a program uses one operating system thread per one language thread.",
                  "answer_start": 1479,
                  "answer_end": 1625,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "How to create a thread?",
              "id": 84,
              "answers": [
                {
                  "answer_id": 84,
                  "document_id": 81,
                  "question_id": 84,
                  "text": "To create a new thread, we call the `thread::spawn` function and pass it a\nclosure (we talked about closures in Chapter 13) containing the code we want to\nrun in the new thread.",
                  "answer_start": 1773,
                  "answer_end": 1950,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What happens to other threads when main thread completes?",
              "id": 85,
              "answers": [
                {
                  "answer_id": 85,
                  "document_id": 81,
                  "question_id": 85,
                  "text": "Note that when the main thread of a Rust program completes, all spawned threads\nare shut down, whether or not they have finished running.",
                  "answer_start": 2330,
                  "answer_end": 2467,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What does thread::spawn return?",
              "id": 86,
              "answers": [
                {
                  "answer_id": 86,
                  "document_id": 81,
                  "question_id": 86,
                  "text": "The return type of\n`thread::spawn` is `JoinHandle`.",
                  "answer_start": 4278,
                  "answer_end": 4329,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What does JoinHandle do?",
              "id": 87,
              "answers": [
                {
                  "answer_id": 87,
                  "document_id": 81,
                  "question_id": 87,
                  "text": "A `JoinHandle` is an owned value that, when we\ncall the `join` method on it, will wait for its thread to finish.",
                  "answer_start": 4330,
                  "answer_end": 4442,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What happens when thread is blocked?",
              "id": 88,
              "answers": [
                {
                  "answer_id": 88,
                  "document_id": 81,
                  "question_id": 88,
                  "text": "*Blocking* a thread means that\nthread is prevented from performing work or exiting.",
                  "answer_start": 5013,
                  "answer_end": 5096,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "Why move is used with thread closures?",
              "id": 89,
              "answers": [
                {
                  "answer_id": 89,
                  "document_id": 81,
                  "question_id": 89,
                  "text": "We'll often use the `move` keyword with closures passed to `thread::spawn`\nbecause the closure will then take ownership of the values it uses from the\nenvironment, thus transferring ownership of those values from one thread to\nanother.",
                  "answer_start": 7300,
                  "answer_end": 7535,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "How to transfer values from one thread to another?",
              "id": 90,
              "answers": [
                {
                  "answer_id": 90,
                  "document_id": 81,
                  "question_id": 90,
                  "text": "To use data from the main thread in the spawned thread, the\nspawned thread’s closure must capture the values it needs.",
                  "answer_start": 7930,
                  "answer_end": 8048,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "Why should ownership be moved between threads?",
              "id": 91,
              "answers": [
                {
                  "answer_id": 91,
                  "document_id": 81,
                  "question_id": 91,
                  "text": "By telling Rust to move ownership of `v` to the spawned\nthread, we’re guaranteeing Rust that the main thread won’t use `v` anymore.",
                  "answer_start": 11766,
                  "answer_end": 11897,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "## Using Threads to Run Code Simultaneously\n\nIn most current operating systems, an executed program’s code is run in a\n*process*, and the operating system will manage multiple processes at once.\nWithin a program, you can also have independent parts that run simultaneously.\nThe features that run these independent parts are called *threads*. For\nexample, a web server could have multiple threads so that it could respond to\nmore than one request at the same time.\n\nSplitting the computation in your program into multiple threads to run multiple\ntasks at the same time can improve performance, but it also adds complexity.\nBecause threads can run simultaneously, there’s no inherent guarantee about the\norder in which parts of your code on different threads will run. This can lead\nto problems, such as:\n\n* Race conditions, where threads are accessing data or resources in an\n  inconsistent order\n* Deadlocks, where two threads are waiting for each other, preventing both\n  threads from continuing\n* Bugs that happen only in certain situations and are hard to reproduce and fix\n  reliably\n\nRust attempts to mitigate the negative effects of using threads, but\nprogramming in a multithreaded context still takes careful thought and requires\na code structure that is different from that in programs running in a single\nthread.\n\nProgramming languages implement threads in a few different ways, and many\noperating systems provide an API the language can call for creating new\nthreads. The Rust standard library uses a *1:1* model of thread implementation,\nwhereby a program uses one operating system thread per one language thread.\nThere are crates that implement other models of threading that make different\ntradeoffs to the 1:1 model.\n\n### Creating a New Thread with `spawn`\n\nTo create a new thread, we call the `thread::spawn` function and pass it a\nclosure (we talked about closures in Chapter 13) containing the code we want to\nrun in the new thread. The example in Listing 16-1 prints some text from a main\nthread and other text from a new thread:\n\n<span class=\"filename\">Filename: src/main.rs</span>\n\n```rust\n{{#rustdoc_include ../listings/ch16-fearless-concurrency/listing-16-01/src/main.rs}}\n```\n\n<span class=\"caption\">Listing 16-1: Creating a new thread to print one thing\nwhile the main thread prints something else</span>\n\nNote that when the main thread of a Rust program completes, all spawned threads\nare shut down, whether or not they have finished running. The output from this\nprogram might be a little different every time, but it will look similar to the\nfollowing:\n\n<!-- Not extracting output because changes to this output aren't significant;\nthe changes are likely to be due to the threads running differently rather than\nchanges in the compiler -->\n\n```text\nhi number 1 from the main thread!\nhi number 1 from the spawned thread!\nhi number 2 from the main thread!\nhi number 2 from the spawned thread!\nhi number 3 from the main thread!\nhi number 3 from the spawned thread!\nhi number 4 from the main thread!\nhi number 4 from the spawned thread!\nhi number 5 from the spawned thread!\n```\n\nThe calls to `thread::sleep` force a thread to stop its execution for a short\nduration, allowing a different thread to run. The threads will probably take\nturns, but that isn’t guaranteed: it depends on how your operating system\nschedules the threads. In this run, the main thread printed first, even though\nthe print statement from the spawned thread appears first in the code. And even\nthough we told the spawned thread to print until `i` is 9, it only got to 5\nbefore the main thread shut down.\n\nIf you run this code and only see output from the main thread, or don’t see any\noverlap, try increasing the numbers in the ranges to create more opportunities\nfor the operating system to switch between the threads.\n\n### Waiting for All Threads to Finish Using `join` Handles\n\nThe code in Listing 16-1 not only stops the spawned thread prematurely most of\nthe time due to the main thread ending, but because there is no guarantee on\nthe order in which threads run, we also can’t guarantee that the spawned thread\nwill get to run at all!\n\nWe can fix the problem of the spawned thread not running or ending prematurely\nby saving the return value of `thread::spawn` in a variable. The return type of\n`thread::spawn` is `JoinHandle`. A `JoinHandle` is an owned value that, when we\ncall the `join` method on it, will wait for its thread to finish. Listing 16-2\nshows how to use the `JoinHandle` of the thread we created in Listing 16-1 and\ncall `join` to make sure the spawned thread finishes before `main` exits:\n\n<span class=\"filename\">Filename: src/main.rs</span>\n\n```rust\n{{#rustdoc_include ../listings/ch16-fearless-concurrency/listing-16-02/src/main.rs}}\n```\n\n<span class=\"caption\">Listing 16-2: Saving a `JoinHandle` from `thread::spawn`\nto guarantee the thread is run to completion</span>\n\nCalling `join` on the handle blocks the thread currently running until the\nthread represented by the handle terminates. *Blocking* a thread means that\nthread is prevented from performing work or exiting. Because we’ve put the call\nto `join` after the main thread’s `for` loop, running Listing 16-2 should\nproduce output similar to this:\n\n<!-- Not extracting output because changes to this output aren't significant;\nthe changes are likely to be due to the threads running differently rather than\nchanges in the compiler -->\n\n```text\nhi number 1 from the main thread!\nhi number 2 from the main thread!\nhi number 1 from the spawned thread!\nhi number 3 from the main thread!\nhi number 2 from the spawned thread!\nhi number 4 from the main thread!\nhi number 3 from the spawned thread!\nhi number 4 from the spawned thread!\nhi number 5 from the spawned thread!\nhi number 6 from the spawned thread!\nhi number 7 from the spawned thread!\nhi number 8 from the spawned thread!\nhi number 9 from the spawned thread!\n```\n\nThe two threads continue alternating, but the main thread waits because of the\ncall to `handle.join()` and does not end until the spawned thread is finished.\n\nBut let’s see what happens when we instead move `handle.join()` before the\n`for` loop in `main`, like this:\n\n<span class=\"filename\">Filename: src/main.rs</span>\n\n```rust\n{{#rustdoc_include ../listings/ch16-fearless-concurrency/no-listing-01-join-too-early/src/main.rs}}\n```\n\nThe main thread will wait for the spawned thread to finish and then run its\n`for` loop, so the output won’t be interleaved anymore, as shown here:\n\n<!-- Not extracting output because changes to this output aren't significant;\nthe changes are likely to be due to the threads running differently rather than\nchanges in the compiler -->\n\n```text\nhi number 1 from the spawned thread!\nhi number 2 from the spawned thread!\nhi number 3 from the spawned thread!\nhi number 4 from the spawned thread!\nhi number 5 from the spawned thread!\nhi number 6 from the spawned thread!\nhi number 7 from the spawned thread!\nhi number 8 from the spawned thread!\nhi number 9 from the spawned thread!\nhi number 1 from the main thread!\nhi number 2 from the main thread!\nhi number 3 from the main thread!\nhi number 4 from the main thread!\n```\n\nSmall details, such as where `join` is called, can affect whether or not your\nthreads run at the same time.\n\n### Using `move` Closures with Threads\n\nWe'll often use the `move` keyword with closures passed to `thread::spawn`\nbecause the closure will then take ownership of the values it uses from the\nenvironment, thus transferring ownership of those values from one thread to\nanother. In the [“Capturing References or Moving Ownership”][capture]<!-- ignore\n--> section of Chapter 13, we discussed `move` in the context of closures. Now,\nwe’ll concentrate more on the interaction between `move` and `thread::spawn`.\n\nNotice in Listing 16-1 that the closure we pass to `thread::spawn` takes no\narguments: we’re not using any data from the main thread in the spawned\nthread’s code. To use data from the main thread in the spawned thread, the\nspawned thread’s closure must capture the values it needs. Listing 16-3 shows\nan attempt to create a vector in the main thread and use it in the spawned\nthread. However, this won’t yet work, as you’ll see in a moment.\n\n<span class=\"filename\">Filename: src/main.rs</span>\n\n```rust,ignore,does_not_compile\n{{#rustdoc_include ../listings/ch16-fearless-concurrency/listing-16-03/src/main.rs}}\n```\n\n<span class=\"caption\">Listing 16-3: Attempting to use a vector created by the\nmain thread in another thread</span>\n\nThe closure uses `v`, so it will capture `v` and make it part of the closure’s\nenvironment. Because `thread::spawn` runs this closure in a new thread, we\nshould be able to access `v` inside that new thread. But when we compile this\nexample, we get the following error:\n\n```console\n{{#include ../listings/ch16-fearless-concurrency/listing-16-03/output.txt}}\n```\n\nRust *infers* how to capture `v`, and because `println!` only needs a reference\nto `v`, the closure tries to borrow `v`. However, there’s a problem: Rust can’t\ntell how long the spawned thread will run, so it doesn’t know if the reference\nto `v` will always be valid.\n\nListing 16-4 provides a scenario that’s more likely to have a reference to `v`\nthat won’t be valid:\n\n<span class=\"filename\">Filename: src/main.rs</span>\n\n```rust,ignore,does_not_compile\n{{#rustdoc_include ../listings/ch16-fearless-concurrency/listing-16-04/src/main.rs}}\n```\n\n<span class=\"caption\">Listing 16-4: A thread with a closure that attempts to\ncapture a reference to `v` from a main thread that drops `v`</span>\n\nIf Rust allowed us to run this code, there’s a possibility the spawned thread\nwould be immediately put in the background without running at all. The spawned\nthread has a reference to `v` inside, but the main thread immediately drops\n`v`, using the `drop` function we discussed in Chapter 15. Then, when the\nspawned thread starts to execute, `v` is no longer valid, so a reference to it\nis also invalid. Oh no!\n\nTo fix the compiler error in Listing 16-3, we can use the error message’s\nadvice:\n\n<!-- manual-regeneration\nafter automatic regeneration, look at listings/ch16-fearless-concurrency/listing-16-03/output.txt and copy the relevant part\n-->\n\n```text\nhelp: to force the closure to take ownership of `v` (and any other referenced variables), use the `move` keyword\n  |\n6 |     let handle = thread::spawn(move || {\n  |                                ++++\n```\n\nBy adding the `move` keyword before the closure, we force the closure to take\nownership of the values it’s using rather than allowing Rust to infer that it\nshould borrow the values. The modification to Listing 16-3 shown in Listing\n16-5 will compile and run as we intend:\n\n<span class=\"filename\">Filename: src/main.rs</span>\n\n```rust\n{{#rustdoc_include ../listings/ch16-fearless-concurrency/listing-16-05/src/main.rs}}\n```\n\n<span class=\"caption\">Listing 16-5: Using the `move` keyword to force a closure\nto take ownership of the values it uses</span>\n\nWe might be tempted to try the same thing to fix the code in Listing 16-4 where\nthe main thread called `drop` by using a `move` closure. However, this fix will\nnot work because what Listing 16-4 is trying to do is disallowed for a\ndifferent reason. If we added `move` to the closure, we would move `v` into the\nclosure’s environment, and we could no longer call `drop` on it in the main\nthread. We would get this compiler error instead:\n\n```console\n{{#include ../listings/ch16-fearless-concurrency/output-only-01-move-drop/output.txt}}\n```\n\nRust’s ownership rules have saved us again! We got an error from the code in\nListing 16-3 because Rust was being conservative and only borrowing `v` for the\nthread, which meant the main thread could theoretically invalidate the spawned\nthread’s reference. By telling Rust to move ownership of `v` to the spawned\nthread, we’re guaranteeing Rust that the main thread won’t use `v` anymore. If\nwe change Listing 16-4 in the same way, we’re then violating the ownership\nrules when we try to use `v` in the main thread. The `move` keyword overrides\nRust’s conservative default of borrowing; it doesn’t let us violate the\nownership rules.\n\nWith a basic understanding of threads and the thread API, let’s look at what we\ncan *do* with threads.\n\n[capture]: ch13-01-closures.html#capturing-references-or-moving-ownership\n",
          "document_id": 81
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "What is a channel?",
              "id": 92,
              "answers": [
                {
                  "answer_id": 92,
                  "document_id": 82,
                  "question_id": 92,
                  "text": "A channel is a general programming concept by\nwhich data is sent from one thread to another.",
                  "answer_start": 538,
                  "answer_end": 630,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What is message passing?",
              "id": 93,
              "answers": [
                {
                  "answer_id": 93,
                  "document_id": 82,
                  "question_id": 93,
                  "text": "One increasingly popular approach to ensuring safe concurrency is *message\npassing*, where threads or actors communicate by sending each other messages\ncontaining data.",
                  "answer_start": 59,
                  "answer_end": 227,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What does channel consist of?",
              "id": 94,
              "answers": [
                {
                  "answer_id": 94,
                  "document_id": 82,
                  "question_id": 94,
                  "text": "A channel has two halves: a transmitter and a receiver.",
                  "answer_start": 857,
                  "answer_end": 912,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "How to communicate via channel?",
              "id": 95,
              "answers": [
                {
                  "answer_id": 95,
                  "document_id": 82,
                  "question_id": 95,
                  "text": "One part of your\ncode calls methods on the transmitter with the data you want to send, and\nanother part checks the receiving end for arriving messages.",
                  "answer_start": 1069,
                  "answer_end": 1220,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "How to create a new channel?",
              "id": 96,
              "answers": [
                {
                  "answer_id": 96,
                  "document_id": 82,
                  "question_id": 96,
                  "text": "We create a new channel using the `mpsc::channel` function",
                  "answer_start": 2314,
                  "answer_end": 2372,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What does mpsc mean?",
              "id": 97,
              "answers": [
                {
                  "answer_id": 97,
                  "document_id": 82,
                  "question_id": 97,
                  "text": "`mpsc` stands for\n*multiple producer, single consumer*.",
                  "answer_start": 2374,
                  "answer_end": 2429,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What is returned by mpsc::channel?",
              "id": 98,
              "answers": [
                {
                  "answer_id": 98,
                  "document_id": 82,
                  "question_id": 98,
                  "text": "The `mpsc::channel` function returns a tuple, the first element of which is the\nsending end--the transmitter--and the second element is the receiving end--the\nreceiver.",
                  "answer_start": 2869,
                  "answer_end": 3037,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What does send method return?",
              "id": 99,
              "answers": [
                {
                  "answer_id": 99,
                  "document_id": 82,
                  "question_id": 99,
                  "text": "The `send` method returns a `Result‹T, E>` type, so if the receiver has\nalready been dropped and there’s nowhere to send a value, the send operation\nwill return an error.",
                  "answer_start": 4353,
                  "answer_end": 4523,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "How to receive a message from channel?",
              "id": 100,
              "answers": [
                {
                  "answer_id": 100,
                  "document_id": 82,
                  "question_id": 100,
                  "text": "We’re using `recv`,\nshort for *receive*, which will block the main thread’s execution and wait\nuntil a value is sent down the channel. Once a value is sent, `recv` will\nreturn it in a `Result‹T, E>`. When the transmitter closes, `recv` will return\nan error to signal that no more values will be coming.",
                  "answer_start": 5218,
                  "answer_end": 5520,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "When try_recv should be used?",
              "id": 101,
              "answers": [
                {
                  "answer_id": 101,
                  "document_id": 82,
                  "question_id": 101,
                  "text": "Using `try_recv` is useful if\nthis thread has other work to do while waiting for messages",
                  "answer_start": 5724,
                  "answer_end": 5813,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "## Using Message Passing to Transfer Data Between Threads\n\nOne increasingly popular approach to ensuring safe concurrency is *message\npassing*, where threads or actors communicate by sending each other messages\ncontaining data. Here’s the idea in a slogan from [the Go language\ndocumentation](https://golang.org/doc/effective_go.html#concurrency):\n“Do not communicate by sharing memory; instead, share memory by communicating.”\n\nTo accomplish message-sending concurrency, Rust's standard library provides an\nimplementation of *channels*. A channel is a general programming concept by\nwhich data is sent from one thread to another.\n\nYou can imagine a channel in programming as being like a directional channel of\nwater, such as a stream or a river. If you put something like a rubber duck\ninto a river, it will travel downstream to the end of the waterway.\n\nA channel has two halves: a transmitter and a receiver. The transmitter half is\nthe upstream location where you put rubber ducks into the river, and the\nreceiver half is where the rubber duck ends up downstream. One part of your\ncode calls methods on the transmitter with the data you want to send, and\nanother part checks the receiving end for arriving messages. A channel is said\nto be *closed* if either the transmitter or receiver half is dropped.\n\nHere, we’ll work up to a program that has one thread to generate values and\nsend them down a channel, and another thread that will receive the values and\nprint them out. We’ll be sending simple values between threads using a channel\nto illustrate the feature. Once you’re familiar with the technique, you could\nuse channels for any threads that need to communicate between each other, such\nas a chat system or a system where many threads perform parts of a calculation\nand send the parts to one thread that aggregates the results.\n\nFirst, in Listing 16-6, we’ll create a channel but not do anything with it.\nNote that this won’t compile yet because Rust can’t tell what type of values we\nwant to send over the channel.\n\n<span class=\"filename\">Filename: src/main.rs</span>\n\n```rust,ignore,does_not_compile\n{{#rustdoc_include ../listings/ch16-fearless-concurrency/listing-16-06/src/main.rs}}\n```\n\n<span class=\"caption\">Listing 16-6: Creating a channel and assigning the two\nhalves to `tx` and `rx`</span>\n\nWe create a new channel using the `mpsc::channel` function; `mpsc` stands for\n*multiple producer, single consumer*. In short, the way Rust’s standard library\nimplements channels means a channel can have multiple *sending* ends that\nproduce values but only one *receiving* end that consumes those values. Imagine\nmultiple streams flowing together into one big river: everything sent down any\nof the streams will end up in one river at the end. We’ll start with a single\nproducer for now, but we’ll add multiple producers when we get this example\nworking.\n\nThe `mpsc::channel` function returns a tuple, the first element of which is the\nsending end--the transmitter--and the second element is the receiving end--the\nreceiver. The abbreviations `tx` and `rx` are traditionally used in many fields\nfor *transmitter* and *receiver* respectively, so we name our variables as such\nto indicate each end. We’re using a `let` statement with a pattern that\ndestructures the tuples; we’ll discuss the use of patterns in `let` statements\nand destructuring in Chapter 18. For now, know that using a `let` statement\nthis way is a convenient approach to extract the pieces of the tuple returned\nby `mpsc::channel`.\n\nLet’s move the transmitting end into a spawned thread and have it send one\nstring so the spawned thread is communicating with the main thread, as shown in\nListing 16-7. This is like putting a rubber duck in the river upstream or\nsending a chat message from one thread to another.\n\n<span class=\"filename\">Filename: src/main.rs</span>\n\n```rust\n{{#rustdoc_include ../listings/ch16-fearless-concurrency/listing-16-07/src/main.rs}}\n```\n\n<span class=\"caption\">Listing 16-7: Moving `tx` to a spawned thread and sending\n“hi”</span>\n\nAgain, we’re using `thread::spawn` to create a new thread and then using `move`\nto move `tx` into the closure so the spawned thread owns `tx`. The spawned\nthread needs to own the transmitter to be able to send messages through the\nchannel. The transmitter has a `send` method that takes the value we want to\nsend. The `send` method returns a `Result<T, E>` type, so if the receiver has\nalready been dropped and there’s nowhere to send a value, the send operation\nwill return an error. In this example, we’re calling `unwrap` to panic in case\nof an error. But in a real application, we would handle it properly: return to\nChapter 9 to review strategies for proper error handling.\n\nIn Listing 16-8, we’ll get the value from the receiver in the main thread. This\nis like retrieving the rubber duck from the water at the end of the river or\nreceiving a chat message.\n\n<span class=\"filename\">Filename: src/main.rs</span>\n\n```rust\n{{#rustdoc_include ../listings/ch16-fearless-concurrency/listing-16-08/src/main.rs}}\n```\n\n<span class=\"caption\">Listing 16-8: Receiving the value “hi” in the main thread\nand printing it</span>\n\nThe receiver has two useful methods: `recv` and `try_recv`. We’re using `recv`,\nshort for *receive*, which will block the main thread’s execution and wait\nuntil a value is sent down the channel. Once a value is sent, `recv` will\nreturn it in a `Result<T, E>`. When the transmitter closes, `recv` will return\nan error to signal that no more values will be coming.\n\nThe `try_recv` method doesn’t block, but will instead return a `Result<T, E>`\nimmediately: an `Ok` value holding a message if one is available and an `Err`\nvalue if there aren’t any messages this time. Using `try_recv` is useful if\nthis thread has other work to do while waiting for messages: we could write a\nloop that calls `try_recv` every so often, handles a message if one is\navailable, and otherwise does other work for a little while until checking\nagain.\n\nWe’ve used `recv` in this example for simplicity; we don’t have any other work\nfor the main thread to do other than wait for messages, so blocking the main\nthread is appropriate.\n\nWhen we run the code in Listing 16-8, we’ll see the value printed from the main\nthread:\n\n<!-- Not extracting output because changes to this output aren't significant;\nthe changes are likely to be due to the threads running differently rather than\nchanges in the compiler -->\n\n```text\nGot: hi\n```\n\nPerfect!\n\n### Channels and Ownership Transference\n\nThe ownership rules play a vital role in message sending because they help you\nwrite safe, concurrent code. Preventing errors in concurrent programming is the\nadvantage of thinking about ownership throughout your Rust programs. Let’s do\nan experiment to show how channels and ownership work together to prevent\nproblems: we’ll try to use a `val` value in the spawned thread *after* we’ve\nsent it down the channel. Try compiling the code in Listing 16-9 to see why\nthis code isn’t allowed:\n\n<span class=\"filename\">Filename: src/main.rs</span>\n\n```rust,ignore,does_not_compile\n{{#rustdoc_include ../listings/ch16-fearless-concurrency/listing-16-09/src/main.rs}}\n```\n\n<span class=\"caption\">Listing 16-9: Attempting to use `val` after we’ve sent it\ndown the channel</span>\n\nHere, we try to print `val` after we’ve sent it down the channel via `tx.send`.\nAllowing this would be a bad idea: once the value has been sent to another\nthread, that thread could modify or drop it before we try to use the value\nagain. Potentially, the other thread’s modifications could cause errors or\nunexpected results due to inconsistent or nonexistent data. However, Rust gives\nus an error if we try to compile the code in Listing 16-9:\n\n```console\n{{#include ../listings/ch16-fearless-concurrency/listing-16-09/output.txt}}\n```\n\nOur concurrency mistake has caused a compile time error. The `send` function\ntakes ownership of its parameter, and when the value is moved, the receiver\ntakes ownership of it. This stops us from accidentally using the value again\nafter sending it; the ownership system checks that everything is okay.\n\n### Sending Multiple Values and Seeing the Receiver Waiting\n\nThe code in Listing 16-8 compiled and ran, but it didn’t clearly show us that\ntwo separate threads were talking to each other over the channel. In Listing\n16-10 we’ve made some modifications that will prove the code in Listing 16-8 is\nrunning concurrently: the spawned thread will now send multiple messages and\npause for a second between each message.\n\n<span class=\"filename\">Filename: src/main.rs</span>\n\n```rust,noplayground\n{{#rustdoc_include ../listings/ch16-fearless-concurrency/listing-16-10/src/main.rs}}\n```\n\n<span class=\"caption\">Listing 16-10: Sending multiple messages and pausing\nbetween each</span>\n\nThis time, the spawned thread has a vector of strings that we want to send to\nthe main thread. We iterate over them, sending each individually, and pause\nbetween each by calling the `thread::sleep` function with a `Duration` value of\n1 second.\n\nIn the main thread, we’re not calling the `recv` function explicitly anymore:\ninstead, we’re treating `rx` as an iterator. For each value received, we’re\nprinting it. When the channel is closed, iteration will end.\n\nWhen running the code in Listing 16-10, you should see the following output\nwith a 1-second pause in between each line:\n\n<!-- Not extracting output because changes to this output aren't significant;\nthe changes are likely to be due to the threads running differently rather than\nchanges in the compiler -->\n\n```text\nGot: hi\nGot: from\nGot: the\nGot: thread\n```\n\nBecause we don’t have any code that pauses or delays in the `for` loop in the\nmain thread, we can tell that the main thread is waiting to receive values from\nthe spawned thread.\n\n### Creating Multiple Producers by Cloning the Transmitter\n\nEarlier we mentioned that `mpsc` was an acronym for *multiple producer,\nsingle consumer*. Let’s put `mpsc` to use and expand the code in Listing 16-10\nto create multiple threads that all send values to the same receiver. We can do\nso by cloning the transmitter, as shown in Listing 16-11:\n\n<span class=\"filename\">Filename: src/main.rs</span>\n\n```rust,noplayground\n{{#rustdoc_include ../listings/ch16-fearless-concurrency/listing-16-11/src/main.rs:here}}\n```\n\n<span class=\"caption\">Listing 16-11: Sending multiple messages from multiple\nproducers</span>\n\nThis time, before we create the first spawned thread, we call `clone` on the\ntransmitter. This will give us a new transmitter we can pass to the first\nspawned thread. We pass the original transmitter to a second spawned thread.\nThis gives us two threads, each sending different messages to the one receiver.\n\nWhen you run the code, your output should look something like this:\n\n<!-- Not extracting output because changes to this output aren't significant;\nthe changes are likely to be due to the threads running differently rather than\nchanges in the compiler -->\n\n```text\nGot: hi\nGot: more\nGot: from\nGot: messages\nGot: for\nGot: the\nGot: thread\nGot: you\n```\n\nYou might see the values in another order, depending on your system. This is\nwhat makes concurrency interesting as well as difficult. If you experiment with\n`thread::sleep`, giving it various values in the different threads, each run\nwill be more nondeterministic and create different output each time.\n\nNow that we’ve looked at how channels work, let’s look at a different method of\nconcurrency.\n",
          "document_id": 82
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "What is mutex?",
              "id": 102,
              "answers": [
                {
                  "answer_id": 102,
                  "document_id": 83,
                  "question_id": 102,
                  "text": "*Mutex* is an abbreviation for *mutual exclusion*, as in, a mutex allows only\none thread to access some data at any given time.",
                  "answer_start": 1166,
                  "answer_end": 1293,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What must done before accessing mutex data?",
              "id": 103,
              "answers": [
                {
                  "answer_id": 103,
                  "document_id": 83,
                  "question_id": 103,
                  "text": "To access the data in a\nmutex, a thread must first signal that it wants access by asking to acquire the\nmutex’s *lock*.",
                  "answer_start": 1294,
                  "answer_end": 1413,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What is lock?",
              "id": 104,
              "answers": [
                {
                  "answer_id": 104,
                  "document_id": 83,
                  "question_id": 104,
                  "text": "The lock is a data structure that is part of the mutex that\nkeeps track of who currently has exclusive access to the data.",
                  "answer_start": 1414,
                  "answer_end": 1536,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "How to create a new mutex?",
              "id": 105,
              "answers": [
                {
                  "answer_id": 105,
                  "document_id": 83,
                  "question_id": 105,
                  "text": "As with many types, we create a `Mutex‹T>` using the associated function `new`.",
                  "answer_start": 3098,
                  "answer_end": 3177,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "How to access mutex data?",
              "id": 106,
              "answers": [
                {
                  "answer_id": 106,
                  "document_id": 83,
                  "question_id": 106,
                  "text": "To access the data inside the mutex, we use the `lock` method to acquire the\nlock.",
                  "answer_start": 3178,
                  "answer_end": 3260,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What is returned from lock?",
              "id": 107,
              "answers": [
                {
                  "answer_id": 107,
                  "document_id": 83,
                  "question_id": 107,
                  "text": "More accurately, the call\nto `lock` *returns* a smart pointer called `MutexGuard`, wrapped in a\n`LockResult` that we handled with the call to `unwrap`.",
                  "answer_start": 4027,
                  "answer_end": 4178,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "How to use reference counting in multithreading?",
              "id": 108,
              "answers": [
                {
                  "answer_id": 108,
                  "document_id": 83,
                  "question_id": 108,
                  "text": "Fortunately, `Arc‹T>` *is* a type like `Rc‹T>` that is safe to use in\nconcurrent situations.",
                  "answer_start": 8423,
                  "answer_end": 8515,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "Why not all types are atomic?",
              "id": 109,
              "answers": [
                {
                  "answer_id": 109,
                  "document_id": 83,
                  "question_id": 109,
                  "text": "The reason is that\nthread safety comes with a performance penalty that you only want to pay when\nyou really need to.",
                  "answer_start": 9049,
                  "answer_end": 9165,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "Can Mutex<T> create deadlocks?",
              "id": 110,
              "answers": [
                {
                  "answer_id": 110,
                  "document_id": 83,
                  "question_id": 110,
                  "text": "`Mutex‹T>` comes with the risk of\ncreating *deadlocks*.",
                  "answer_start": 11606,
                  "answer_end": 11661,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "How to prevent deadlocks?",
              "id": 112,
              "answers": [
                {
                  "answer_id": 112,
                  "document_id": 83,
                  "question_id": 112,
                  "text": "If you’re interested in deadlocks, try creating a Rust\nprogram that has a deadlock; then research deadlock mitigation strategies for\nmutexes in any language and have a go at implementing them in Rust. The\nstandard library API documentation for `Mutex‹T>` and `MutexGuard` offers\nuseful information.",
                  "answer_start": 11818,
                  "answer_end": 12116,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "## Shared-State Concurrency\n\nMessage passing is a fine way of handling concurrency, but it’s not the only\none. Another method would be for multiple threads to access the same shared\ndata. Consider this part of the slogan from the Go language documentation\nagain: “do not communicate by sharing memory.”\n\nWhat would communicating by sharing memory look like? In addition, why would\nmessage-passing enthusiasts caution not to use memory sharing?\n\nIn a way, channels in any programming language are similar to single ownership,\nbecause once you transfer a value down a channel, you should no longer use that\nvalue. Shared memory concurrency is like multiple ownership: multiple threads\ncan access the same memory location at the same time. As you saw in Chapter 15,\nwhere smart pointers made multiple ownership possible, multiple ownership can\nadd complexity because these different owners need managing. Rust’s type system\nand ownership rules greatly assist in getting this management correct. For an\nexample, let’s look at mutexes, one of the more common concurrency primitives\nfor shared memory.\n\n### Using Mutexes to Allow Access to Data from One Thread at a Time\n\n*Mutex* is an abbreviation for *mutual exclusion*, as in, a mutex allows only\none thread to access some data at any given time. To access the data in a\nmutex, a thread must first signal that it wants access by asking to acquire the\nmutex’s *lock*. The lock is a data structure that is part of the mutex that\nkeeps track of who currently has exclusive access to the data. Therefore, the\nmutex is described as *guarding* the data it holds via the locking system.\n\nMutexes have a reputation for being difficult to use because you have to\nremember two rules:\n\n* You must attempt to acquire the lock before using the data.\n* When you’re done with the data that the mutex guards, you must unlock the\n  data so other threads can acquire the lock.\n\nFor a real-world metaphor for a mutex, imagine a panel discussion at a\nconference with only one microphone. Before a panelist can speak, they have to\nask or signal that they want to use the microphone. When they get the\nmicrophone, they can talk for as long as they want to and then hand the\nmicrophone to the next panelist who requests to speak. If a panelist forgets to\nhand the microphone off when they’re finished with it, no one else is able to\nspeak. If management of the shared microphone goes wrong, the panel won’t work\nas planned!\n\nManagement of mutexes can be incredibly tricky to get right, which is why so\nmany people are enthusiastic about channels. However, thanks to Rust’s type\nsystem and ownership rules, you can’t get locking and unlocking wrong.\n\n#### The API of `Mutex<T>`\n\nAs an example of how to use a mutex, let’s start by using a mutex in a\nsingle-threaded context, as shown in Listing 16-12:\n\n<span class=\"filename\">Filename: src/main.rs</span>\n\n```rust\n{{#rustdoc_include ../listings/ch16-fearless-concurrency/listing-16-12/src/main.rs}}\n```\n\n<span class=\"caption\">Listing 16-12: Exploring the API of `Mutex<T>` in a\nsingle-threaded context for simplicity</span>\n\nAs with many types, we create a `Mutex<T>` using the associated function `new`.\nTo access the data inside the mutex, we use the `lock` method to acquire the\nlock. This call will block the current thread so it can’t do any work until\nit’s our turn to have the lock.\n\nThe call to `lock` would fail if another thread holding the lock panicked. In\nthat case, no one would ever be able to get the lock, so we’ve chosen to\n`unwrap` and have this thread panic if we’re in that situation.\n\nAfter we’ve acquired the lock, we can treat the return value, named `num` in\nthis case, as a mutable reference to the data inside. The type system ensures\nthat we acquire a lock before using the value in `m`. The type of `m` is\n`Mutex<i32>`, not `i32`, so we *must* call `lock` to be able to use the `i32`\nvalue. We can’t forget; the type system won’t let us access the inner `i32`\notherwise.\n\nAs you might suspect, `Mutex<T>` is a smart pointer. More accurately, the call\nto `lock` *returns* a smart pointer called `MutexGuard`, wrapped in a\n`LockResult` that we handled with the call to `unwrap`. The `MutexGuard` smart\npointer implements `Deref` to point at our inner data; the smart pointer also\nhas a `Drop` implementation that releases the lock automatically when a\n`MutexGuard` goes out of scope, which happens at the end of the inner scope. As\na result, we don’t risk forgetting to release the lock and blocking the mutex\nfrom being used by other threads, because the lock release happens\nautomatically.\n\nAfter dropping the lock, we can print the mutex value and see that we were able\nto change the inner `i32` to 6.\n\n#### Sharing a `Mutex<T>` Between Multiple Threads\n\nNow, let’s try to share a value between multiple threads using `Mutex<T>`.\nWe’ll spin up 10 threads and have them each increment a counter value by 1, so\nthe counter goes from 0 to 10. The next example in Listing 16-13 will have\na compiler error, and we’ll use that error to learn more about using\n`Mutex<T>` and how Rust helps us use it correctly.\n\n<span class=\"filename\">Filename: src/main.rs</span>\n\n```rust,ignore,does_not_compile\n{{#rustdoc_include ../listings/ch16-fearless-concurrency/listing-16-13/src/main.rs}}\n```\n\n<span class=\"caption\">Listing 16-13: Ten threads each increment a counter\nguarded by a `Mutex<T>`</span>\n\nWe create a `counter` variable to hold an `i32` inside a `Mutex<T>`, as we did\nin Listing 16-12. Next, we create 10 threads by iterating over a range of\nnumbers. We use `thread::spawn` and give all the threads the same closure: one\nthat moves the counter into the thread, acquires a lock on the `Mutex<T>` by\ncalling the `lock` method, and then adds 1 to the value in the mutex. When a\nthread finishes running its closure, `num` will go out of scope and release the\nlock so another thread can acquire it.\n\nIn the main thread, we collect all the join handles. Then, as we did in Listing\n16-2, we call `join` on each handle to make sure all the threads finish. At\nthat point, the main thread will acquire the lock and print the result of this\nprogram.\n\nWe hinted that this example wouldn’t compile. Now let’s find out why!\n\n```console\n{{#include ../listings/ch16-fearless-concurrency/listing-16-13/output.txt}}\n```\n\nThe error message states that the `counter` value was moved in the previous\niteration of the loop. Rust is telling us that we can’t move the ownership\nof lock `counter` into multiple threads. Let’s fix the compiler error with a\nmultiple-ownership method we discussed in Chapter 15.\n\n#### Multiple Ownership with Multiple Threads\n\nIn Chapter 15, we gave a value multiple owners by using the smart pointer\n`Rc<T>` to create a reference counted value. Let’s do the same here and see\nwhat happens. We’ll wrap the `Mutex<T>` in `Rc<T>` in Listing 16-14 and clone\nthe `Rc<T>` before moving ownership to the thread.\n\n<span class=\"filename\">Filename: src/main.rs</span>\n\n```rust,ignore,does_not_compile\n{{#rustdoc_include ../listings/ch16-fearless-concurrency/listing-16-14/src/main.rs}}\n```\n\n<span class=\"caption\">Listing 16-14: Attempting to use `Rc<T>` to allow\nmultiple threads to own the `Mutex<T>`</span>\n\nOnce again, we compile and get... different errors! The compiler is teaching us\na lot.\n\n```console\n{{#include ../listings/ch16-fearless-concurrency/listing-16-14/output.txt}}\n```\n\nWow, that error message is very wordy! Here’s the important part to focus on:\n`` `Rc<Mutex<i32>>` cannot be sent between threads safely ``. The compiler is\nalso telling us the reason why: ``the trait `Send` is not implemented for\n`Rc<Mutex<i32>>` ``. We’ll talk about `Send` in the next section: it’s one of\nthe traits that ensures the types we use with threads are meant for use in\nconcurrent situations.\n\nUnfortunately, `Rc<T>` is not safe to share across threads. When `Rc<T>`\nmanages the reference count, it adds to the count for each call to `clone` and\nsubtracts from the count when each clone is dropped. But it doesn’t use any\nconcurrency primitives to make sure that changes to the count can’t be\ninterrupted by another thread. This could lead to wrong counts—subtle bugs that\ncould in turn lead to memory leaks or a value being dropped before we’re done\nwith it. What we need is a type exactly like `Rc<T>` but one that makes changes\nto the reference count in a thread-safe way.\n\n#### Atomic Reference Counting with `Arc<T>`\n\nFortunately, `Arc<T>` *is* a type like `Rc<T>` that is safe to use in\nconcurrent situations. The *a* stands for *atomic*, meaning it’s an *atomically\nreference counted* type. Atomics are an additional kind of concurrency\nprimitive that we won’t cover in detail here: see the standard library\ndocumentation for [`std::sync::atomic`][atomic]<!-- ignore --> for more\ndetails. At this point, you just need to know that atomics work like primitive\ntypes but are safe to share across threads.\n\nYou might then wonder why all primitive types aren’t atomic and why standard\nlibrary types aren’t implemented to use `Arc<T>` by default. The reason is that\nthread safety comes with a performance penalty that you only want to pay when\nyou really need to. If you’re just performing operations on values within a\nsingle thread, your code can run faster if it doesn’t have to enforce the\nguarantees atomics provide.\n\nLet’s return to our example: `Arc<T>` and `Rc<T>` have the same API, so we fix\nour program by changing the `use` line, the call to `new`, and the call to\n`clone`. The code in Listing 16-15 will finally compile and run:\n\n<span class=\"filename\">Filename: src/main.rs</span>\n\n```rust\n{{#rustdoc_include ../listings/ch16-fearless-concurrency/listing-16-15/src/main.rs}}\n```\n\n<span class=\"caption\">Listing 16-15: Using an `Arc<T>` to wrap the `Mutex<T>`\nto be able to share ownership across multiple threads</span>\n\nThis code will print the following:\n\n<!-- Not extracting output because changes to this output aren't significant;\nthe changes are likely to be due to the threads running differently rather than\nchanges in the compiler -->\n\n```text\nResult: 10\n```\n\nWe did it! We counted from 0 to 10, which may not seem very impressive, but it\ndid teach us a lot about `Mutex<T>` and thread safety. You could also use this\nprogram’s structure to do more complicated operations than just incrementing a\ncounter. Using this strategy, you can divide a calculation into independent\nparts, split those parts across threads, and then use a `Mutex<T>` to have each\nthread update the final result with its part.\n\nNote that if you are doing simple numerical operations, there are types simpler\nthan `Mutex<T>` types provided by the [`std::sync::atomic` module of the\nstandard library][atomic]<!-- ignore -->. These types provide safe, concurrent,\natomic access to primitive types. We chose to use `Mutex<T>` with a primitive\ntype for this example so we could concentrate on how `Mutex<T>` works.\n\n### Similarities Between `RefCell<T>`/`Rc<T>` and `Mutex<T>`/`Arc<T>`\n\nYou might have noticed that `counter` is immutable but we could get a mutable\nreference to the value inside it; this means `Mutex<T>` provides interior\nmutability, as the `Cell` family does. In the same way we used `RefCell<T>` in\nChapter 15 to allow us to mutate contents inside an `Rc<T>`, we use `Mutex<T>`\nto mutate contents inside an `Arc<T>`.\n\nAnother detail to note is that Rust can’t protect you from all kinds of logic\nerrors when you use `Mutex<T>`. Recall in Chapter 15 that using `Rc<T>` came\nwith the risk of creating reference cycles, where two `Rc<T>` values refer to\neach other, causing memory leaks. Similarly, `Mutex<T>` comes with the risk of\ncreating *deadlocks*. These occur when an operation needs to lock two resources\nand two threads have each acquired one of the locks, causing them to wait for\neach other forever. If you’re interested in deadlocks, try creating a Rust\nprogram that has a deadlock; then research deadlock mitigation strategies for\nmutexes in any language and have a go at implementing them in Rust. The\nstandard library API documentation for `Mutex<T>` and `MutexGuard` offers\nuseful information.\n\nWe’ll round out this chapter by talking about the `Send` and `Sync` traits and\nhow we can use them with custom types.\n\n[atomic]: ../std/sync/atomic/index.html\n",
          "document_id": 83
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "What does Send trait do?",
              "id": 74,
              "answers": [
                {
                  "answer_id": 74,
                  "document_id": 84,
                  "question_id": 74,
                  "text": "The `Send` marker trait indicates that ownership of values of the type\nimplementing `Send` can be transferred between threads.",
                  "answer_start": 612,
                  "answer_end": 738,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "Which types implement Send?",
              "id": 75,
              "answers": [
                {
                  "answer_id": 75,
                  "document_id": 84,
                  "question_id": 75,
                  "text": "Almost every Rust type\nis `Send`, but there are some exceptions, including `Rc‹T>`",
                  "answer_start": 739,
                  "answer_end": 821,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "Which structs are Send?",
              "id": 76,
              "answers": [
                {
                  "answer_id": 76,
                  "document_id": 84,
                  "question_id": 76,
                  "text": "Any type composed entirely of `Send` types is automatically marked as `Send` as\nwell.",
                  "answer_start": 1472,
                  "answer_end": 1557,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What does Sync trait do?",
              "id": 77,
              "answers": [
                {
                  "answer_id": 77,
                  "document_id": 84,
                  "question_id": 77,
                  "text": "The `Sync` marker trait indicates that it is safe for the type implementing\n`Sync` to be referenced from multiple threads.",
                  "answer_start": 1713,
                  "answer_end": 1835,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "When types are Sync?",
              "id": 78,
              "answers": [
                {
                  "answer_id": 78,
                  "document_id": 84,
                  "question_id": 78,
                  "text": "any type `T` is\n`Sync` if `&T` (an immutable reference to `T`) is `Send`, meaning the reference\ncan be sent safely to another thread.",
                  "answer_start": 1852,
                  "answer_end": 1985,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "## Extensible Concurrency with the `Sync` and `Send` Traits\n\nInterestingly, the Rust language has *very* few concurrency features. Almost\nevery concurrency feature we’ve talked about so far in this chapter has been\npart of the standard library, not the language. Your options for handling\nconcurrency are not limited to the language or the standard library; you can\nwrite your own concurrency features or use those written by others.\n\nHowever, two concurrency concepts are embedded in the language: the\n`std::marker` traits `Sync` and `Send`.\n\n### Allowing Transference of Ownership Between Threads with `Send`\n\nThe `Send` marker trait indicates that ownership of values of the type\nimplementing `Send` can be transferred between threads. Almost every Rust type\nis `Send`, but there are some exceptions, including `Rc<T>`: this cannot be\n`Send` because if you cloned an `Rc<T>` value and tried to transfer ownership\nof the clone to another thread, both threads might update the reference count\nat the same time. For this reason, `Rc<T>` is implemented for use in\nsingle-threaded situations where you don’t want to pay the thread-safe\nperformance penalty.\n\nTherefore, Rust’s type system and trait bounds ensure that you can never\naccidentally send an `Rc<T>` value across threads unsafely. When we tried to do\nthis in Listing 16-14, we got the error `the trait Send is not implemented for\nRc<Mutex<i32>>`. When we switched to `Arc<T>`, which is `Send`, the code\ncompiled.\n\nAny type composed entirely of `Send` types is automatically marked as `Send` as\nwell. Almost all primitive types are `Send`, aside from raw pointers, which\nwe’ll discuss in Chapter 19.\n\n### Allowing Access from Multiple Threads with `Sync`\n\nThe `Sync` marker trait indicates that it is safe for the type implementing\n`Sync` to be referenced from multiple threads. In other words, any type `T` is\n`Sync` if `&T` (an immutable reference to `T`) is `Send`, meaning the reference\ncan be sent safely to another thread. Similar to `Send`, primitive types are\n`Sync`, and types composed entirely of types that are `Sync` are also `Sync`.\n\nThe smart pointer `Rc<T>` is also not `Sync` for the same reasons that it’s not\n`Send`. The `RefCell<T>` type (which we talked about in Chapter 15) and the\nfamily of related `Cell<T>` types are not `Sync`. The implementation of borrow\nchecking that `RefCell<T>` does at runtime is not thread-safe. The smart\npointer `Mutex<T>` is `Sync` and can be used to share access with multiple\nthreads as you saw in the [“Sharing a `Mutex<T>` Between Multiple\nThreads”][sharing-a-mutext-between-multiple-threads]<!-- ignore --> section.\n\n### Implementing `Send` and `Sync` Manually Is Unsafe\n\nBecause types that are made up of `Send` and `Sync` traits are automatically\nalso `Send` and `Sync`, we don’t have to implement those traits manually. As\nmarker traits, they don’t even have any methods to implement. They’re just\nuseful for enforcing invariants related to concurrency.\n\nManually implementing these traits involves implementing unsafe Rust code.\nWe’ll talk about using unsafe Rust code in Chapter 19; for now, the important\ninformation is that building new concurrent types not made up of `Send` and\n`Sync` parts requires careful thought to uphold the safety guarantees. [“The\nRustonomicon”][nomicon] has more information about these guarantees and how to\nuphold them.\n\n## Summary\n\nThis isn’t the last you’ll see of concurrency in this book: the project in\nChapter 20 will use the concepts in this chapter in a more realistic situation\nthan the smaller examples discussed here.\n\nAs mentioned earlier, because very little of how Rust handles concurrency is\npart of the language, many concurrency solutions are implemented as crates.\nThese evolve more quickly than the standard library, so be sure to search\nonline for the current, state-of-the-art crates to use in multithreaded\nsituations.\n\nThe Rust standard library provides channels for message passing and smart\npointer types, such as `Mutex<T>` and `Arc<T>`, that are safe to use in\nconcurrent contexts. The type system and the borrow checker ensure that the\ncode using these solutions won’t end up with data races or invalid references.\nOnce you get your code to compile, you can rest assured that it will happily\nrun on multiple threads without the kinds of hard-to-track-down bugs common in\nother languages. Concurrent programming is no longer a concept to be afraid of:\ngo forth and make your programs concurrent, fearlessly!\n\nNext, we’ll talk about idiomatic ways to model problems and structure solutions\nas your Rust programs get bigger. In addition, we’ll discuss how Rust’s idioms\nrelate to those you might be familiar with from object-oriented programming.\n\n[sharing-a-mutext-between-multiple-threads]:\nch16-03-shared-state.html#sharing-a-mutext-between-multiple-threads\n[nomicon]: ../nomicon/index.html\n",
          "document_id": 84
        }
      ]
    }
  ]
}